{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "from PIL import Image\n",
    "import cv2\n",
    "from skimage.color import rgb2gray\n",
    "from skimage import io\n",
    "from skimage.measure import label, regionprops\n",
    "import glob\n",
    "import re\n",
    "from scipy.stats import ttest_ind\n",
    "import seaborn as sns\n",
    "\n",
    "class ImageAnalysis:\n",
    "    \n",
    "    \"\"\"\n",
    "    Provides methods for organizing and analyzing image data from various directory structures within a project folder.\n",
    "    This class initializes by reading the project folder, creating a DataFrame that lists each directory and its path,\n",
    "    and allows for further expansion to include specific image analysis metadata.\n",
    "\n",
    "    Parameters:\n",
    "    - project_folder (str): The path to the project folder containing various image data directories.\n",
    "\n",
    "    \"\"\"\n",
    "    \n",
    "    def __init__(self, project_folder):\n",
    "        self.project_folder = project_folder\n",
    "        self.directory_df = self.initialize_directory_df() \n",
    "        \n",
    "    def initialize_directory_df(self):\n",
    "        directories = [d for d in os.listdir(self.project_folder) if os.path.isdir(os.path.join(self.project_folder, d))]\n",
    "        directory_data = [{'directory_name': d, 'directory_path': os.path.join(self.project_folder, d)} for d in directories]\n",
    "        return pd.DataFrame(directory_data, columns=['directory_name', 'directory_path'])\n",
    "    \n",
    "    def expand_directory_df(self):\n",
    "        # Add new columns with default empty lists\n",
    "        self.directory_df['sensor_type'] = ''\n",
    "        self.directory_df['session_id'] = ''\n",
    "        self.directory_df['stimulation_ids'] = [[] for _ in range(len(self.directory_df))]\n",
    "        self.directory_df['stimulation_frame_number'] = [[] for _ in range(len(self.directory_df))]\n",
    "\n",
    "        for index, row in self.directory_df.iterrows():\n",
    "            folder_name = row['directory_name']\n",
    "            folder_path = row['directory_path']\n",
    "            \n",
    "            # Parse folder name for sensor type and session id\n",
    "            parts = folder_name.split('_')\n",
    "            sensor_type = 'gcamp8' if parts[0].startswith('g') else 'cablam'\n",
    "            session_id = parts[0][1:] + parts[1]  # Assuming the first part is always the experiment ID\n",
    "\n",
    "            # Update DataFrame with sensor_type and session_id\n",
    "            self.directory_df.at[index, 'sensor_type'] = sensor_type\n",
    "            self.directory_df.at[index, 'session_id'] = session_id\n",
    "\n",
    "            # Check for CSV file ending in 'biolumi' or 'fluor'\n",
    "            csv_filename = [f for f in os.listdir(folder_path) if (f.endswith('biolumi.csv') or f.endswith('fluor.csv'))]\n",
    "            if csv_filename:\n",
    "                csv_file_path = os.path.join(folder_path, csv_filename[0])\n",
    "                df_csv = pd.read_csv(csv_file_path, header=None)\n",
    "                stimulation_ids = df_csv.iloc[1].dropna().tolist()\n",
    "                stimulation_frame_number = df_csv.iloc[0].dropna().tolist()\n",
    "\n",
    "                # Update DataFrame with stimulation information\n",
    "                self.directory_df.at[index, 'stimulation_ids'] = stimulation_ids\n",
    "                self.directory_df.at[index, 'stimulation_frame_number'] = stimulation_frame_number\n",
    "\n",
    "        return self.directory_df\n",
    "        \n",
    "    def max_projection_mean_values(self, tif_path):\n",
    "        \"\"\"\n",
    "        Generates a maximum intensity projection based on the mean values of a multi-frame TIF file\n",
    "        and saves it to a new subdirectory 'processed_data/processed_image_analysis_output'\n",
    "        with a '_max_projection' suffix in the file name.\n",
    "\n",
    "        Parameters:\n",
    "        tif_path (str): Path to the multi-frame TIF file.\n",
    "\n",
    "        Returns:\n",
    "        str: Path to the saved maximum intensity projection image.\n",
    "        \"\"\"\n",
    "\n",
    "        with Image.open(tif_path) as img:\n",
    "            # Initialize a summing array with the shape of the first frame and float type for mean calculation\n",
    "            sum_image = np.zeros((img.height, img.width), dtype=np.float32)\n",
    "\n",
    "            # Sum up all frames\n",
    "            for i in range(img.n_frames):\n",
    "                img.seek(i)\n",
    "                sum_image += np.array(img, dtype=np.float32)\n",
    "\n",
    "            # Compute the mean image by dividing the sum by the number of frames\n",
    "            mean_image = sum_image / img.n_frames\n",
    "        \n",
    "        # Define the new directory path\n",
    "        processed_dir = os.path.join(os.path.dirname(tif_path), 'processed_data', 'processed_image_analysis_output')\n",
    "        \n",
    "        # Create the directory if it does not exist\n",
    "        os.makedirs(processed_dir, exist_ok=True)\n",
    "        \n",
    "        # Create a new file path for the max projection image with the '_max_projection' suffix\n",
    "        # The filename is extracted from tif_path and appended with '_max_projection.tif'\n",
    "        file_name = os.path.basename(tif_path)\n",
    "        max_proj_image_path = os.path.join(processed_dir, file_name.replace('.tif', '_max_projection.tif'))\n",
    "       \n",
    "        # Save the max projection image to the new file path\n",
    "        Image.fromarray(mean_image).save(max_proj_image_path)\n",
    "\n",
    "        # Return the path to the saved image\n",
    "        return max_proj_image_path\n",
    "    \n",
    "    def analyze_all_sessions(self, function_to_apply):\n",
    "        \"\"\"\n",
    "        Iterates over all session IDs in the directory DataFrame and applies the given function to each.\n",
    "\n",
    "        Parameters:\n",
    "        function_to_apply (callable): Function to be applied to each session. It should accept a session ID.\n",
    "\n",
    "        Returns:\n",
    "        dict: A dictionary with session_ids as keys and function return values as values.\n",
    "        \"\"\"\n",
    "        results = {}\n",
    "        for session_id in self.directory_df['session_id']:\n",
    "            try:\n",
    "                result = function_to_apply(session_id)\n",
    "                results[session_id] = result\n",
    "            except Exception as e:\n",
    "                print(f\"An error occurred while processing session {session_id}: {e}\")\n",
    "        return results\n",
    "    \n",
    "    def analyze_session_max_projection(self, session_id):\n",
    "        \"\"\"\n",
    "        Wrapper function to apply max_projection_mean_values to a session's TIF file.\n",
    "\n",
    "        Parameters:\n",
    "        session_id (str): The session ID for which the TIF file will be processed.\n",
    "\n",
    "        Returns:\n",
    "        str: Path to the processed max projection TIFF file.\n",
    "        \"\"\"\n",
    "        # analysis is an instance of ImageAnalysis\n",
    "        tif_path = self.get_session_raw_data(session_id)\n",
    "        if isinstance(tif_path, str) and tif_path.endswith('.tif'):\n",
    "            return self.max_projection_mean_values(tif_path)\n",
    "        else:\n",
    "            return f\"No valid TIF file found for session {session_id}\"# Apply max_projection_mean_values to all sessions\n",
    "        \n",
    "    def get_session_raw_data(self, session_id):\n",
    "        # Check if the session_id is in the 'session_id' column of the directory_df\n",
    "        if session_id in self.directory_df['session_id'].tolist():\n",
    "            # Find the directory path for the given session_id\n",
    "            directory_path = self.directory_df[self.directory_df['session_id'] == session_id]['directory_path'].values[0]\n",
    "            \n",
    "            # Search for the .tif file within that directory\n",
    "            for file_name in os.listdir(directory_path):\n",
    "                if file_name.endswith('.tif'):\n",
    "                    return os.path.join(directory_path, file_name)\n",
    "\n",
    "            # If no .tif file is found in the directory\n",
    "            return f\"No .tif file found in the directory for session {session_id}.\"\n",
    "        else:\n",
    "            # If the session_id is not present in the DataFrame\n",
    "            return f\"Session ID {session_id} is not present in the directory DataFrame.\"\n",
    "         \n",
    "    def add_tiff_dimensions(self):\n",
    "        \"\"\"\n",
    "        Analyzes the dimensions of TIF files in the directory DataFrame and adds this data as new columns.\n",
    "        \"\"\"\n",
    "        # Ensure the DataFrame has the columns for dimensions\n",
    "        if 'x_dim' not in self.directory_df.columns:\n",
    "            self.directory_df['x_dim'] = None\n",
    "            self.directory_df['y_dim'] = None\n",
    "            self.directory_df['z_dim_frames'] = None\n",
    "\n",
    "        # Iterate over each session_id and update the dimensions\n",
    "        for index, row in self.directory_df.iterrows():\n",
    "            tif_path = self.get_session_raw_data(row['session_id'])\n",
    "            if isinstance(tif_path, str) and tif_path.endswith('.tif'):\n",
    "                try:\n",
    "                    with Image.open(tif_path) as img:\n",
    "                        self.directory_df.at[index, 'x_dim'] = img.width\n",
    "                        self.directory_df.at[index, 'y_dim'] = img.height\n",
    "                        # For z-dimension, count the frames\n",
    "                        img.seek(0)  # Ensure the pointer is at the beginning\n",
    "                        frames = 0\n",
    "                        while True:\n",
    "                            try:\n",
    "                                img.seek(img.tell() + 1)\n",
    "                                frames += 1\n",
    "                            except EOFError:\n",
    "                                break\n",
    "                        self.directory_df.at[index, 'z_dim_frames'] = frames\n",
    "                except Exception as e:\n",
    "                    print(f\"Could not process TIF dimensions for session {row['session_id']}: {e}\")\n",
    "                                \n",
    "    def analyze_all_calcium_signals(self):\n",
    "        \"\"\"\n",
    "        Applies calcium signal extraction to all session_ids in the directory DataFrame and stores the results.\n",
    "        \"\"\"\n",
    "        results = {}\n",
    "        for session_id in self.directory_df['session_id']:\n",
    "            # Ensure the ROI analysis has been done to get the labeled images\n",
    "            roi_results = self.analyze_roi(session_id)\n",
    "            # Check if analyze_roi returned a path to labeled images\n",
    "            if isinstance(roi_results, tuple):\n",
    "                # Extract calcium signals using the labeled ROI mask\n",
    "                calcium_csv_path = self.extract_calcium_signals(session_id)\n",
    "                results[session_id] = calcium_csv_path\n",
    "            else:\n",
    "                # If roi_results is an error message, pass it through\n",
    "                results[session_id] = roi_results\n",
    "                \n",
    "            #results is a dictionary where each key is a session_id and the corresponding value is the path to the saved CSV file containing calcium signal data.\n",
    "        return results\n",
    "     \n",
    "    def analyze_roi(self, session_id):\n",
    "        \"\"\"\n",
    "        Analyzes ROI of the 'labels_postexport.tif' file for a given session and saves two results:\n",
    "        one with labels and another without labels.I t also saves the labeled image data as numpy array for future use.\n",
    "        \"\"\"\n",
    "        \n",
    "        #### SETP 1: DEFINE PATHS ####\n",
    "        # define the paths, including the directory where processed images will be saved (processed_dir) \n",
    "        # and the name of the TIF file that contains the ROI labels (consistent_file_name)\n",
    "        processed_dir = 'processed_data/processed_image_analysis_output'\n",
    "        consistent_file_name = 'labels_postexport.tif'\n",
    "        output_suffix_with_labels = '_roi_analysis_with_labels.png'\n",
    "        output_suffix_without_labels = '_roi_analysis_without_labels.png'\n",
    "\n",
    "        #### STEP 2: RETRIEVE SESSION DATA ####\n",
    "        # Retrieve the directory path from the DataFrame\n",
    "        # looks up the session's directory path from a DataFrame (directory_df) using the provided session_id. \n",
    "        # If the session ID isn't found, it returns a message indicating no directory entry was found for that session.\n",
    "        \n",
    "        directory_entry = self.directory_df[self.directory_df['session_id'] == session_id]\n",
    "        if directory_entry.empty:\n",
    "            return f\"No directory entry found for session {session_id}\"\n",
    "\n",
    "        #### STEP 3: VERIFY AND LOAD THE ROI TIF FILE ####\n",
    "        # constructs the full path to the labels_postexport.tif file and checks if it exists. If it does, the file is opened and loaded. \n",
    "        # If the file is in RGB format, it's converted to grayscale using rgb2gray from skimage.color. \n",
    "        # This conversion is crucial for analyzing the image as a binary mask where non-white pixels are considered ROIs.\n",
    "        directory_path = directory_entry['directory_path'].values[0]\n",
    "        \n",
    "        # Build the path to the postexport TIFF file\n",
    "        tiff_file_path = os.path.join(directory_path, processed_dir, consistent_file_name)\n",
    "\n",
    "        # Verify that the file exists\n",
    "        if not os.path.exists(tiff_file_path):\n",
    "            return f\"File not found for session {session_id}\"\n",
    "        else:\n",
    "            print(f\"Analyzing session {session_id}...\")\n",
    "        \n",
    "        #### STEP 4: CREATE AND SAVE THE BINARY MASK ####\n",
    "        # k: The method then converts the grayscale image to a binary mask, identifying all non-white pixels as ROIs \n",
    "        # (pixels with value less than 1 after normalization are set to 1, and others to 0). \n",
    "        # This binary mask is labeled using label from skimage.measure, assigning a unique label to each connected component (ROI).\n",
    "        \n",
    "        # Load the image\n",
    "        mask_image = Image.open(tiff_file_path)\n",
    "\n",
    "        # Convert RGB image to grayscale if necessary\n",
    "        if mask_image.mode == 'RGB':\n",
    "            # Convert to grayscale using skimage's rgb2gray\n",
    "            image_array = rgb2gray(np.array(mask_image))\n",
    "\n",
    "        # Assuming that all non-white pixels are ROIs\n",
    "        binary_mask = np.where(image_array < 1, 1, 0)  # Here, 1 corresponds to white in the normalized grayscale image\n",
    "\n",
    "        # Label the regions\n",
    "        labeled_image = label(binary_mask, connectivity=1)\n",
    "        num_rois = np.max(labeled_image)\n",
    "        \n",
    "        # Save the labeled image data as a NumPy array file for future processing\n",
    "        labeled_image_path = os.path.join(directory_path, processed_dir, f\"{session_id}_labeled_image.npy\")\n",
    "        np.save(labeled_image_path, labeled_image)\n",
    "        \n",
    "        \n",
    "        #### STEP 5: SAVE THE UNLABELED ROI IMAGE ####\n",
    "        # Save Unlabeled ROI Image: The method saves a version of the labeled image without any annotations to a specified path (output_path_without_labels). \n",
    "        # This image is saved in the processed_image_analysis_output directory with a specific suffix to indicate it's the unlabeled version.\n",
    "        \n",
    "        # Save the image without labels\n",
    "        output_path_without_labels = os.path.join(directory_path, processed_dir, session_id + output_suffix_without_labels)\n",
    "        plt.imsave(output_path_without_labels, labeled_image, cmap='nipy_spectral')\n",
    "\n",
    "        \n",
    "        #### STEP 6: ANALYZE AND SAVE LABELED ROI IMAGE ####\n",
    "        # Iterates through each detected region using regionprops, extracts the centroid, \n",
    "        # and annotates the image with the region's label. \n",
    "        # This annotated image is saved separately, indicating it includes ROI labels.\n",
    "        \n",
    "        # Analyze regions and save properties\n",
    "        regions = regionprops(labeled_image)\n",
    "\n",
    "        # Prepare to save the ROI analysis image with labels\n",
    "        output_path_with_labels = os.path.join(directory_path, processed_dir, session_id + output_suffix_with_labels)\n",
    "        \n",
    "        fig, ax = plt.subplots()\n",
    "        ax.imshow(labeled_image, cmap='nipy_spectral')\n",
    "        ax.axis('off')\n",
    "\n",
    "        # Annotate each ROI with its corresponding label (ID)\n",
    "        for region in regions:\n",
    "            # Get the coordinates of the centroid of the region\n",
    "            y, x = region.centroid\n",
    "            # Annotate the ROI ID at the centroid position\n",
    "            ax.text(x, y, str(region.label), color='white', ha='center', va='center')\n",
    "\n",
    "        plt.savefig(output_path_with_labels)\n",
    "        plt.close()\n",
    "\n",
    "        # Return the paths of the saved figures LABELED AND UNLABELED and number of ROIs\n",
    "        return (output_path_with_labels, output_path_without_labels), num_rois\n",
    "    \n",
    "    def analyze_all_rois(self):\n",
    "        \"\"\"\n",
    "        Applies ROI analysis to all sessions and saves the results.\n",
    "        \"\"\"\n",
    "        results = {}\n",
    "        for session_id in self.directory_df['session_id']:\n",
    "            result = self.analyze_roi(session_id)\n",
    "            results[session_id] = result\n",
    "        return results\n",
    "    \n",
    "    def process_all_sessions(self, use_corrected_data=False):\n",
    "        \n",
    "        \"\"\"\n",
    "        This assumes the analyze_all_rois method has been previously run to generate the numpy files \n",
    "        and the corresponding images with and without labels for ROI per session.\n",
    "        \n",
    "        Process all sessions using either corrected or uncorrected calcium signal data.\n",
    "\n",
    "        Parameters\n",
    "        ----------\n",
    "        use_corrected_data : bool, optional\n",
    "            Flag indicating whether to use corrected calcium signals. Defaults to False, \n",
    "            indicating uncorrected data should be used.\n",
    "\n",
    "        Returns\n",
    "        -------\n",
    "        dict\n",
    "            A dictionary with processed data for all sessions, keyed by session ID.\n",
    "        \"\"\"\n",
    "        \n",
    "        all_data = {}\n",
    "        \n",
    "        for session_id in self.directory_df['session_id'].unique():\n",
    "            stim_frame_numbers, roi_data, stimulation_ids = self.create_trial_locked_calcium_signals(session_id, use_corrected_data=use_corrected_data)\n",
    "            if stim_frame_numbers and roi_data and stimulation_ids:  # Ensure data was returned\n",
    "                all_data[session_id] = {\n",
    "                    'stim_frame_numbers': stim_frame_numbers,\n",
    "                    'roi_data': roi_data,\n",
    "                    'stimulation_ids': stimulation_ids\n",
    "                }\n",
    "        return all_data\n",
    "    \n",
    "    def create_trial_locked_calcium_signals(self, session_id, use_corrected_data=False):\n",
    "        \"\"\"\n",
    "        Generate trial-locked calcium signal data for a given session ID, allowing\n",
    "        the choice between corrected and uncorrected data.\n",
    "        \n",
    "        Parameters\n",
    "        ----------\n",
    "        session_id : str\n",
    "            The session ID for which to generate trial-locked signals.\n",
    "        use_corrected_data : bool, optional\n",
    "            Whether to use corrected calcium signal data. The default is False, which uses uncorrected data.\n",
    "        \n",
    "        Returns\n",
    "        -------\n",
    "        tuple\n",
    "            A tuple containing the stimulation frame numbers, ROI data, and stimulation IDs.\n",
    "        \"\"\"\n",
    "\n",
    "        processed_dir = 'processed_data/processed_image_analysis_output'\n",
    "        calcium_csv_suffix = '_corrected_calcium_signals.csv' if use_corrected_data else '_calcium_signals.csv'\n",
    "\n",
    "        directory_entry = self.directory_df[self.directory_df['session_id'] == session_id]\n",
    "\n",
    "        if directory_entry.empty:\n",
    "            print(f\"No directory entry found for session {session_id}\")\n",
    "            return None, None, None\n",
    "\n",
    "        directory_path = directory_entry['directory_path'].values[0]\n",
    "        csv_path = os.path.join(directory_path, processed_dir, f\"{session_id}{calcium_csv_suffix}\")\n",
    "\n",
    "        if not os.path.exists(csv_path):\n",
    "            print(f\"Calcium signals file not found for session {session_id} using {'corrected' if use_corrected_data else 'uncorrected'} data\")\n",
    "            return None, None, None\n",
    "\n",
    "        calcium_signals_df = pd.read_csv(csv_path)\n",
    "        stim_frame_numbers = directory_entry['stimulation_frame_number'].values[0]\n",
    "        stimulation_ids = directory_entry['stimulation_ids'].values[0]\n",
    "\n",
    "        pre_stim_frames = 10 # 10 frames before stimulation\n",
    "        post_stim_frames = 100 # 100 frames after stimulation\n",
    "\n",
    "        roi_data = {roi: {} for roi in calcium_signals_df.columns if 'ROI' in roi}\n",
    "\n",
    "        for stim_id, stim_frame in zip(stimulation_ids, stim_frame_numbers):\n",
    "            start_idx = max(stim_frame - pre_stim_frames, 0) \n",
    "            end_idx = min(stim_frame + post_stim_frames, len(calcium_signals_df))\n",
    "\n",
    "            for roi in roi_data:\n",
    "                trial = calcium_signals_df.loc[start_idx:end_idx, roi]\n",
    "                roi_data[roi][(stim_id, stim_frame)] = trial.to_numpy()\n",
    "\n",
    "        return stim_frame_numbers, roi_data, stimulation_ids\n",
    "    \n",
    "    def extract_calcium_signals(self, session_id):\n",
    "        \"\"\"\n",
    "        Extracts calcium signals from time-series data using the saved labeled ROI mask\n",
    "        and saves the results as a CSV file in the 'processed_image_analysis_output' directory.\n",
    "\n",
    "        Parameters:\n",
    "        session_id (str): Session ID for which to perform the analysis.\n",
    "\n",
    "        Returns:\n",
    "        str: Path to the saved CSV file containing calcium signal data.\n",
    "        \"\"\"\n",
    "        processed_dir = 'processed_data/processed_image_analysis_output'\n",
    "        calcium_csv_suffix = '_calcium_signals.csv'\n",
    "\n",
    "        # Retrieve the directory path from the DataFrame\n",
    "        directory_entry = self.directory_df[self.directory_df['session_id'] == session_id]\n",
    "        if directory_entry.empty:\n",
    "            return f\"No directory entry found for session {session_id}\"\n",
    "\n",
    "        directory_path = directory_entry['directory_path'].values[0]\n",
    "\n",
    "        # Path to the saved labeled image numpy file\n",
    "        labeled_image_path = os.path.join(directory_path, processed_dir, session_id + '_labeled_image.npy')\n",
    "\n",
    "        # Verify and load the labeled image numpy file\n",
    "        if not os.path.exists(labeled_image_path):\n",
    "            return f\"Labeled image file not found for session {session_id}\"\n",
    "        labeled_image = np.load(labeled_image_path)\n",
    "\n",
    "        # Locate and load the time-series TIFF file\n",
    "        tif_files = glob.glob(os.path.join(directory_path, '*.tif'))\n",
    "        tif_files = [f for f in tif_files if 'postexport' not in f and 'labels' not in f]  # Ensure it's the correct TIFF\n",
    "        if not tif_files:\n",
    "            return f\"No time-series .tif file found in the directory for session {session_id}\"\n",
    "        time_series_path = tif_files[0]  # Assuming there's only one relevant TIFF file\n",
    "        time_series = io.imread(time_series_path)\n",
    "\n",
    "        # Initialize an array to store calcium signal data\n",
    "        num_rois = np.max(labeled_image)\n",
    "        num_frames = time_series.shape[0]\n",
    "        calcium_signals = np.zeros((num_rois, num_frames))\n",
    "\n",
    "        # Extract the signal from each ROI in each frame\n",
    "        for t in range(num_frames):\n",
    "            frame = time_series[t]\n",
    "            for roi in range(1, num_rois + 1):\n",
    "                roi_mask = labeled_image == roi\n",
    "                roi_data = frame[roi_mask]\n",
    "                calcium_signals[roi - 1, t] = np.mean(roi_data)\n",
    "\n",
    "        # Create and save the DataFrame with calcium signals\n",
    "        calcium_df = pd.DataFrame(calcium_signals.T, columns=[f\"ROI_{i}\" for i in range(1, num_rois + 1)])\n",
    "        calcium_df['Frame'] = np.arange(1, num_frames + 1)\n",
    "        csv_path = os.path.join(directory_path, processed_dir, session_id + calcium_csv_suffix)\n",
    "        calcium_df.to_csv(csv_path, index=False)\n",
    "\n",
    "        return csv_path\n",
    "    \n",
    "    def process_all_sessions_entire_recording(self, use_corrected_data=False):\n",
    "        \"\"\"\n",
    "        Processes all sessions and stores calcium signal dataframes in a dictionary.\n",
    "\n",
    "        Parameters\n",
    "        ----------\n",
    "        use_corrected_data : bool, optional\n",
    "            Whether to use corrected calcium signal data. The default is False, which uses uncorrected data.\n",
    "\n",
    "        Returns\n",
    "        -------\n",
    "        dict\n",
    "            A dictionary where each key is a session ID and the value is the corresponding calcium_signals dataframe.\n",
    "        \"\"\"\n",
    "        processed_dir = 'processed_data/processed_image_analysis_output'\n",
    "        calcium_csv_suffix = '_corrected_calcium_signals.csv' if use_corrected_data else '_calcium_signals.csv'\n",
    "        session_data = {}\n",
    "\n",
    "        for session_id in self.directory_df['session_id'].unique():\n",
    "            directory_entry = self.directory_df[self.directory_df['session_id'] == session_id]\n",
    "\n",
    "            if directory_entry.empty:\n",
    "                print(f\"No directory entry found for session {session_id}\")\n",
    "                continue  # Skip this session and proceed with the next\n",
    "\n",
    "            directory_path = directory_entry['directory_path'].values[0]\n",
    "            csv_path = os.path.join(directory_path, processed_dir, f\"{session_id}{calcium_csv_suffix}\")\n",
    "\n",
    "            if not os.path.exists(csv_path):\n",
    "                print(f\"Calcium signals file not found for session {session_id} using {'corrected' if use_corrected_data else 'uncorrected'} data\")\n",
    "                continue  # Skip this session and proceed with the next\n",
    "\n",
    "            calcium_signals_df = pd.read_csv(csv_path)\n",
    "            # Store the dataframe in the dictionary with session_id as the key\n",
    "            session_data[session_id] = calcium_signals_df\n",
    "\n",
    "        return session_data\n",
    "        \n",
    "    def calculate_responsiveness(self, all_data, pre_stim_frames=10, post_stim_frames=10, alpha=0.01, return_dataframe=False):    \n",
    "        \"\"\"\n",
    "        This function calculates and identifies responsive cells within calcium imaging data, applying statistical \n",
    "        tests to determine whether the change in signal post-stimulation is significant compared to the pre-stimulation \n",
    "        baseline. It stores detailed metrics including means, standard deviations, and p-values for each ROI across all sessions.\n",
    "\n",
    "        Parameters:\n",
    "        - all_data (dict): Nested dictionary containing the processed calcium signal data for multiple sessions, \n",
    "        structured with session IDs as top-level keys.\n",
    "        - pre_stim_frames (int): The number of frames before the stimulus used to calculate the baseline signal.\n",
    "        - post_stim_frames (int): The number of frames after the stimulus used for post-stimulus signal analysis.\n",
    "        - alpha (float): The significance level used to determine if a response is statistically significant.\n",
    "        - return_dataframe (bool): If set to True, the function also returns a pandas DataFrame containing the computed metrics.\n",
    "\n",
    "        Returns:\n",
    "        - dict: A nested dictionary containing calculated metrics for each session ID, ROI, and stimulus event. If \n",
    "        `return_dataframe` is True, it also returns a DataFrame alongside this dictionary.\n",
    "\n",
    "        The output dictionary follows a multi-level structure:\n",
    "        - Level 1 (Session Level): Keys are session IDs, and values are dictionaries containing data for each session.\n",
    "        - Level 2 (ROI Level): Within each session dictionary, keys are ROIs, and values are dictionaries with metrics for each ROI.\n",
    "        - Level 3 (Stimulus Event Level): For each ROI, keys are tuples of (stimulation_id, stim_frame_number), and values \n",
    "        are dictionaries containing the metrics calculated for each stimulus event.\n",
    "\n",
    "        Metrics included for each stimulus event:\n",
    "        - 'pre_stim_mean': Mean of the signal in the pre-stimulus period.\n",
    "        - 'pre_stim_sd': Standard deviation of the signal in the pre-stimulus period.\n",
    "        - 'post_stim_peak': Maximum signal value in the post-stimulus period (not normalized).\n",
    "        - 'post_stim_sd': Standard deviation of the signal in the post-stimulus period, excluding the peak value.\n",
    "        - 'p_value': P-value from the t-test comparing pre-stimulus and post-stimulus signals.\n",
    "        - 'is_responsive': Boolean indicating whether the ROI is considered responsive based on the p-value being below alpha.\n",
    "\n",
    "        \n",
    "        Returns:\n",
    "        dict or (dict, pd.DataFrame): A dictionary and optionally a DataFrame containing all metrics and SDs for each session ID, ROI, and stimulus.\n",
    "        \"\"\"\n",
    "        responsiveness_data = {}\n",
    "        dataframe_rows = []\n",
    "\n",
    "        for session_id, session_data in all_data.items():\n",
    "            session_responsiveness = {}\n",
    "            for roi, roi_data in session_data['roi_data'].items():\n",
    "                roi_responsiveness = {}\n",
    "                for (stim_id, stim_frame), signal_data in roi_data.items():\n",
    "                    # Validate signal_data length\n",
    "                    if signal_data.size >= (pre_stim_frames + post_stim_frames + 1):\n",
    "                        pre_stim_signal = signal_data[:pre_stim_frames]\n",
    "                        post_stim_signal = signal_data[pre_stim_frames + 1 : pre_stim_frames + 1 + post_stim_frames]\n",
    "                        \n",
    "    \n",
    "                        \n",
    "                        # New calculation for the entire array\n",
    "                        delta_f_f_full_array = (signal_data - np.mean(signal_data[:pre_stim_frames])) / np.mean(signal_data[:pre_stim_frames])\n",
    "                        \n",
    "                        \n",
    "\n",
    "                        # Calculate means and SDs\n",
    "                        pre_stim_mean = np.mean(pre_stim_signal)\n",
    "                        pre_stim_sd = np.std(pre_stim_signal)\n",
    "                        post_stim_peak = np.nanmax(post_stim_signal) if not np.isnan(np.nanmax(post_stim_signal)) else np.nan\n",
    "                        post_stim_sd = np.std(post_stim_signal[1:])  # Excluding the peak (stimulation point)\n",
    "                        post_stim_peak_index = np.nanargmax(post_stim_signal) if not np.isnan(post_stim_peak) else np.nan\n",
    "                        \n",
    "                        #calculate the median of the post_stim_signal and the median of the pre_stim_signal\n",
    "                        post_stim_median = np.median(post_stim_signal)\n",
    "                        pre_stim_median = np.median(pre_stim_signal)\n",
    "                        \n",
    "                        #calculate the mean of the post_stim_signal and the mean of the pre_stim_signal\n",
    "                        post_stim_mean = np.mean(post_stim_signal)\n",
    "                        \n",
    "                        # calculate the delta_f/f for the post_stim_signal and the pre_stim_signal and save entire array\n",
    "                        delta_f_f_post_stim = (post_stim_signal - pre_stim_mean) / pre_stim_mean\n",
    "                        \n",
    "                        # calculate the peak delta_f/f for the post_stim_signal and save the value \n",
    "                        peak_delta_f_f_post_stim = (post_stim_peak - pre_stim_mean) / pre_stim_mean\n",
    "                \n",
    "                        # Perform t-test between normalized pre-stimulus and post-stimulus signals\n",
    "                        t_stat, p_value = ttest_ind(pre_stim_signal, post_stim_signal, equal_var=False)\n",
    "\n",
    "                        # Determine responsiveness based on the p-value without explicit prior length check\n",
    "                        is_responsive = p_value < alpha if not np.isnan(p_value) else False\n",
    "                        \n",
    "                        # Time metrics calculations with safety checks\n",
    "                        half_peak_value = post_stim_peak / 2 if not np.isnan(post_stim_peak) else np.nan\n",
    "                        half_rise_index = np.where(post_stim_signal >= half_peak_value)[0][0] if np.any(post_stim_signal >= half_peak_value) else np.nan\n",
    "                        half_decay_index = np.where(post_stim_signal[post_stim_peak_index:] <= half_peak_value)[0][0] + post_stim_peak_index if post_stim_peak_index and np.any(post_stim_signal[post_stim_peak_index:] <= half_peak_value) else np.nan\n",
    "\n",
    "                        # Convert indices to milliseconds\n",
    "                        # Adjusted line with conditional to ensure a minimum of 100 ms:\n",
    "                        time_to_peak = max(100, post_stim_peak_index * 100) if not np.isnan(post_stim_peak_index) else np.nan\n",
    "                        half_rise_time = half_rise_index * 100 if not np.isnan(half_rise_index) else np.nan\n",
    "                        half_decay_time = half_decay_index * 100 if not np.isnan(half_decay_index) else np.nan\n",
    "\n",
    "                    # Save all calculated metrics\n",
    "                    roi_responsiveness[(stim_id, stim_frame)] = {\n",
    "                        'pre_stim_mean': pre_stim_mean,\n",
    "                        'pre_stim_sd': pre_stim_sd,\n",
    "                        'post_stim_peak': post_stim_peak,\n",
    "                        'post_stim_sd': post_stim_sd,\n",
    "                        'p_value': p_value,\n",
    "                        'post_stim_mean': post_stim_mean,\n",
    "                        'delta_f_f_post_stim': delta_f_f_post_stim,\n",
    "                        'pre_stim_median': pre_stim_median,\n",
    "                        'post_stim_median': post_stim_median,\n",
    "                        'peak_delta_f_f_post_stim': peak_delta_f_f_post_stim,\n",
    "                        'is_responsive': is_responsive\n",
    "                \n",
    "                    }\n",
    "\n",
    "                    # Append data for DataFrame\n",
    "                    dataframe_rows.append({\n",
    "                        'session_id': session_id,\n",
    "                        'roi': roi,\n",
    "                        'stimulation_id': stim_id,\n",
    "                        'stim_frame_number': stim_frame,\n",
    "                        'pre_stim_mean': pre_stim_mean,\n",
    "                        'pre_stim_sd': pre_stim_sd,\n",
    "                        'post_stim_peak': post_stim_peak,\n",
    "                        'post_stim_sd': post_stim_sd,\n",
    "                        'post_stim_mean': post_stim_mean,\n",
    "                        'delta_f_f_post_stim': delta_f_f_post_stim*100,\n",
    "                        'pre_stim_median': pre_stim_median,\n",
    "                        'post_stim_median': post_stim_median,\n",
    "                        'peak_delta_f_f_post_stim': peak_delta_f_f_post_stim*100,\n",
    "                        'delta_f_f_full_array': delta_f_f_full_array*100,\n",
    "                        'raw_signal': signal_data,\n",
    "                        'p_value': p_value,\n",
    "                        'time_to_peak': time_to_peak,\n",
    "                        'half_rise_time': half_rise_time,\n",
    "                        'half_decay_time': half_decay_time,\n",
    "                        'is_responsive': is_responsive\n",
    "                    })\n",
    "\n",
    "                session_responsiveness[roi] = roi_responsiveness\n",
    "            responsiveness_data[session_id] = session_responsiveness\n",
    "\n",
    "        # Create and return DataFrame if requested\n",
    "        if return_dataframe:\n",
    "            responsiveness_df = pd.DataFrame(dataframe_rows)\n",
    "            return responsiveness_data, responsiveness_df\n",
    "        else:\n",
    "            return responsiveness_data\n",
    "        \n",
    "    def filter_responsive_rois(self, all_data, responsiveness_data):\n",
    "        \"\"\"\n",
    "        Creates a new data structure similar to all_data but excludes the data for non-responsive ROIs \n",
    "        for specific stimulation IDs, maintaining only responsive ROI data.\n",
    "\n",
    "        Parameters:\n",
    "        all_data (dict): Original dictionary with the complete dataset.\n",
    "        responsiveness_data (dict): Dictionary containing responsiveness information for each ROI.\n",
    "\n",
    "        Returns:\n",
    "        dict: A new dictionary mirroring all_data's structure but excluding data for non-responsive ROIs per stimulus.\n",
    "        \"\"\"\n",
    "        filtered_data = {}\n",
    "\n",
    "        for session_id, session_content in all_data.items():\n",
    "            filtered_data[session_id] = {\n",
    "                'stim_frame_numbers': session_content['stim_frame_numbers'],\n",
    "                'roi_data': {},\n",
    "                'stimulation_ids': session_content['stimulation_ids']\n",
    "            }\n",
    "\n",
    "            for roi, roi_data in session_content['roi_data'].items():\n",
    "                filtered_roi_data = {}\n",
    "\n",
    "                for stim_key, signal_data in roi_data.items():\n",
    "                    # Include the data only if the ROI is responsive for this stimulus\n",
    "                    if responsiveness_data[session_id][roi].get(stim_key, {}).get('is_responsive', False):\n",
    "                        filtered_roi_data[stim_key] = signal_data\n",
    "                \n",
    "                # Update only if there's at least one responsive stim event for the ROI\n",
    "                if filtered_roi_data:\n",
    "                    filtered_data[session_id]['roi_data'][roi] = filtered_roi_data\n",
    "\n",
    "        return filtered_data\n",
    "    \n",
    "    def filter_responsive_rois_by_stimulation(self, session_data, responsiveness_df):\n",
    "        # Initialize a dictionary to hold the filtered dataframes\n",
    "        filtered_data_by_session = {}\n",
    "        \n",
    "        # Filter for responsive ROIs with stimulation_id == 12\n",
    "        responsive_df = responsiveness_df[\n",
    "            (responsiveness_df['is_responsive']) & \n",
    "            (responsiveness_df['stimulation_id'] == 12)\n",
    "        ]\n",
    "        \n",
    "        # Group by session_id to process each session separately\n",
    "        grouped_responsive_df = responsive_df.groupby('session_id')\n",
    "        \n",
    "        for session_id, group in grouped_responsive_df:\n",
    "            # Initialize a list to collect dataframes for this session\n",
    "            session_frames_list = []\n",
    "            \n",
    "            # Get unique ROIs for this session that are responsive\n",
    "            unique_rois = group['roi'].unique()\n",
    "            \n",
    "            # Access the session's dataframe\n",
    "            session_df = session_data.get(session_id)\n",
    "            if session_df is None:\n",
    "                print(f\"Session ID {session_id} not found in session_data.\")\n",
    "                continue\n",
    "            \n",
    "            # Filter the session dataframe for responsive ROIs\n",
    "            for roi in unique_rois:\n",
    "                # Extract the ROI number and construct the column name\n",
    "                roi_number = re.search(r'\\d+', roi)\n",
    "                if not roi_number:\n",
    "                    print(f\"ROI format is incorrect for {roi}\")\n",
    "                    continue\n",
    "                roi_column_name = f'ROI_{roi_number.group()}'\n",
    "                \n",
    "                if roi_column_name in session_df.columns:\n",
    "                    # Access the entire column for the responsive ROI\n",
    "                    roi_frames_df = session_df[[roi_column_name]].copy()\n",
    "                    \n",
    "                    # Add the ROI frames to the list for this session\n",
    "                    session_frames_list.append(roi_frames_df)\n",
    "                else:\n",
    "                    print(f\"Column {roi_column_name} not found in session dataframe for session_id {session_id}.\")\n",
    "            \n",
    "            # Combine the frames for the session into a single dataframe\n",
    "            if session_frames_list:\n",
    "                combined_frames_df = pd.concat(session_frames_list, axis=1)\n",
    "                # Store the filtered data in the dictionary using the session_id as the key\n",
    "                filtered_data_by_session[session_id] = combined_frames_df\n",
    "\n",
    "        return filtered_data_by_session\n",
    "    \n",
    "    def plot_session_time_series(self, filtered_data_by_session):\n",
    "        for session_id, session_df in filtered_data_by_session.items():\n",
    "            # Calculate the nanmean signal across ROIs for the session\n",
    "            median_signal = session_df.median(axis=1, skipna=True)\n",
    "            \n",
    "            # Setup the plot\n",
    "            plt.figure(figsize=(10, 6))\n",
    "            plt.title(f\"Session ID: {session_id} Entire Recording \")\n",
    "            plt.xlabel(\"Time (frames)\")\n",
    "            plt.ylabel(\"Signal (a.u.)\") \n",
    "            \n",
    "            # Plot each ROI time series in grey\n",
    "            for column in session_df.columns:\n",
    "                plt.plot(session_df.index, session_df[column], color='lightgrey', alpha=0.5, lw=0.5)\n",
    "            \n",
    "            # Plot the nanmean signal in blue\n",
    "            plt.plot(session_df.index, median_signal, color='blue', label='Median Signal')\n",
    "            \n",
    "            # Add legend\n",
    "            plt.legend()\n",
    "            \n",
    "            # Show the plot\n",
    "            plt.show()\n",
    "\n",
    "    def process_biolumi_calcium_signal(self, session_id, directory_df):\n",
    "        processed_dir = 'processed_data/processed_image_analysis_output'\n",
    "        calcium_csv_suffix = '_calcium_signals.csv'\n",
    "        directory_entry = directory_df[directory_df['session_id'] == session_id]\n",
    "\n",
    "        # Check if the directory_entry is empty\n",
    "        if directory_entry.empty:\n",
    "            print(f\"No directory entry found for session {session_id}. Please check the session_id.\")\n",
    "            return None\n",
    "        \n",
    "        directory_path = directory_entry['directory_path'].values[0]\n",
    "        csv_path = os.path.join(directory_path, processed_dir, str(session_id) + calcium_csv_suffix)\n",
    "\n",
    "        \n",
    "        if not os.path.exists(csv_path):\n",
    "            print(f\"Calcium signals file not found for session {session_id}\")\n",
    "            return None\n",
    "\n",
    "        calcium_signals_df = pd.read_csv(csv_path) # import the calcium signals csv file\n",
    "        \n",
    "        # Correct the \"Dark signal\" for each ROI\n",
    "        for roi in calcium_signals_df.columns:\n",
    "            if 'ROI' in roi:  # Assuming ROI columns are prefixed with 'ROI'\n",
    "                dark_signal_median = calcium_signals_df[roi][:300].median() # Calculate the median of the first 100 frames\n",
    "                calcium_signals_df[roi] = calcium_signals_df[roi] - dark_signal_median\n",
    "                calcium_signals_df.loc[calcium_signals_df[roi] < 0, roi] = np.nan\n",
    "        \n",
    "        \n",
    "        #save the corrected calcium signals to a new csv file in the same directory\n",
    "        corrected_csv_path = os.path.join(directory_path, processed_dir, str(session_id) + '_corrected' + calcium_csv_suffix)\n",
    "        calcium_signals_df.to_csv(corrected_csv_path, index=False)\n",
    "        \n",
    "        return calcium_signals_df\n",
    "\n",
    "    def process_all_sessions_biolumi(self):\n",
    "        unique_sessions = self.directory_df['session_id'].unique()\n",
    "        for session_id in unique_sessions:\n",
    "            print(f\"Processing session ID: {session_id}\")\n",
    "            self.process_biolumi_calcium_signal(session_id, self.directory_df)\n",
    "            print(f\"Completed processing for session ID: {session_id}\")\n",
    "            \n",
    "    def plot_stim_responsiveness(self, df, stim_ids=None, only_responsive=False):\n",
    "        \"\"\"\n",
    "        Plots the delta F/F response for given stimulation IDs.\n",
    "\n",
    "        Parameters:\n",
    "        - df (pd.DataFrame): DataFrame containing the responsiveness data.\n",
    "        - stim_ids (list): List of stimulation IDs to plot. If None, all unique IDs in the DataFrame will be used.\n",
    "\n",
    "        Returns:\n",
    "        - fig (plt.Figure): The created figure.\n",
    "        \"\"\"\n",
    "        \n",
    "        # Filter for responsive units if required\n",
    "        if only_responsive:\n",
    "            df = df[df['is_responsive'] == True]\n",
    "        \n",
    "        # If stim_ids is not provided, get the unique IDs from the DataFrame and sort them\n",
    "        if stim_ids is None:\n",
    "            stim_ids = sorted(df['stimulation_id'].unique())\n",
    "        else:\n",
    "            # If stim_ids is provided, ensure it is sorted\n",
    "            stim_ids = sorted(stim_ids)\n",
    "        \n",
    "        # Create a figure and axes with subplots\n",
    "        n_stims = len(stim_ids)\n",
    "        fig, axes = plt.subplots(1, n_stims, figsize=(20, 10), sharey=True)\n",
    "        \n",
    "        # Adjust if we only have one subplot to make sure 'axes' is iterable\n",
    "        if n_stims == 1:\n",
    "            axes = [axes]\n",
    "\n",
    "        # Iterate through each stimulation ID and plot\n",
    "        for ax, stim_id in zip(axes, stim_ids):\n",
    "            stim_df = df[df['stimulation_id'] == stim_id]\n",
    "\n",
    "            # Assuming 'delta_f_f_post_stim' contains lists, we will need to extract them\n",
    "            delta_f_f_values = np.vstack(stim_df['delta_f_f_full_array'].values)\n",
    "            print(delta_f_f_values.shape)\n",
    "            \n",
    "            # Calculate mean and standard deviation\n",
    "            mean_response = np.nanmean(delta_f_f_values, axis=0)\n",
    "            std_response = np.nanstd(delta_f_f_values, axis=0)\n",
    "\n",
    "            # Time vector assuming each frame corresponds to 1 unit of time\n",
    "            time_vector = np.arange(len(mean_response))\n",
    "            \n",
    "            # Plot the mean response and fill the standard deviation\n",
    "            ax.plot(time_vector, mean_response, label=f'Stim ID {stim_id}')\n",
    "            ax.fill_between(time_vector, mean_response - std_response, mean_response + std_response, alpha=0.2)\n",
    "            \n",
    "            ax.set_title(f'Stim ID {stim_id}')\n",
    "            ax.set_xlabel('Time (relative to stimulus)').set_visible(False)\n",
    "            ax.set_ylabel('F/F')\n",
    "            ax.legend()\n",
    "            \n",
    "    def plot_stim_responsiveness(self, df, stim_ids=None, include='both', y_lim=None, x_lim=None, mean_color='black', figsize=(15, 5)):\n",
    "        \"\"\"\n",
    "        Plots the delta F/F response for given stimulation IDs, filtering based on responsiveness if specified.\n",
    "        Individual replicates are plotted in light grey, while the mean response is plotted in a user-defined color.\n",
    "        Adds a red dotted line at the stimulation onset, considering the user-defined x-axis limits.\n",
    "        Prints the number of responsive and unresponsive units for each stimulus ID on the plot.\n",
    "        User can define the y-axis limits, x-axis limits, and the figure size.\n",
    "\n",
    "        Parameters:\n",
    "        - df (pd.DataFrame): DataFrame containing the responsiveness data.\n",
    "        - stim_ids (list): List of stimulation IDs to plot. If None, all unique IDs in the DataFrame will be used.\n",
    "        - include (str): Can be 'responsive', 'non-responsive', or 'both' to filter units based on responsiveness.\n",
    "        - y_lim (tuple): A tuple of (min, max) for y-axis limits. If None, limits are automatically determined.\n",
    "        - x_lim (tuple): A tuple of (min, max) for x-axis limits. If None, defaults to the entire range of the data.\n",
    "        - mean_color (str): Color for the mean response line.\n",
    "        - figsize (tuple): Figure dimension as (width, height).\n",
    "\n",
    "        Returns:\n",
    "        - fig (plt.Figure): The created figure.\n",
    "        \"\"\"\n",
    "\n",
    "        # If stim_ids is not provided, get the unique IDs from the DataFrame and sort them\n",
    "        if stim_ids is None:\n",
    "            stim_ids = sorted(df['stimulation_id'].unique())\n",
    "        else:\n",
    "            stim_ids = sorted(stim_ids)\n",
    "        \n",
    "        # Adjust the x-axis to align with the pre-stimulus, stimulus onset, and post-stimulus periods\n",
    "        stim_index = 9  # Index at which stimulation occurs\n",
    "        total_frames = 111  # Total number of frames, including pre-stim, stim, and post-stim\n",
    "        sampling_interval = 100  # Time per index in ms at 10Hz sampling rate\n",
    "\n",
    "        # Create a figure and axes with subplots\n",
    "        n_stims = len(stim_ids)\n",
    "        fig, axes = plt.subplots(1, n_stims, figsize=figsize, sharey=True)\n",
    "\n",
    "        # Adjust if we only have one subplot to make sure 'axes' is iterable\n",
    "        if n_stims == 1:\n",
    "            axes = [axes]\n",
    "\n",
    "        # Set the y-axis limit if specified\n",
    "        if y_lim:\n",
    "            plt.setp(axes, ylim=y_lim)\n",
    "\n",
    "        # Set the x-axis limit if specified\n",
    "        if x_lim is not None:\n",
    "            new_x_lim = (x_lim[0] * sampling_interval, x_lim[1] * sampling_interval)\n",
    "            plt.setp(axes, xlim=new_x_lim)\n",
    "\n",
    "\n",
    "\n",
    "        for ax, stim_id in zip(axes, stim_ids):\n",
    "            # Filter the DataFrame based on the current stim_id\n",
    "            stim_df = df[df['stimulation_id'] == stim_id]\n",
    "            if include != 'both':\n",
    "                stim_df = stim_df[stim_df['is_responsive'] == (include == 'responsive')]\n",
    "\n",
    "            # Get the delta_f_f_full_array values for plotting\n",
    "            delta_f_f_values = np.vstack(stim_df['delta_f_f_full_array'].values)\n",
    "\n",
    "            # Calculate the time vector considering the stimulation index\n",
    "            time_vector = np.arange(-stim_index, total_frames - stim_index) * sampling_interval\n",
    "\n",
    "            # Plot individual replicates in light grey\n",
    "            for trace in delta_f_f_values:\n",
    "                ax.plot(time_vector, trace, color='lightgrey', linewidth=0.5)\n",
    "\n",
    "            # Calculate mean response and plot in the specified mean_color\n",
    "            mean_response = np.nanmedian(delta_f_f_values, axis=0)\n",
    "            ax.plot(time_vector, mean_response, color=mean_color, label=f'Stim ID {stim_id}')\n",
    "\n",
    "            # Add vertical line at stimulation onset if it's within the x-axis limits\n",
    "            if x_lim is None or (0 >= x_lim[0] and 0 <= x_lim[1]):\n",
    "                ax.axvline(x=0, color='red', linestyle='--', label='Stimulation Onset')\n",
    "\n",
    "            # Count and display the number of responsive and unresponsive units for this stim_id\n",
    "            num_responsive = len(stim_df[stim_df['is_responsive'] == True])\n",
    "            num_unresponsive = len(stim_df[stim_df['is_responsive'] == False])\n",
    "            info_text = f'Responsive: {num_responsive}'\n",
    "            ax.text(0.95, 0.95, info_text, transform=ax.transAxes, fontsize=9,\n",
    "                    verticalalignment='top', horizontalalignment='right',\n",
    "                    bbox=dict(facecolor='white', alpha=0.5, edgecolor='black', boxstyle='round'))\n",
    "\n",
    "            # Set titles and labels\n",
    "            ax.set_title(f'Stim ID {stim_id}')\n",
    "            ax.set_xlabel('ms', fontsize=24)\n",
    "            ax.set_ylabel('F/F$_o$ (%)', fontsize=24)\n",
    "            #make y-axis labels larger\n",
    "            ax.tick_params(axis='y', labelsize=18)\n",
    "            ax.tick_params(axis='x', labelsize=18)\n",
    "            ax.legend().remove()\n",
    "\n",
    "        # To prevent x-axis labels from overlapping\n",
    "        plt.tight_layout()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class SensorDataPlotter:\n",
    "    def __init__(self, data_frames, sensor_names, sensor_box_colors, sensor_strip_colors):\n",
    "        \"\"\"\n",
    "        Initialize the object with a list of data frames, corresponding sensor names, and specific colors for each sensor.\n",
    "        :param data_frames: List of pandas DataFrames containing the sensor data.\n",
    "        :param sensor_names: List of strings representing the names of the sensors.\n",
    "        :param sensor_box_colors: Dictionary mapping sensor names to boxplot colors.\n",
    "        :param sensor_strip_colors: Dictionary mapping sensor names to stripplot colors.\n",
    "        \"\"\"\n",
    "        self.data_frames = data_frames\n",
    "        self.sensor_names = sensor_names\n",
    "        self.sensor_box_colors = sensor_box_colors\n",
    "        self.sensor_strip_colors = sensor_strip_colors\n",
    "        self.combined_df = None\n",
    "        \n",
    "    def prepare_for_plotting(self, df_column_name):\n",
    "        \"\"\"\n",
    "        Prepares a single dataframe suitable for plotting from multiple sensor dataframes.\n",
    "        :param df_column_name: The name of the column to use for the value in the plot.\n",
    "        \"\"\"\n",
    "        # Add a 'sensor_name' column to each DataFrame and concatenate them into a single DataFrame\n",
    "        frames = []\n",
    "        for df, name in zip(self.data_frames, self.sensor_names):\n",
    "            df = df.copy()  # Make a copy to avoid modifying the original DataFrame\n",
    "            df['sensor_name'] = name\n",
    "            df['value'] = df[df_column_name]\n",
    "            frames.append(df)\n",
    "        # Concatenate all Dataframes into a single DataFrame\n",
    "        self.combined_df = pd.concat(frames, ignore_index=True)\n",
    "        \n",
    "        #filter the self.combined_df to only include responsive ROIs when is_responsive is True based on if the entry is True or False\n",
    "        self.combined_df = self.combined_df[self.combined_df['is_responsive'] == True]\n",
    "        \n",
    "        # Ensure the value column is present and has the correct data type for plotting\n",
    "        if df_column_name not in self.combined_df.columns:\n",
    "            raise ValueError(f\"The column '{df_column_name}' does not exist in the DataFrame.\") # Raise an error if the column does not exist\n",
    "        self.combined_df[df_column_name] = pd.to_numeric(self.combined_df[df_column_name], errors='coerce') # Convert to numeric where eoors are coerced which means invalid parsing will be set as NaN\n",
    "    \n",
    "    def plot_data(self, df_column_name, selected_stim_ids, box_width=.8, strip_size=3, fig_size=(12, 8), dpi=300):\n",
    "        \"\"\"\n",
    "        Plots the data using boxplot and stripplot for selected stimulation IDs.\n",
    "        :param df_column_name: The name of the column to use for the value in the plot.\n",
    "        :param selected_stim_ids: List of stimulation IDs to plot. If None, plot all.\n",
    "        :param box_width: The width of the boxplots.\n",
    "        :param strip_size: The size of the points in the stripplots.\n",
    "        :param fig_size: Tuple representing the figure size (width, height) in inches.\n",
    "        :param dpi: The resolution in dots per inch.\n",
    "        \"\"\"\n",
    "        \n",
    "        ### check varuable types and raise errors if necessary ###\n",
    "        ##########################################################\n",
    "       \n",
    "        df_column_name = str(df_column_name)\n",
    "        \n",
    "        if selected_stim_ids is not None:\n",
    "            if not isinstance(selected_stim_ids, list):\n",
    "                raise ValueError(\"The selected_stim_ids parameter must be a list of stimulation IDs.\")\n",
    "            if not all(isinstance(stim_id, int) for stim_id in selected_stim_ids):\n",
    "                raise ValueError(\"All elements in the selected_stim_ids list must be integers.\")\n",
    "            \n",
    "        if not isinstance(box_width, (int, float)):\n",
    "            raise ValueError(\"The box_width parameter must be an integer or float.\")\n",
    "        if not isinstance(strip_size, (int, float)):\n",
    "            raise ValueError(\"The strip_size parameter must be an integer or float.\")\n",
    "        if not isinstance(fig_size, tuple) or len(fig_size) != 2:\n",
    "            raise ValueError(\"The fig_size parameter must be a tuple of two integers.\")\n",
    "        if not all(isinstance(val, (int, float)) for val in fig_size):\n",
    "            raise ValueError(\"The fig_size parameter must contain only integers or floats.\")\n",
    "        if not isinstance(dpi, int):\n",
    "            raise ValueError(\"The dpi parameter must be an integer.\")\n",
    "        \n",
    "    \n",
    "        \n",
    "        ### import, and filter the combined_df for the selected stimulation IDs if provided###\n",
    "        #####################################################################################\n",
    "       \n",
    "        #check if the combined_df is None and if so, call the prepare_for_plotting method \n",
    "        if self.combined_df is None:\n",
    "            self.prepare_for_plotting(df_column_name)\n",
    "       \n",
    "            \n",
    "        # Filter the combined DataFrame for the selected stimulation IDs if provided\n",
    "        if selected_stim_ids is not None:\n",
    "            self.combined_df = self.combined_df[self.combined_df['stimulation_id'].isin(selected_stim_ids)]\n",
    "            \n",
    "        # Raise an error if no data is available after filtering\n",
    "        if self.combined_df.empty:\n",
    "            raise ValueError(\"No data available for the selected stimulation IDs.\")\n",
    "        \n",
    "\n",
    "        \n",
    "        ### set up the boxplot and stripplot properties ###\n",
    "        ####################################################\n",
    "        \n",
    "        # Boxplot properties will have black edges and lines\n",
    "        boxprops = {'edgecolor': 'k', 'linewidth': 1.5}\n",
    "        lineprops = {'color': 'k', 'linewidth': 1.5}\n",
    "        \n",
    "        boxplot_kwargs = {\n",
    "            'boxprops': boxprops, 'medianprops': lineprops,\n",
    "            'whiskerprops': lineprops, 'capprops': lineprops,\n",
    "            'width': box_width, 'palette': self.sensor_box_colors,\n",
    "            'hue_order': self.sensor_names\n",
    "        }\n",
    "\n",
    "        # Stripplot properties\n",
    "        stripplot_kwargs = {\n",
    "            'linewidth': 0.1, 'size': strip_size, 'alpha': 0.3,\n",
    "            'palette': self.sensor_strip_colors, 'hue_order': self.sensor_names\n",
    "        }\n",
    "        \n",
    "        # Plotting with specified figure size and resolution\n",
    "        plt.figure(figsize=fig_size, dpi=dpi)\n",
    "        ax = plt.subplot()\n",
    "\n",
    "        sns.stripplot(\n",
    "            x='stimulation_id', y=df_column_name, hue='sensor_name',\n",
    "            data=self.combined_df, ax=ax, jitter=0.3, dodge=True,\n",
    "            **stripplot_kwargs\n",
    "        )\n",
    "        \n",
    "        ## error bars on the boxplot are the 95% confidence interval\n",
    "        sns.boxplot(\n",
    "            x='stimulation_id', y=df_column_name, hue='sensor_name',\n",
    "            data=self.combined_df, ax=ax, fliersize=0,\n",
    "            **boxplot_kwargs\n",
    "        )\n",
    "        \n",
    "        ### set the axis labels and ticks properties ### \n",
    "        ################################################\n",
    "            \n",
    "        # Set the font size of the x-axis and y-axis labels \n",
    "        ax.set_xlabel('Stimulation ID', fontsize=18)\n",
    "        ax.set_ylabel(df_column_name, fontsize=18)\n",
    "        \n",
    "        # Set the font size of the x-axis and y-axis ticks\n",
    "        ax.tick_params(axis='x', labelsize=24)\n",
    "        ax.tick_params(axis='y', labelsize=24)\n",
    "        ax.legend_.remove()\n",
    "        \n",
    "        #set the font to arial and the font size to 24\n",
    "        plt.rcParams['font.sans-serif'] = 'Arial'\n",
    "        plt.tight_layout()  # Adjust layout to fit legend#\n",
    "        plt.show()\n",
    "\n",
    "    def plot_mean_with_error(self, df_column_name, error_type='SEM', selected_stim_ids=None, xlim=None, ylim= None, fig_size=(8, 6), dpi=300):\n",
    "        \"\"\"\n",
    "        Plots the mean values with error bars for selected stimulation IDs across sensors, using consistent colors.\n",
    "        :param df_column_name: The name of the column to use for the value in the plot.\n",
    "        :param error_type: The type of error to display ('SD' for Standard Deviation or 'SEM' for Standard Error of the Mean).\n",
    "        :param selected_stim_ids: List of stimulation IDs to plot. If None, plot all.\n",
    "        :param fig_size: Tuple representing the figure size (width, height) in inches.\n",
    "        :param dpi: The resolution in dots per inch.\n",
    "        \"\"\"\n",
    "        if self.combined_df is None:\n",
    "            self.prepare_for_plotting(df_column_name)\n",
    "        \n",
    "        # Filter for selected stimulation IDs if provided\n",
    "        if selected_stim_ids is not None:\n",
    "            plot_df = self.combined_df[self.combined_df['stimulation_id'].isin(selected_stim_ids)]\n",
    "        else:\n",
    "            plot_df = self.combined_df\n",
    "\n",
    "        plt.figure(figsize=fig_size, dpi=dpi)\n",
    "        ax = plt.subplot()\n",
    "        \n",
    "        \n",
    "\n",
    "        # Plot the mean with error bars for each sensor\n",
    "        for sensor_name in self.sensor_names:\n",
    "            sensor_data = plot_df[plot_df['sensor_name'] == sensor_name]\n",
    "            means = sensor_data.groupby('stimulation_id')[df_column_name].mean()\n",
    "            errors = sensor_data.groupby('stimulation_id')[df_column_name].std() if error_type == 'SD' else sensor_data.groupby('stimulation_id')[df_column_name].sem()\n",
    "            \n",
    "            ax.errorbar(means.index, means, yerr=errors, label=sensor_name,\n",
    "                        fmt='-o', capsize=5, color=self.sensor_box_colors[sensor_name])\n",
    "        \n",
    "        # Set the font size of the x-axis and y-axis labels \n",
    "        ax.set_xlabel('Stimulation ID', fontsize=18)\n",
    "        ax.set_ylabel(df_column_name, fontsize=18)\n",
    "        \n",
    "        # Set the font size of the x-axis and y-axis ticks\n",
    "        ax.tick_params(axis='x', labelsize=24)\n",
    "        ax.tick_params(axis='y', labelsize=24)\n",
    "        \n",
    "        ax.set_title('Mean ' + df_column_name + ' by Stimulation ID across Sensors', fontsize=14)\n",
    "        ax.legend(title='Sensor', loc='upper left')\n",
    "                # Set custom axis limits if provided\n",
    "        if xlim:\n",
    "            plt.xlim(xlim)\n",
    "        if ylim:\n",
    "            plt.ylim(ylim)\n",
    "            \n",
    "        plt.tight_layout()\n",
    "        plt.show()\n",
    "                \n",
    "    def plot_time_series(self, full_array_column, selected_stim_ids=None, fig_size=(10, 8), dpi=300):\n",
    "        \"\"\"\n",
    "        Plots time series data for selected stimulation IDs for each sensor separately.\n",
    "        :param full_array_column: The name of the column with time series data.\n",
    "        :param selected_stim_ids: List of stimulation IDs to plot. If None, plot all available.\n",
    "        :param fig_size: Tuple representing the figure size of each subplot.\n",
    "        :param dpi: The resolution in dots per inch.\n",
    "        \"\"\"\n",
    "        if self.combined_df is None:\n",
    "            raise ValueError(\"Data has not been prepared for plotting. Call prepare_for_plotting first.\")\n",
    "        \n",
    "        # Get unique stimulation IDs to plot\n",
    "        stim_ids = selected_stim_ids if selected_stim_ids is not None else self.combined_df['stimulation_id'].unique()\n",
    "        num_stim_ids = len(stim_ids)\n",
    "        num_sensors = len(self.sensor_names)\n",
    "        \n",
    "        # Create a figure with subplots for each sensor and stimulation ID\n",
    "        fig, axes = plt.subplots(num_sensors, num_stim_ids, figsize=(fig_size[0] * num_stim_ids, fig_size[1] * num_sensors), dpi=dpi, sharey=True)\n",
    "\n",
    "        if num_sensors == 1 or num_stim_ids == 1:  # If there's only one sensor or one stim ID, axes will not be a 2D array\n",
    "            axes = np.array(axes).reshape(num_sensors, -1)\n",
    "\n",
    "        for row_idx, sensor_name in enumerate(self.sensor_names):\n",
    "            for col_idx, stim_id in enumerate(stim_ids):\n",
    "                ax = axes[row_idx, col_idx]\n",
    "                sensor_stim_data = self.combined_df[(self.combined_df['sensor_name'] == sensor_name) & (self.combined_df['stimulation_id'] == stim_id)]\n",
    "                \n",
    "                if not sensor_stim_data.empty:\n",
    "                    sample_size =  len(sensor_stim_data.iloc[0][full_array_column])\n",
    "                    time_vector = (np.arange(sample_size) - 10) * 100  # Adjust time_vector for 100 ms intervals\n",
    "\n",
    "                    # Plot all individual responses in grey using the time_vector\n",
    "                    for _, row in sensor_stim_data.iterrows():\n",
    "                        ax.plot(time_vector, row[full_array_column], color='gainsboro', alpha=0.3)\n",
    "\n",
    "                    # Calculate and plot the median response in the sensor's color\n",
    "                    median_response = np.nanmedian([row[full_array_column] for _, row in sensor_stim_data.iterrows()], axis=0)\n",
    "                    ax.plot(time_vector, median_response, color=self.sensor_box_colors[sensor_name])\n",
    "                    \n",
    "\n",
    "                ax.set_title(f'Stim ID {stim_id} - {sensor_name}', fontsize=14)\n",
    "                ax.set_xlabel('Time (ms)', fontsize=18)\n",
    "                if col_idx == 0:\n",
    "                    ax.set_ylabel('F/F', fontsize=18)\n",
    "                ax.tick_params(axis='x', labelsize=24)\n",
    "                ax.tick_params(axis='y', labelsize=24)\n",
    "  \n",
    "\n",
    "        plt.tight_layout()\n",
    "        plt.rcParams['font.sans-serif'] = 'Arial'\n",
    "        plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "project_folder = '/Volumes/MannySSD/cablam_imaging/raw_data_template' #path to the folder containing the raw data to be analyzed (i.e. the folder containing the folders for each experiment)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Section 1 --preparing all the data and directories. Do this once with all the data \n",
    "### run this section of code before running the cablam and gcamp8 code instances to avoid errors\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "analysis = ImageAnalysis(project_folder) #initialize the ImageAnalysis class with the project folder\n",
    "analysis.expand_directory_df() #expand the directory DataFrame to include sensor type, session ID, stimulation IDs, and stimulation frame numbers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "analysis.add_tiff_dimensions() #add the dimensions of the tif files to the directory DataFrame"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### this will create the directories and save the max projection images for each session"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "results = analysis.analyze_all_sessions(analysis.analyze_session_max_projection)\n",
    "\n",
    "# Output the results variable to confirm the max projection images were saved\n",
    "for session_id, result_path in results.items():\n",
    "    if isinstance(result_path, str):\n",
    "        print(f\"Session ID {session_id}: Max projection image saved at {result_path}\")\n",
    "    else:\n",
    "        print(f\"Session ID {session_id}: {result_path}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "At this point add your manual ROIs .tif file of handdrawn ROIs to the corresponding 'processed_image_analysis_output' directory. \n",
    "\n",
    "Drag and drop the 'labels_postexport.tif' file into the 'processed_image_analysis_output' that was created in the previous step to the matching sensor found in 'manual_mask_for_cablam' and 'manual_mask_for_gcamp' folders. Ensure the .tif files have the same matching xy pixel size to ensure the correct aligmen to the .tif calcium movies. \n",
    "\n",
    "The code assumes the manual/ML generated masks are called 'labels_postexport.tif' and extracts this files itteratively for every unique session ID "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#extract calcium signals for all sessions in the directory_df, confirms the location of the saved calcium signals and the location of the saved calcium signals\n",
    "all_results = analysis.analyze_all_calcium_signals()\n",
    "\n",
    "for session_id, csv_path in all_results.items():\n",
    "    if isinstance(csv_path, str):\n",
    "        print(f\"Session {session_id} - Calcium signals saved at: {csv_path}\")\n",
    "    else:\n",
    "        print(f\"Session {session_id} - Error: {csv_path}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Section 2: Analyzing Image Data for Multiple Sensor Types. \n",
    "### Section 2a: once the ImageAnalysis class has been initialized at least once for all files and directory DataFrame has been expanded to include the sensor type, session ID, stimulation IDs, and stimulation frame numbers, we can filter the directory DataFrame to analyze image data for specific sensor types. In this example, we will analyze image data for two sensor types: gcamp8 and cablam.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#create an instance of the ImageAnalysis class for each sensor type: gcamp8 and cablam\n",
    "### cablam analysis ###\n",
    "analysis_cablam1x = ImageAnalysis(project_folder)\n",
    "analysis_cablam1x.expand_directory_df() #expand the directory_df to include the sensor_type, session_id, stimulation_ids, and stimulation_frame_number\n",
    "#filter the directory_df to only include the rows where the sensor_type is 'cablam' and the directory_name contains '1xfz'\n",
    "analysis_cablam1x.directory_df = analysis_cablam1x.directory_df[(analysis_cablam1x.directory_df['sensor_type'] == 'cablam') & (analysis_cablam1x.directory_df['directory_name'].str.contains('1xfz'))]\n",
    "analysis_cablam1x.directory_df "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "### gcamp8 analysis ###\n",
    "analysis_gcamp8 = ImageAnalysis(project_folder)\n",
    "analysis_gcamp8.expand_directory_df() #expand the directory_df to include the sensor_type, session_id, stimulation_ids, and stimulation_frame_number\n",
    "#filter the directory_df to only include the rows where the sensor_type is 'gcamp8'\n",
    "analysis_gcamp8.directory_df = analysis_gcamp8.directory_df[(analysis_gcamp8.directory_df['sensor_type'] == 'gcamp8')]\n",
    "analysis_gcamp8.directory_df"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Section 2b.1: you must use corrected_data as False the first run through if this is the first time running the process_all_sessions method"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "all_data_gcamp8 = analysis_gcamp8.process_all_sessions(use_corrected_data=False)\n",
    "all_data_cablam1x = analysis_cablam1x.process_all_sessions(use_corrected_data=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### let see what the all_data_gcamp8 looks likes "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for session_id, session_data in all_data_gcamp8.items():\n",
    "    print(f\"Session ID: {session_id}\")\n",
    "    print(f\"Stimulation Frame Numbers: {session_data['stim_frame_numbers']}\")\n",
    "    print(f\"Stimulation IDs: {session_data['stimulation_ids']}\")\n",
    "    for roi, roi_data in session_data['roi_data'].items():\n",
    "        print(f\"ROI: {roi}\")\n",
    "        for key, value in roi_data.items():\n",
    "            print(f\"Stimulation ID, Frame Number tuple: {key}\")\n",
    "            print(f\"Data: {value}\")\n",
    "    print(\"\\n\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Section 2b.2: once you ran process_all_sessions once, you can now implement the median substraction method create a corrected CSV files via the process_biolumi_calcium_signal method "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "analysis_cablam1x.process_all_sessions_biolumi() #now create the corrected calcium signals for the cablam1x data and save the csv files"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Section 2b.3: now you can create the data needed for plotting and downstream analysis "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "all_data_cablam1x = analysis_cablam1x.process_all_sessions(use_corrected_data=True) # reimport the data with the corrected calcium signals if the corrected data is True \n",
    "all_data_cablam1x_session_data = analysis_cablam1x.process_all_sessions_entire_recording(use_corrected_data=True)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "all_data_gcamp8_session_data = analysis_gcamp8.process_all_sessions_entire_recording(use_corrected_data=False) #always keep tihs false because the gcamp8 data has not been corrected"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Section 3: Calculate responsiveness to generate the dictionary and dfs for each sensor"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Section 3a - Define responsive ROIs first and create necessary variables: the output of calculate_responsiveness are a the data in dictionary or dataframe format which has all the session ID in one place"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "responsiveness_data_gcamp8, responsiveness_df_gcamp8 = analysis_gcamp8.calculate_responsiveness(all_data_gcamp8, return_dataframe=True)\n",
    "responsiveness_data_cablam1x, responsiveness_df_cablam1x = analysis_cablam1x.calculate_responsiveness(all_data_cablam1x, return_dataframe=True)\n",
    "responsiveness_df_cablam1x"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Section 3b.1 - filter data to remove non responive neurons using the dictionary as the input "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "filtered_data_gcamp8 = analysis_gcamp8.filter_responsive_rois(all_data_gcamp8, responsiveness_data_gcamp8)\n",
    "filtered_data_cablam1x = analysis_cablam1x.filter_responsive_rois(all_data_cablam1x, responsiveness_data_cablam1x)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Section 3b.2 - filter data to remove non responive neurons using the dataframe as the input "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "gcamp8_filtered_responsive_rois = analysis_gcamp8.filter_responsive_rois_by_stimulation(all_data_gcamp8_session_data, responsiveness_df_gcamp8)\n",
    "cablam_filtered_responsive_rois = analysis_cablam1x.filter_responsive_rois_by_stimulation(all_data_cablam1x_session_data, responsiveness_df_cablam1x)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# At this point, you can now use flexible plotting functions/methods"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#plots the time series data for  ROIs for each session\n",
    "analysis_gcamp8.plot_session_time_series(gcamp8_filtered_responsive_rois)\n",
    "analysis_cablam1x.plot_session_time_series(cablam_filtered_responsive_rois)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "analysis_cablam1x.plot_stim_responsiveness(\n",
    "    df=responsiveness_df_cablam1x,\n",
    "    include='responsive',\n",
    "    y_lim=None,\n",
    "    x_lim=(-10, 100),\n",
    "    mean_color='red',\n",
    "    figsize=(20, 6)\n",
    ")\n",
    "\n",
    "analysis_gcamp8.plot_stim_responsiveness(\n",
    "    df=responsiveness_df_gcamp8,\n",
    "    include='responsive',\n",
    "    y_lim=None,\n",
    "    x_lim=(-10, 100),\n",
    "    mean_color='black',\n",
    "    figsize=(20, 6)\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Using the SensorDataPlotter class methods "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Compare two sensors "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Sensor names\n",
    "sensor_names_cablamvsgcamp = ['CaBLAM1x', 'GCaMP8s']\n",
    "\n",
    "# Dictionaries for sensor colors (boxplot and stripplot)\n",
    "sensor_box_colors2 = {\n",
    "    'CaBLAM1x': '#ccccff',   # Light blue\n",
    "    'GCaMP8s': '#d3d3d3'   # Light grey\n",
    "}\n",
    "\n",
    "sensor_strip_colors2 = {\n",
    "    'CaBLAM1x': '#0000ff',   # Dark blue\n",
    "    'GCaMP8s': '#808080'   # Dark grey\n",
    "}\n",
    "# Initialize the SensorDataPlotter object\n",
    "cablamvsgcamp_plotter = SensorDataPlotter(\n",
    "    data_frames=[responsiveness_df_cablam1x, responsiveness_df_gcamp8],\n",
    "    sensor_names=sensor_names_cablamvsgcamp,\n",
    "    sensor_box_colors=sensor_box_colors2,\n",
    "    sensor_strip_colors=sensor_strip_colors2\n",
    ") \n",
    "\n",
    "cablamvsgcamp_plotter.plot_data('peak_delta_f_f_post_stim',selected_stim_ids=[12, 36, 60, 120, 480])\n",
    "cablamvsgcamp_plotter.plot_data('time_to_peak',selected_stim_ids=[12, 36, 60, 120, 480])\n",
    "\n",
    "cablamvsgcamp_plotter.plot_mean_with_error('peak_delta_f_f_post_stim', error_type='SEM' ,selected_stim_ids=[12, 36, 60, 120, 480], ylim=None)\n",
    "cablamvsgcamp_plotter.plot_time_series('delta_f_f_full_array', selected_stim_ids=[12, 36, 60, 120, 480])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Analyze a single sensor"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Sensor names\n",
    "sensor_names_gcamp = ['GCaMP8s']\n",
    "\n",
    "# Dictionaries for sensor colors (boxplot and stripplot)\n",
    "sensor_box_colors_gcamp = {\n",
    "    'GCaMP8s': '#d3d3d3'   # Light grey\n",
    "}\n",
    "\n",
    "sensor_strip_colors_gcamp = {\n",
    "    'GCaMP8s': '#808080'   # Dark grey\n",
    "}\n",
    "\n",
    "# Initialize the SensorDataPlotter object\n",
    "gcamp_plotter = SensorDataPlotter(\n",
    "    data_frames=[responsiveness_df_gcamp8],\n",
    "    sensor_names=sensor_names_gcamp,\n",
    "    sensor_box_colors=sensor_box_colors_gcamp,\n",
    "    sensor_strip_colors=sensor_strip_colors_gcamp\n",
    ")\n",
    "\n",
    "gcamp_plotter.plot_data('peak_delta_f_f_post_stim', selected_stim_ids=[12, 36, 60, 120, 480])\n",
    "gcamp_plotter.plot_data('time_to_peak', selected_stim_ids=[12, 36, 60, 120, 480])\n",
    "gcamp_plotter.plot_mean_with_error('peak_delta_f_f_post_stim', error_type='SEM', selected_stim_ids=[12, 36, 60, 120, 480], ylim=None)\n",
    "gcamp_plotter.plot_time_series('delta_f_f_full_array', selected_stim_ids=[12, 36, 60, 120, 480])"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "biolumi_calcium_imaging",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.18"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
