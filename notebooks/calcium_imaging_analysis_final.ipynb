{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 100,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "from PIL import Image\n",
    "import cv2\n",
    "from skimage.color import rgb2gray\n",
    "from skimage import io\n",
    "from skimage.measure import label, regionprops\n",
    "\n",
    "class ImageAnalysis:\n",
    "    \n",
    "    \"\"\"\n",
    "    Provides methods for organizing and analyzing image data from various directory structures within a project folder.\n",
    "    This class initializes by reading the project folder, creating a DataFrame that lists each directory and its path,\n",
    "    and allows for further expansion to include specific image analysis metadata.\n",
    "\n",
    "    Parameters:\n",
    "    - project_folder (str): The path to the project folder containing various image data directories.\n",
    "\n",
    "    Attributes:\n",
    "    - project_folder (str): Stores the provided path to the project folder.\n",
    "    - directory_df (DataFrame): A pandas DataFrame listing directories within the project folder and various attributes\n",
    "      related to image analysis.\n",
    "\n",
    "    Methods:\n",
    "\n",
    "    __init__(self, project_folder)\n",
    "        Constructor for the ImageAnalysis class. Initializes the project folder and sets up the initial directory\n",
    "        DataFrame by listing all directories within the provided project folder.\n",
    "\n",
    "    initialize_directory_df(self)\n",
    "        Scans the project folder to list all subdirectories and creates a DataFrame with the directory names and their\n",
    "        respective paths.\n",
    "\n",
    "        Returns:\n",
    "        - DataFrame: A pandas DataFrame with columns 'directory_name' and 'directory_path' containing information\n",
    "          about each directory within the project folder.\n",
    "\n",
    "    expand_directory_df(self)\n",
    "        Expands the directory DataFrame by adding additional columns related to the image analysis, such as sensor type,\n",
    "        session ID, stimulation IDs, and stimulation frame numbers. This method parses directory names and CSV files\n",
    "        within directories to extract this information.\n",
    "\n",
    "        Steps Performed:\n",
    "        1. Adds new columns for sensor type, session ID, stimulation IDs, and frame numbers with default values.\n",
    "        2. Iterates through each directory, parsing the directory name for sensor type and session ID.\n",
    "        3. Searches for specific CSV files within each directory and extracts stimulation details from them.\n",
    "\n",
    "        Returns:\n",
    "        - DataFrame: The updated pandas DataFrame with new columns for sensor type, session ID, stimulation IDs, and\n",
    "          frame numbers populated based on the directory's content.\n",
    "\n",
    "    \"\"\"\n",
    "    \n",
    "    def __init__(self, project_folder):\n",
    "        self.project_folder = project_folder\n",
    "        self.directory_df = self.initialize_directory_df() \n",
    "        \n",
    "    def initialize_directory_df(self):\n",
    "        directories = [d for d in os.listdir(self.project_folder) if os.path.isdir(os.path.join(self.project_folder, d))]\n",
    "        directory_data = [{'directory_name': d, 'directory_path': os.path.join(self.project_folder, d)} for d in directories]\n",
    "        return pd.DataFrame(directory_data, columns=['directory_name', 'directory_path'])\n",
    "    \n",
    "    def expand_directory_df(self):\n",
    "        # Add new columns with default empty lists\n",
    "        self.directory_df['sensor_type'] = ''\n",
    "        self.directory_df['session_id'] = ''\n",
    "        self.directory_df['stimulation_ids'] = [[] for _ in range(len(self.directory_df))]\n",
    "        self.directory_df['stimulation_frame_number'] = [[] for _ in range(len(self.directory_df))]\n",
    "\n",
    "        for index, row in self.directory_df.iterrows():\n",
    "            folder_name = row['directory_name']\n",
    "            folder_path = row['directory_path']\n",
    "            \n",
    "            # Parse folder name for sensor type and session id\n",
    "            parts = folder_name.split('_')\n",
    "            sensor_type = 'gcamp8' if parts[0].startswith('g') else 'cablam'\n",
    "            session_id = parts[0][1:] + parts[1]  # Assuming the first part is always the experiment ID\n",
    "\n",
    "            # Update DataFrame with sensor_type and session_id\n",
    "            self.directory_df.at[index, 'sensor_type'] = sensor_type\n",
    "            self.directory_df.at[index, 'session_id'] = session_id\n",
    "\n",
    "            # Check for CSV file ending in 'biolumi' or 'fluor'\n",
    "            csv_filename = [f for f in os.listdir(folder_path) if (f.endswith('biolumi.csv') or f.endswith('fluor.csv'))]\n",
    "            if csv_filename:\n",
    "                csv_file_path = os.path.join(folder_path, csv_filename[0])\n",
    "                df_csv = pd.read_csv(csv_file_path, header=None)\n",
    "                stimulation_ids = df_csv.iloc[1].dropna().tolist()\n",
    "                stimulation_frame_number = df_csv.iloc[0].dropna().tolist()\n",
    "\n",
    "                # Update DataFrame with stimulation information\n",
    "                self.directory_df.at[index, 'stimulation_ids'] = stimulation_ids\n",
    "                self.directory_df.at[index, 'stimulation_frame_number'] = stimulation_frame_number\n",
    "\n",
    "        return self.directory_df\n",
    "        \n",
    "    def max_projection_mean_values(self, tif_path):\n",
    "        \"\"\"\n",
    "        Generates a maximum intensity projection based on the mean values of a multi-frame TIF file\n",
    "        and saves it to a new subdirectory 'processed_data/processed_image_analysis_output'\n",
    "        with a '_max_projection' suffix in the file name.\n",
    "\n",
    "        Parameters:\n",
    "        tif_path (str): Path to the multi-frame TIF file.\n",
    "\n",
    "        Returns:\n",
    "        str: Path to the saved maximum intensity projection image.\n",
    "        \"\"\"\n",
    "\n",
    "        with Image.open(tif_path) as img:\n",
    "            # Initialize a summing array with the shape of the first frame and float type for mean calculation\n",
    "            sum_image = np.zeros((img.height, img.width), dtype=np.float32)\n",
    "\n",
    "            # Sum up all frames\n",
    "            for i in range(img.n_frames):\n",
    "                img.seek(i)\n",
    "                sum_image += np.array(img, dtype=np.float32)\n",
    "\n",
    "            # Compute the mean image by dividing the sum by the number of frames\n",
    "            mean_image = sum_image / img.n_frames\n",
    "        \n",
    "        # Define the new directory path\n",
    "        processed_dir = os.path.join(os.path.dirname(tif_path), 'processed_data', 'processed_image_analysis_output')\n",
    "        \n",
    "        # Create the directory if it does not exist\n",
    "        os.makedirs(processed_dir, exist_ok=True)\n",
    "        \n",
    "        # Create a new file path for the max projection image with the '_max_projection' suffix\n",
    "        # The filename is extracted from tif_path and appended with '_max_projection.tif'\n",
    "        file_name = os.path.basename(tif_path)\n",
    "        max_proj_image_path = os.path.join(processed_dir, file_name.replace('.tif', '_max_projection.tif'))\n",
    "       \n",
    "        # Save the max projection image to the new file path\n",
    "        Image.fromarray(mean_image).save(max_proj_image_path)\n",
    "\n",
    "        # Return the path to the saved image\n",
    "        return max_proj_image_path\n",
    "    \n",
    "    \n",
    "    def analyze_all_sessions(self, function_to_apply):\n",
    "        \"\"\"\n",
    "        Iterates over all session IDs in the directory DataFrame and applies the given function to each.\n",
    "\n",
    "        Parameters:\n",
    "        function_to_apply (callable): Function to be applied to each session. It should accept a session ID.\n",
    "\n",
    "        Returns:\n",
    "        dict: A dictionary with session_ids as keys and function return values as values.\n",
    "        \"\"\"\n",
    "        results = {}\n",
    "        for session_id in self.directory_df['session_id']:\n",
    "            try:\n",
    "                result = function_to_apply(session_id)\n",
    "                results[session_id] = result\n",
    "            except Exception as e:\n",
    "                print(f\"An error occurred while processing session {session_id}: {e}\")\n",
    "        return results\n",
    "    \n",
    "    def analyze_session_max_projection(self, session_id):\n",
    "        \"\"\"\n",
    "        Wrapper function to apply max_projection_mean_values to a session's TIF file.\n",
    "\n",
    "        Parameters:\n",
    "        session_id (str): The session ID for which the TIF file will be processed.\n",
    "\n",
    "        Returns:\n",
    "        str: Path to the processed max projection TIFF file.\n",
    "        \"\"\"\n",
    "        # analysis is an instance of ImageAnalysis\n",
    "        tif_path = self.get_session_raw_data(session_id)\n",
    "        if isinstance(tif_path, str) and tif_path.endswith('.tif'):\n",
    "            return self.max_projection_mean_values(tif_path)\n",
    "        else:\n",
    "            return f\"No valid TIF file found for session {session_id}\"# Apply max_projection_mean_values to all sessions\n",
    "        \n",
    "    def get_session_raw_data(self, session_id):\n",
    "        # Check if the session_id is in the 'session_id' column of the directory_df\n",
    "        if session_id in self.directory_df['session_id'].tolist():\n",
    "            # Find the directory path for the given session_id\n",
    "            directory_path = self.directory_df[self.directory_df['session_id'] == session_id]['directory_path'].values[0]\n",
    "            \n",
    "            # Search for the .tif file within that directory\n",
    "            for file_name in os.listdir(directory_path):\n",
    "                if file_name.endswith('.tif'):\n",
    "                    return os.path.join(directory_path, file_name)\n",
    "\n",
    "            # If no .tif file is found in the directory\n",
    "            return f\"No .tif file found in the directory for session {session_id}.\"\n",
    "        else:\n",
    "            # If the session_id is not present in the DataFrame\n",
    "            return f\"Session ID {session_id} is not present in the directory DataFrame.\"\n",
    "         \n",
    "    def add_tiff_dimensions(self):\n",
    "        \"\"\"\n",
    "        Analyzes the dimensions of TIF files in the directory DataFrame and adds this data as new columns.\n",
    "        \"\"\"\n",
    "        # Ensure the DataFrame has the columns for dimensions\n",
    "        if 'x_dim' not in self.directory_df.columns:\n",
    "            self.directory_df['x_dim'] = None\n",
    "            self.directory_df['y_dim'] = None\n",
    "            self.directory_df['z_dim_frames'] = None\n",
    "\n",
    "        # Iterate over each session_id and update the dimensions\n",
    "        for index, row in self.directory_df.iterrows():\n",
    "            tif_path = self.get_session_raw_data(row['session_id'])\n",
    "            if isinstance(tif_path, str) and tif_path.endswith('.tif'):\n",
    "                try:\n",
    "                    with Image.open(tif_path) as img:\n",
    "                        self.directory_df.at[index, 'x_dim'] = img.width\n",
    "                        self.directory_df.at[index, 'y_dim'] = img.height\n",
    "                        # For z-dimension, count the frames\n",
    "                        img.seek(0)  # Ensure the pointer is at the beginning\n",
    "                        frames = 0\n",
    "                        while True:\n",
    "                            try:\n",
    "                                img.seek(img.tell() + 1)\n",
    "                                frames += 1\n",
    "                            except EOFError:\n",
    "                                break\n",
    "                        self.directory_df.at[index, 'z_dim_frames'] = frames\n",
    "                except Exception as e:\n",
    "                    print(f\"Could not process TIF dimensions for session {row['session_id']}: {e}\")\n",
    "                                \n",
    "    def analyze_all_calcium_signals(self):\n",
    "        \"\"\"\n",
    "        Applies calcium signal extraction to all session_ids in the directory DataFrame and stores the results.\n",
    "        \"\"\"\n",
    "        results = {}\n",
    "        for session_id in self.directory_df['session_id']:\n",
    "            # Ensure the ROI analysis has been done to get the labeled images\n",
    "            roi_results = self.analyze_roi(session_id)\n",
    "            # Check if analyze_roi returned a path to labeled images\n",
    "            if isinstance(roi_results, tuple):\n",
    "                # Extract calcium signals using the labeled ROI mask\n",
    "                calcium_csv_path = self.extract_calcium_signals(session_id)\n",
    "                results[session_id] = calcium_csv_path\n",
    "            else:\n",
    "                # If roi_results is an error message, pass it through\n",
    "                results[session_id] = roi_results\n",
    "                \n",
    "            #results is a dictionary where each key is a session_id and the corresponding value is the path to the saved CSV file containing calcium signal data.\n",
    "        return results\n",
    "    \n",
    "    \n",
    "    def analyze_roi(self, session_id):\n",
    "        \"\"\"\n",
    "        Analyzes ROI of the 'labels_postexport.tif' file for a given session and saves two results:\n",
    "        one with labels and another without labels.I t also saves the labeled image data as numpy array for future use.\n",
    "        \"\"\"\n",
    "        \n",
    "        #### SETP 1: DEFINE PATHS ####\n",
    "        # define the paths, including the directory where processed images will be saved (processed_dir) \n",
    "        # and the name of the TIF file that contains the ROI labels (consistent_file_name)\n",
    "        processed_dir = 'processed_data/processed_image_analysis_output'\n",
    "        consistent_file_name = 'labels_postexport.tif'\n",
    "        output_suffix_with_labels = '_roi_analysis_with_labels.png'\n",
    "        output_suffix_without_labels = '_roi_analysis_without_labels.png'\n",
    "\n",
    "        #### STEP 2: RETRIEVE SESSION DATA ####\n",
    "        # Retrieve the directory path from the DataFrame\n",
    "        # looks up the session's directory path from a DataFrame (directory_df) using the provided session_id. \n",
    "        # If the session ID isn't found, it returns a message indicating no directory entry was found for that session.\n",
    "        \n",
    "        directory_entry = self.directory_df[self.directory_df['session_id'] == session_id]\n",
    "        if directory_entry.empty:\n",
    "            return f\"No directory entry found for session {session_id}\"\n",
    "\n",
    "        #### STEP 3: VERIFY AND LOAD THE ROI TIF FILE ####\n",
    "        # constructs the full path to the labels_postexport.tif file and checks if it exists. If it does, the file is opened and loaded. \n",
    "        # If the file is in RGB format, it's converted to grayscale using rgb2gray from skimage.color. \n",
    "        # This conversion is crucial for analyzing the image as a binary mask where non-white pixels are considered ROIs.\n",
    "        directory_path = directory_entry['directory_path'].values[0]\n",
    "        \n",
    "        # Build the path to the postexport TIFF file\n",
    "        tiff_file_path = os.path.join(directory_path, processed_dir, consistent_file_name)\n",
    "\n",
    "        # Verify that the file exists\n",
    "        if not os.path.exists(tiff_file_path):\n",
    "            return f\"File not found for session {session_id}\"\n",
    "        else:\n",
    "            print(f\"Analyzing session {session_id}...\")\n",
    "        \n",
    "        #### STEP 4: CREATE AND SAVE THE BINARY MASK ####\n",
    "        # k: The method then converts the grayscale image to a binary mask, identifying all non-white pixels as ROIs \n",
    "        # (pixels with value less than 1 after normalization are set to 1, and others to 0). \n",
    "        # This binary mask is labeled using label from skimage.measure, assigning a unique label to each connected component (ROI).\n",
    "        \n",
    "        # Load the image\n",
    "        mask_image = Image.open(tiff_file_path)\n",
    "\n",
    "        # Convert RGB image to grayscale if necessary\n",
    "        if mask_image.mode == 'RGB':\n",
    "            # Convert to grayscale using skimage's rgb2gray\n",
    "            image_array = rgb2gray(np.array(mask_image))\n",
    "\n",
    "        # Assuming that all non-white pixels are ROIs\n",
    "        binary_mask = np.where(image_array < 1, 1, 0)  # Here, 1 corresponds to white in the normalized grayscale image\n",
    "\n",
    "        # Label the regions\n",
    "        labeled_image = label(binary_mask, connectivity=1)\n",
    "        num_rois = np.max(labeled_image)\n",
    "        \n",
    "        # Save the labeled image data as a NumPy array file for future processing\n",
    "        labeled_image_path = os.path.join(directory_path, processed_dir, f\"{session_id}_labeled_image.npy\")\n",
    "        np.save(labeled_image_path, labeled_image)\n",
    "        \n",
    "        \n",
    "        #### STEP 5: SAVE THE UNLABELED ROI IMAGE ####\n",
    "        # Save Unlabeled ROI Image: The method saves a version of the labeled image without any annotations to a specified path (output_path_without_labels). \n",
    "        # This image is saved in the processed_image_analysis_output directory with a specific suffix to indicate it's the unlabeled version.\n",
    "        \n",
    "        # Save the image without labels\n",
    "        output_path_without_labels = os.path.join(directory_path, processed_dir, session_id + output_suffix_without_labels)\n",
    "        plt.imsave(output_path_without_labels, labeled_image, cmap='nipy_spectral')\n",
    "\n",
    "        \n",
    "        #### STEP 6: ANALYZE AND SAVE LABELED ROI IMAGE ####\n",
    "        # Iterates through each detected region using regionprops, extracts the centroid, \n",
    "        # and annotates the image with the region's label. \n",
    "        # This annotated image is saved separately, indicating it includes ROI labels.\n",
    "        \n",
    "        # Analyze regions and save properties\n",
    "        regions = regionprops(labeled_image)\n",
    "\n",
    "        # Prepare to save the ROI analysis image with labels\n",
    "        output_path_with_labels = os.path.join(directory_path, processed_dir, session_id + output_suffix_with_labels)\n",
    "        \n",
    "        fig, ax = plt.subplots()\n",
    "        ax.imshow(labeled_image, cmap='nipy_spectral')\n",
    "        ax.axis('off')\n",
    "\n",
    "        # Annotate each ROI with its corresponding label (ID)\n",
    "        for region in regions:\n",
    "            # Get the coordinates of the centroid of the region\n",
    "            y, x = region.centroid\n",
    "            # Annotate the ROI ID at the centroid position\n",
    "            ax.text(x, y, str(region.label), color='white', ha='center', va='center')\n",
    "\n",
    "        plt.savefig(output_path_with_labels)\n",
    "        plt.close()\n",
    "\n",
    "        # Return the paths of the saved figures LABELED AND UNLABELED and number of ROIs\n",
    "        return (output_path_with_labels, output_path_without_labels), num_rois\n",
    "    \n",
    "    def analyze_all_rois(self):\n",
    "        \"\"\"\n",
    "        Applies ROI analysis to all sessions and saves the results.\n",
    "        \"\"\"\n",
    "        results = {}\n",
    "        for session_id in self.directory_df['session_id']:\n",
    "            result = self.analyze_roi(session_id)\n",
    "            results[session_id] = result\n",
    "        return results\n",
    "    \n",
    "    def process_all_sessions(self, use_corrected_data=False):\n",
    "        \n",
    "        \"\"\"\n",
    "        This assumes the analyze_all_rois method has been previously run to generate the numpy files \n",
    "        and the corresponding images with and without labels for ROI per session.\n",
    "        \n",
    "        Process all sessions using either corrected or uncorrected calcium signal data.\n",
    "\n",
    "        Parameters\n",
    "        ----------\n",
    "        use_corrected_data : bool, optional\n",
    "            Flag indicating whether to use corrected calcium signals. Defaults to False, \n",
    "            indicating uncorrected data should be used.\n",
    "\n",
    "        Returns\n",
    "        -------\n",
    "        dict\n",
    "            A dictionary with processed data for all sessions, keyed by session ID.\n",
    "        \"\"\"\n",
    "        \n",
    "        all_data = {}\n",
    "        for session_id in self.directory_df['session_id'].unique():\n",
    "            stim_frame_numbers, roi_data, stimulation_ids = self.create_trial_locked_calcium_signals(session_id, use_corrected_data=use_corrected_data)\n",
    "            if stim_frame_numbers and roi_data and stimulation_ids:  # Ensure data was returned\n",
    "                all_data[session_id] = {\n",
    "                    'stim_frame_numbers': stim_frame_numbers,\n",
    "                    'roi_data': roi_data,\n",
    "                    'stimulation_ids': stimulation_ids\n",
    "                }\n",
    "        return all_data\n",
    "    \n",
    "    def create_trial_locked_calcium_signals(self, session_id, use_corrected_data=False):\n",
    "        \"\"\"\n",
    "        Generate trial-locked calcium signal data for a given session ID, allowing\n",
    "        the choice between corrected and uncorrected data.\n",
    "        \n",
    "        Parameters\n",
    "        ----------\n",
    "        session_id : str\n",
    "            The session ID for which to generate trial-locked signals.\n",
    "        use_corrected_data : bool, optional\n",
    "            Whether to use corrected calcium signal data. The default is False, which uses uncorrected data.\n",
    "        \n",
    "        Returns\n",
    "        -------\n",
    "        tuple\n",
    "            A tuple containing the stimulation frame numbers, ROI data, and stimulation IDs.\n",
    "        \"\"\"\n",
    "\n",
    "        processed_dir = 'processed_data/processed_image_analysis_output'\n",
    "        calcium_csv_suffix = '_corrected_calcium_signals.csv' if use_corrected_data else '_calcium_signals.csv'\n",
    "\n",
    "        directory_entry = self.directory_df[self.directory_df['session_id'] == session_id]\n",
    "\n",
    "        if directory_entry.empty:\n",
    "            print(f\"No directory entry found for session {session_id}\")\n",
    "            return None, None, None\n",
    "\n",
    "        directory_path = directory_entry['directory_path'].values[0]\n",
    "        csv_path = os.path.join(directory_path, processed_dir, f\"{session_id}{calcium_csv_suffix}\")\n",
    "\n",
    "        if not os.path.exists(csv_path):\n",
    "            print(f\"Calcium signals file not found for session {session_id} using {'corrected' if use_corrected_data else 'uncorrected'} data\")\n",
    "            return None, None, None\n",
    "\n",
    "        calcium_signals_df = pd.read_csv(csv_path)\n",
    "        stim_frame_numbers = directory_entry['stimulation_frame_number'].values[0]\n",
    "        stimulation_ids = directory_entry['stimulation_ids'].values[0]\n",
    "\n",
    "        pre_stim_frames = 10 # 10 frames before stimulation\n",
    "        post_stim_frames = 100 # 100 frames after stimulation\n",
    "\n",
    "        roi_data = {roi: {} for roi in calcium_signals_df.columns if 'ROI' in roi}\n",
    "\n",
    "        for stim_id, stim_frame in zip(stimulation_ids, stim_frame_numbers):\n",
    "            start_idx = max(stim_frame - pre_stim_frames, 0) \n",
    "            end_idx = min(stim_frame + post_stim_frames, len(calcium_signals_df))\n",
    "\n",
    "            for roi in roi_data:\n",
    "                trial = calcium_signals_df.loc[start_idx:end_idx, roi]\n",
    "                roi_data[roi][(stim_id, stim_frame)] = trial.to_numpy()\n",
    "\n",
    "        return stim_frame_numbers, roi_data, stimulation_ids\n",
    "    \n",
    "\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 101,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>directory_name</th>\n",
       "      <th>directory_path</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>g12_12092023_estim_10hz_na_blk</td>\n",
       "      <td>/Volumes/MannySSD/cablam_imaging/raw_data_temp...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>c21_12232023_estim_10hz_1xfz</td>\n",
       "      <td>/Volumes/MannySSD/cablam_imaging/raw_data_temp...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                   directory_name  \\\n",
       "0  g12_12092023_estim_10hz_na_blk   \n",
       "1    c21_12232023_estim_10hz_1xfz   \n",
       "\n",
       "                                      directory_path  \n",
       "0  /Volumes/MannySSD/cablam_imaging/raw_data_temp...  \n",
       "1  /Volumes/MannySSD/cablam_imaging/raw_data_temp...  "
      ]
     },
     "execution_count": 101,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "project_folder = '/Volumes/MannySSD/cablam_imaging/raw_data_template' #path to the folder containing the raw data to be analyzed (i.e. the folder containing the folders for each experiment)\n",
    "analysis = ImageAnalysis(project_folder)\n",
    "analysis.directory_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 102,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>directory_name</th>\n",
       "      <th>directory_path</th>\n",
       "      <th>sensor_type</th>\n",
       "      <th>session_id</th>\n",
       "      <th>stimulation_ids</th>\n",
       "      <th>stimulation_frame_number</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>g12_12092023_estim_10hz_na_blk</td>\n",
       "      <td>/Volumes/MannySSD/cablam_imaging/raw_data_temp...</td>\n",
       "      <td>gcamp8</td>\n",
       "      <td>1212092023</td>\n",
       "      <td>[12, 24, 36, 60, 120, 480]</td>\n",
       "      <td>[3579, 3780, 3982, 4183, 4385, 4587]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>c21_12232023_estim_10hz_1xfz</td>\n",
       "      <td>/Volumes/MannySSD/cablam_imaging/raw_data_temp...</td>\n",
       "      <td>cablam</td>\n",
       "      <td>2112232023</td>\n",
       "      <td>[12, 24, 36, 60, 120, 240, 480, 960, 1920]</td>\n",
       "      <td>[3509, 3911, 4313, 4715, 5118, 5521, 5926, 633...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                   directory_name  \\\n",
       "0  g12_12092023_estim_10hz_na_blk   \n",
       "1    c21_12232023_estim_10hz_1xfz   \n",
       "\n",
       "                                      directory_path sensor_type  session_id  \\\n",
       "0  /Volumes/MannySSD/cablam_imaging/raw_data_temp...      gcamp8  1212092023   \n",
       "1  /Volumes/MannySSD/cablam_imaging/raw_data_temp...      cablam  2112232023   \n",
       "\n",
       "                              stimulation_ids  \\\n",
       "0                  [12, 24, 36, 60, 120, 480]   \n",
       "1  [12, 24, 36, 60, 120, 240, 480, 960, 1920]   \n",
       "\n",
       "                            stimulation_frame_number  \n",
       "0               [3579, 3780, 3982, 4183, 4385, 4587]  \n",
       "1  [3509, 3911, 4313, 4715, 5118, 5521, 5926, 633...  "
      ]
     },
     "execution_count": 102,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "analysis.expand_directory_df()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "At this point add your manual ROIs to the corresponding 'processed_image_analysis_output' directory. Ensure the .tiff files same matching xy pixel size to ensure the correct aligmen to the .tiff calcium movies . \n",
    "\n",
    "The code assumes the manual/ML generated masks are called 'labels_postexport.tif' and extracts this files itteratively for every unique session ID \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 106,
   "metadata": {},
   "outputs": [
    {
     "ename": "AttributeError",
     "evalue": "'ImageAnalysis' object has no attribute 'analyze_all_calcium_signals'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mAttributeError\u001b[0m                            Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[106], line 1\u001b[0m\n\u001b[0;32m----> 1\u001b[0m all_results \u001b[38;5;241m=\u001b[39m \u001b[43manalysis\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43manalyze_all_calcium_signals\u001b[49m()\n\u001b[1;32m      3\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m session_id, csv_path \u001b[38;5;129;01min\u001b[39;00m all_results\u001b[38;5;241m.\u001b[39mitems():\n\u001b[1;32m      4\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(csv_path, \u001b[38;5;28mstr\u001b[39m):\n",
      "\u001b[0;31mAttributeError\u001b[0m: 'ImageAnalysis' object has no attribute 'analyze_all_calcium_signals'"
     ]
    }
   ],
   "source": [
    "all_results = analysis.analyze_all_calcium_signals()\n",
    "\n",
    "for session_id, csv_path in all_results.items():\n",
    "    if isinstance(csv_path, str):\n",
    "        print(f\"Session {session_id} - Calcium signals saved at: {csv_path}\")\n",
    "    else:\n",
    "        print(f\"Session {session_id} - Error: {csv_path}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 104,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Calcium signals file not found for session 1212092023 using uncorrected data\n",
      "Calcium signals file not found for session 2112232023 using uncorrected data\n"
     ]
    }
   ],
   "source": [
    "all_data = analysis.process_all_sessions(use_corrected_data=False)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "biolumi_calcium_imaging",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.18"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
