{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys\n",
    "import os \n",
    "from PIL import Image\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from PIL import Image\n",
    "import cv2\n",
    "sys.path.append('..')  #adds the Root Directory to the system path\n",
    "from BL_CalciumAnalysis.image_analysis_methods import ImageAnalysis\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#test "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(sys.executable) #print the path of the Python executable being used, which should point to the Python interpreter in your Conda environment."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "from skimage.measure import label, regionprops\n",
    "import matplotlib.pyplot as plt\n",
    "from skimage.color import rgb2gray\n",
    "from skimage import io\n",
    "import glob\n",
    "import ast \n",
    "\n",
    "\n",
    "class ImageAnalysis:\n",
    "    def __init__(self, project_folder):\n",
    "        self.project_folder = project_folder\n",
    "        self.directory_df = self.initialize_directory_df() \n",
    "        \n",
    "    def initialize_directory_df(self):\n",
    "        directories = [d for d in os.listdir(self.project_folder) if os.path.isdir(os.path.join(self.project_folder, d))]\n",
    "        directory_data = [{'directory_name': d, 'directory_path': os.path.join(self.project_folder, d)} for d in directories]\n",
    "        return pd.DataFrame(directory_data, columns=['directory_name', 'directory_path'])\n",
    "    \n",
    "    def list_directories(self):\n",
    "        return [d for d in os.listdir(self.project_folder) if os.path.isdir(os.path.join(self.project_folder, d))]\n",
    "    \n",
    "    def list_files(self, folder_name):\n",
    "        folder_path = os.path.join(self.project_folder, folder_name)\n",
    "        all_files = []\n",
    "        for root, dirs, files in os.walk(folder_path):\n",
    "            for file in files:\n",
    "                all_files.append(os.path.join(root, file))\n",
    "        return all_files\n",
    "    \n",
    "    def generate_dark_image(self, tiff_path, num_frames=200):\n",
    "        \"\"\"\n",
    "        Generates a median 'dark' image from the first specified number of frames in a multi-frame TIFF file.\n",
    "\n",
    "        This method is used for compensating the dark pixel offset in bioluminescence imaging data.\n",
    "\n",
    "        Parameters:\n",
    "        tiff_path (str): Path to the multi-frame TIFF file.\n",
    "        num_frames (int, optional): Number of frames to consider for generating the dark image. Defaults to 200.\n",
    "\n",
    "        Returns:\n",
    "        numpy.ndarray: A median image representing the 'dark' image.\n",
    "        \"\"\"\n",
    "        with Image.open(tiff_path) as img:\n",
    "            frames = [np.array(img.getdata(), dtype=np.float32).reshape(img.size[::-1]) for i in range(num_frames)]\n",
    "            median_frame = np.median(frames, axis=0)\n",
    "            return median_frame\n",
    "\n",
    "    def subtract_dark_image(self, raw_tiff_path, dark_image):\n",
    "        \"\"\"\n",
    "        Subtracts a 'dark' image from each frame of a multi-frame TIFF file.\n",
    "\n",
    "        This method is used to compensate for the average dark pixel offset in bioluminescence imaging data.\n",
    "\n",
    "        Parameters:\n",
    "        raw_tiff_path (str): Path to the raw multi-frame TIFF file.\n",
    "        dark_image (numpy.ndarray): The 'dark' image to be subtracted from each frame of the raw image.\n",
    "\n",
    "        Returns:\n",
    "        list of numpy.ndarray: A list of images, each representing a frame from the raw image with the dark image subtracted.\n",
    "        \"\"\"\n",
    "        with Image.open(raw_tiff_path) as img:\n",
    "            compensated_images = []\n",
    "            for i in range(img.n_frames):\n",
    "                img.seek(i)\n",
    "                frame = np.array(img.getdata(), dtype=np.float32).reshape(img.size[::-1])\n",
    "                compensated_image = cv2.subtract(frame, dark_image)\n",
    "                compensated_images.append(compensated_image)\n",
    "            return compensated_images\n",
    "        \n",
    "    def expand_directory_df(self):\n",
    "        # Add new columns with default empty lists\n",
    "        self.directory_df['sensor_type'] = ''\n",
    "        self.directory_df['session_id'] = ''\n",
    "        self.directory_df['stimulation_ids'] = [[] for _ in range(len(self.directory_df))]\n",
    "        self.directory_df['stimulation_frame_number'] = [[] for _ in range(len(self.directory_df))]\n",
    "\n",
    "        for index, row in self.directory_df.iterrows():\n",
    "            folder_name = row['directory_name']\n",
    "            folder_path = row['directory_path']\n",
    "            \n",
    "            # Parse folder name for sensor type and session id\n",
    "            parts = folder_name.split('_')\n",
    "            sensor_type = 'gcamp8' if parts[0].startswith('g') else 'cablam'\n",
    "            session_id = parts[0][1:] + parts[1]  # Assuming the first part is always the experiment ID\n",
    "\n",
    "            # Update DataFrame with sensor_type and session_id\n",
    "            self.directory_df.at[index, 'sensor_type'] = sensor_type\n",
    "            self.directory_df.at[index, 'session_id'] = session_id\n",
    "\n",
    "            # Check for CSV file ending in 'biolumi' or 'fluor'\n",
    "            csv_filename = [f for f in os.listdir(folder_path) if (f.endswith('biolumi.csv') or f.endswith('fluor.csv'))]\n",
    "            if csv_filename:\n",
    "                csv_file_path = os.path.join(folder_path, csv_filename[0])\n",
    "                df_csv = pd.read_csv(csv_file_path, header=None)\n",
    "                stimulation_ids = df_csv.iloc[1].dropna().tolist()\n",
    "                stimulation_frame_number = df_csv.iloc[0].dropna().tolist()\n",
    "\n",
    "                # Update DataFrame with stimulation information\n",
    "                self.directory_df.at[index, 'stimulation_ids'] = stimulation_ids\n",
    "                self.directory_df.at[index, 'stimulation_frame_number'] = stimulation_frame_number\n",
    "\n",
    "        return self.directory_df\n",
    "    \n",
    "    def get_session_raw_data(self, session_id):\n",
    "        # Check if the session_id is in the 'session_id' column of the directory_df\n",
    "        if session_id in self.directory_df['session_id'].tolist():\n",
    "            # Find the directory path for the given session_id\n",
    "            directory_path = self.directory_df[self.directory_df['session_id'] == session_id]['directory_path'].values[0]\n",
    "            \n",
    "            # Search for the .tif file within that directory\n",
    "            for file_name in os.listdir(directory_path):\n",
    "                if file_name.endswith('.tif'):\n",
    "                    return os.path.join(directory_path, file_name)\n",
    "\n",
    "            # If no .tif file is found in the directory\n",
    "            return f\"No .tif file found in the directory for session {session_id}.\"\n",
    "        else:\n",
    "            # If the session_id is not present in the DataFrame\n",
    "            return f\"Session ID {session_id} is not present in the directory DataFrame.\"\n",
    "        \n",
    "    def max_projection_mean_values(self, tif_path):\n",
    "        \"\"\"\n",
    "        Generates a maximum intensity projection based on the mean values of a multi-frame TIF file\n",
    "        and saves it to a new subdirectory 'processed_data/processed_image_analysis_output'\n",
    "        with a '_max_projection' suffix in the file name.\n",
    "\n",
    "        Parameters:\n",
    "        tif_path (str): Path to the multi-frame TIF file.\n",
    "\n",
    "        Returns:\n",
    "        str: Path to the saved maximum intensity projection image.\n",
    "        \"\"\"\n",
    "\n",
    "        with Image.open(tif_path) as img:\n",
    "            # Initialize a summing array with the shape of the first frame and float type for mean calculation\n",
    "            sum_image = np.zeros((img.height, img.width), dtype=np.float32)\n",
    "\n",
    "            # Sum up all frames\n",
    "            for i in range(img.n_frames):\n",
    "                img.seek(i)\n",
    "                sum_image += np.array(img, dtype=np.float32)\n",
    "\n",
    "            # Compute the mean image by dividing the sum by the number of frames\n",
    "            mean_image = sum_image / img.n_frames\n",
    "        \n",
    "        # Define the new directory path\n",
    "        processed_dir = os.path.join(os.path.dirname(tif_path), 'processed_data', 'processed_image_analysis_output')\n",
    "        \n",
    "        # Create the directory if it does not exist\n",
    "        os.makedirs(processed_dir, exist_ok=True)\n",
    "        \n",
    "        # Create a new file path for the max projection image with the '_max_projection' suffix\n",
    "        # The filename is extracted from tif_path and appended with '_max_projection.tif'\n",
    "        file_name = os.path.basename(tif_path)\n",
    "        max_proj_image_path = os.path.join(processed_dir, file_name.replace('.tif', '_max_projection.tif'))\n",
    "       \n",
    "        # Save the max projection image to the new file path\n",
    "        Image.fromarray(mean_image).save(max_proj_image_path)\n",
    "\n",
    "        # Return the path to the saved image\n",
    "        return max_proj_image_path\n",
    "    \n",
    "    def analyze_all_sessions(self, function_to_apply):\n",
    "        \"\"\"\n",
    "        Iterates over all session IDs in the directory DataFrame and applies the given function to each.\n",
    "\n",
    "        Parameters:\n",
    "        function_to_apply (callable): Function to be applied to each session. It should accept a session ID.\n",
    "\n",
    "        Returns:\n",
    "        dict: A dictionary with session_ids as keys and function return values as values.\n",
    "        \"\"\"\n",
    "        results = {}\n",
    "        for session_id in self.directory_df['session_id']:\n",
    "            try:\n",
    "                result = function_to_apply(session_id)\n",
    "                results[session_id] = result\n",
    "            except Exception as e:\n",
    "                print(f\"An error occurred while processing session {session_id}: {e}\")\n",
    "        return results\n",
    "    \n",
    "    def add_tiff_dimensions(self):\n",
    "        \"\"\"\n",
    "        Analyzes the dimensions of TIF files in the directory DataFrame and adds this data as new columns.\n",
    "        \"\"\"\n",
    "        # Ensure the DataFrame has the columns for dimensions; initialize them with None or appropriate defaults\n",
    "        if 'x_dim' not in self.directory_df.columns:\n",
    "            self.directory_df['x_dim'] = None\n",
    "            self.directory_df['y_dim'] = None\n",
    "            self.directory_df['z_dim_frames'] = None\n",
    "\n",
    "        # Iterate over each session_id and update the dimensions\n",
    "        for index, row in self.directory_df.iterrows():\n",
    "            tif_path = self.get_session_raw_data(row['session_id'])\n",
    "            if isinstance(tif_path, str) and tif_path.endswith('.tif'):\n",
    "                try:\n",
    "                    with Image.open(tif_path) as img:\n",
    "                        self.directory_df.at[index, 'x_dim'] = img.width\n",
    "                        self.directory_df.at[index, 'y_dim'] = img.height\n",
    "                        # For z-dimension, count the frames\n",
    "                        img.seek(0)  # Ensure the pointer is at the beginning\n",
    "                        frames = 0\n",
    "                        while True:\n",
    "                            try:\n",
    "                                img.seek(img.tell() + 1)\n",
    "                                frames += 1\n",
    "                            except EOFError:\n",
    "                                break\n",
    "                        self.directory_df.at[index, 'z_dim_frames'] = frames\n",
    "                except Exception as e:\n",
    "                    print(f\"Could not process TIF dimensions for session {row['session_id']}: {e}\")\n",
    "    \n",
    "    def analyze_roi(self, session_id):\n",
    "        \"\"\"\n",
    "        Analyzes ROI of the 'labels_postexport.tif' file for a given session and saves two results:\n",
    "        one with labels and another without labels.I t also saves the labeled image data as numpy array for future use.\n",
    "        \"\"\"\n",
    "        \n",
    "        # SETP 1: DEFINE PATHS\n",
    "        # define the paths, including the directory where processed images will be saved (processed_dir) \n",
    "        # and the name of the TIF file that contains the ROI labels (consistent_file_name)\n",
    "        processed_dir = 'processed_data/processed_image_analysis_output'\n",
    "        consistent_file_name = 'labels_postexport.tif'\n",
    "        output_suffix_with_labels = '_roi_analysis_with_labels.png'\n",
    "        output_suffix_without_labels = '_roi_analysis_without_labels.png'\n",
    "\n",
    "        # STEP 2: RETRIEVE SESSION DATA \n",
    "        # Retrieve the directory path from the DataFrame\n",
    "        # looks up the session's directory path from a DataFrame (directory_df) using the provided session_id. \n",
    "        # If the session ID isn't found, it returns a message indicating no directory entry was found for that session.\n",
    "        \n",
    "        directory_entry = self.directory_df[self.directory_df['session_id'] == session_id]\n",
    "        if directory_entry.empty:\n",
    "            return f\"No directory entry found for session {session_id}\"\n",
    "\n",
    "        # STEP 3: VERIFY AND LOAD THE ROI TIF FILE \n",
    "        # constructs the full path to the labels_postexport.tif file and checks if it exists. If it does, the file is opened and loaded. \n",
    "        # If the file is in RGB format, it's converted to grayscale using rgb2gray from skimage.color. \n",
    "        # This conversion is crucial for analyzing the image as a binary mask where non-white pixels are considered ROIs.\n",
    "        directory_path = directory_entry['directory_path'].values[0]\n",
    "        \n",
    "        # Build the path to the postexport TIFF file\n",
    "        tiff_file_path = os.path.join(directory_path, processed_dir, consistent_file_name)\n",
    "\n",
    "        # Verify that the file exists\n",
    "        if not os.path.exists(tiff_file_path):\n",
    "            return f\"File not found for session {session_id}\"\n",
    "\n",
    "        \n",
    "        \n",
    "        # STEP 4: CREATE AND SAVE THE BINARY MASK\n",
    "        # k: The method then converts the grayscale image to a binary mask, identifying all non-white pixels as ROIs \n",
    "        # (pixels with value less than 1 after normalization are set to 1, and others to 0). \n",
    "        # This binary mask is labeled using label from skimage.measure, assigning a unique label to each connected component (ROI).\n",
    "        \n",
    "        # Load the image\n",
    "        mask_image = Image.open(tiff_file_path)\n",
    "\n",
    "        # Convert RGB image to grayscale if necessary\n",
    "        if mask_image.mode == 'RGB':\n",
    "            # Convert to grayscale using skimage's rgb2gray\n",
    "            image_array = rgb2gray(np.array(mask_image))\n",
    "\n",
    "        # Assuming that all non-white pixels are ROIs\n",
    "        binary_mask = np.where(image_array < 1, 1, 0)  # Here, 1 corresponds to white in the normalized grayscale image\n",
    "\n",
    "        # Label the regions\n",
    "        labeled_image = label(binary_mask, connectivity=1)\n",
    "        num_rois = np.max(labeled_image)\n",
    "        \n",
    "        # Save the labeled image data as a NumPy array file for future processing\n",
    "        labeled_image_path = os.path.join(directory_path, processed_dir, f\"{session_id}_labeled_image.npy\")\n",
    "        np.save(labeled_image_path, labeled_image)\n",
    "        \n",
    "        \n",
    "        # STEP 5: SAVE THE UNLABELED ROI IMAGE \n",
    "        # Save Unlabeled ROI Image: The method saves a version of the labeled image without any annotations to a specified path (output_path_without_labels). \n",
    "        # This image is saved in the processed_image_analysis_output directory with a specific suffix to indicate it's the unlabeled version.\n",
    "        \n",
    "        # Save the image without labels\n",
    "        output_path_without_labels = os.path.join(directory_path, processed_dir, session_id + output_suffix_without_labels)\n",
    "        plt.imsave(output_path_without_labels, labeled_image, cmap='nipy_spectral')\n",
    "\n",
    "        \n",
    "        # STEP 6: ANALYZE AND SAVE LABELED ROI IMAGE \n",
    "        # Iterates through each detected region using regionprops, extracts the centroid, \n",
    "        # and annotates the image with the region's label. \n",
    "        # This annotated image is saved separately, indicating it includes ROI labels.\n",
    "        \n",
    "        # Analyze regions and save properties\n",
    "        regions = regionprops(labeled_image)\n",
    "\n",
    "        # Prepare to save the ROI analysis image with labels\n",
    "        output_path_with_labels = os.path.join(directory_path, processed_dir, session_id + output_suffix_with_labels)\n",
    "        \n",
    "        fig, ax = plt.subplots()\n",
    "        ax.imshow(labeled_image, cmap='nipy_spectral')\n",
    "        ax.axis('off')\n",
    "\n",
    "        # Annotate each ROI with its corresponding label (ID)\n",
    "        for region in regions:\n",
    "            # Get the coordinates of the centroid of the region\n",
    "            y, x = region.centroid\n",
    "            # Annotate the ROI ID at the centroid position\n",
    "            ax.text(x, y, str(region.label), color='white', ha='center', va='center')\n",
    "\n",
    "        plt.savefig(output_path_with_labels)\n",
    "        plt.close()\n",
    "\n",
    "        # Return the paths of the saved figures LABELED AND UNLABELED and number of ROIs\n",
    "        return (output_path_with_labels, output_path_without_labels), num_rois\n",
    "    \n",
    "    def analyze_all_rois(self):\n",
    "        \"\"\"\n",
    "        Applies ROI analysis to all sessions and saves the results.\n",
    "        \"\"\"\n",
    "        results = {}\n",
    "        for session_id in self.directory_df['session_id']:\n",
    "            result = self.analyze_roi(session_id)\n",
    "            results[session_id] = result\n",
    "        return results\n",
    "    \n",
    "    def extract_calcium_signals(self, session_id):\n",
    "        \"\"\"\n",
    "        Extracts calcium signals from time-series data using the saved labeled ROI mask\n",
    "        and saves the results as a CSV file in the 'processed_image_analysis_output' directory.\n",
    "\n",
    "        Parameters:\n",
    "        session_id (str): Session ID for which to perform the analysis.\n",
    "\n",
    "        Returns:\n",
    "        str: Path to the saved CSV file containing calcium signal data.\n",
    "        \"\"\"\n",
    "        processed_dir = 'processed_data/processed_image_analysis_output'\n",
    "        calcium_csv_suffix = '_calcium_signals.csv'\n",
    "\n",
    "        # Retrieve the directory path from the DataFrame\n",
    "        directory_entry = self.directory_df[self.directory_df['session_id'] == session_id]\n",
    "        if directory_entry.empty:\n",
    "            return f\"No directory entry found for session {session_id}\"\n",
    "\n",
    "        directory_path = directory_entry['directory_path'].values[0]\n",
    "\n",
    "        # Path to the saved labeled image numpy file\n",
    "        labeled_image_path = os.path.join(directory_path, processed_dir, session_id + '_labeled_image.npy')\n",
    "\n",
    "        # Verify and load the labeled image numpy file\n",
    "        if not os.path.exists(labeled_image_path):\n",
    "            return f\"Labeled image file not found for session {session_id}\"\n",
    "        labeled_image = np.load(labeled_image_path)\n",
    "\n",
    "        # Locate and load the time-series TIFF file\n",
    "        tif_files = glob.glob(os.path.join(directory_path, '*.tif'))\n",
    "        tif_files = [f for f in tif_files if 'postexport' not in f and 'labels' not in f]  # Ensure it's the correct TIFF\n",
    "        if not tif_files:\n",
    "            return f\"No time-series .tif file found in the directory for session {session_id}\"\n",
    "        time_series_path = tif_files[0]  # Assuming there's only one relevant TIFF file\n",
    "        time_series = io.imread(time_series_path)\n",
    "\n",
    "        # Initialize an array to store calcium signal data\n",
    "        num_rois = np.max(labeled_image)\n",
    "        num_frames = time_series.shape[0]\n",
    "        calcium_signals = np.zeros((num_rois, num_frames))\n",
    "\n",
    "        # Extract the signal from each ROI in each frame\n",
    "        for t in range(num_frames):\n",
    "            frame = time_series[t]\n",
    "            for roi in range(1, num_rois + 1):\n",
    "                roi_mask = labeled_image == roi\n",
    "                roi_data = frame[roi_mask]\n",
    "                calcium_signals[roi - 1, t] = np.mean(roi_data)\n",
    "\n",
    "        # Create and save the DataFrame with calcium signals\n",
    "        calcium_df = pd.DataFrame(calcium_signals.T, columns=[f\"ROI_{i}\" for i in range(1, num_rois + 1)])\n",
    "        calcium_df['Frame'] = np.arange(1, num_frames + 1)\n",
    "        csv_path = os.path.join(directory_path, processed_dir, session_id + calcium_csv_suffix)\n",
    "        calcium_df.to_csv(csv_path, index=False)\n",
    "\n",
    "        return csv_path\n",
    "    \n",
    "    def analyze_all_calcium_signals(self):\n",
    "        \"\"\"\n",
    "        Applies calcium signal extraction to all session_ids in the directory DataFrame and stores the results.\n",
    "        \"\"\"\n",
    "        results = {}\n",
    "        for session_id in self.directory_df['session_id']:\n",
    "            # Ensure the ROI analysis has been done to get the labeled images\n",
    "            roi_results = self.analyze_roi(session_id)\n",
    "            # Check if analyze_roi returned a path to labeled images\n",
    "            if isinstance(roi_results, tuple):\n",
    "                # Extract calcium signals using the labeled ROI mask\n",
    "                calcium_csv_path = self.extract_calcium_signals(session_id)\n",
    "                results[session_id] = calcium_csv_path\n",
    "            else:\n",
    "                # If roi_results is an error message, pass it through\n",
    "                results[session_id] = roi_results\n",
    "                \n",
    "            #results is a dictionary where each key is a session_id and the corresponding value is the path to the saved CSV file containing calcium signal data.\n",
    "        return results\n",
    "            \n",
    "    def plot_session_calcium_signals(self, session_id, use_corrected_data=False):\n",
    "        \"\"\"\n",
    "        Attempt to plot calcium signals for a given session and return a status message.\n",
    "\n",
    "        Parameters\n",
    "        ----------\n",
    "        session_id : str\n",
    "            The identifier for the session for which calcium signals are to be plotted.\n",
    "        use_corrected_data : bool, optional\n",
    "            Flag indicating whether to use corrected calcium signals or not (default is False).\n",
    "\n",
    "        Returns\n",
    "        -------\n",
    "        str\n",
    "            A message indicating whether the plotting was successful or failed. If it failed,\n",
    "            the message includes the reason for the failure.\n",
    "        \"\"\"\n",
    "        try:\n",
    "            self.plot_calcium_signals(session_id, use_corrected_data=use_corrected_data)\n",
    "            data_type = 'corrected' if use_corrected_data else 'uncorrected'\n",
    "            return f\"Plotted {data_type} calcium signals for session {session_id}\"\n",
    "        except Exception as e:\n",
    "            return f\"Failed to plot calcium signals for session {session_id}: {e}\"\n",
    "    \n",
    "    def plot_all_sessions_calcium_signals(self, use_corrected_data=False):\n",
    "        \"\"\"\n",
    "        Apply the plot_session_calcium_signals method to all sessions in the dataset.\n",
    "\n",
    "        Iterates over all session IDs and plots calcium signals for each session using\n",
    "        the plot_session_calcium_signals method. Collects and returns the outcomes of\n",
    "        the plotting process for each session.\n",
    "\n",
    "        Parameters\n",
    "        ----------\n",
    "        use_corrected_data : bool, optional\n",
    "            Flag indicating whether to use corrected calcium signals or not (default is False).\n",
    "\n",
    "        Returns\n",
    "        -------\n",
    "        dict\n",
    "            A dictionary where each key is a session ID and the corresponding value is\n",
    "            a message indicating the success or failure of the plotting operation for\n",
    "            that session.\n",
    "        \"\"\"\n",
    "        results = {}\n",
    "        for session_id in self.directory_df['session_id'].tolist():\n",
    "            result = self.plot_session_calcium_signals(session_id, use_corrected_data=use_corrected_data)\n",
    "            results[session_id] = result\n",
    "        return results\n",
    "        \n",
    "    def plot_calcium_signals(self, session_id, use_corrected_data=False):\n",
    "        processed_dir = 'processed_data/processed_image_analysis_output'\n",
    "        \n",
    "        # Choose the file suffix based on whether corrected data should be used\n",
    "        calcium_csv_suffix = '_corrected_calcium_signals.csv' if use_corrected_data else '_calcium_signals.csv'\n",
    "\n",
    "        directory_entry = self.directory_df[self.directory_df['session_id'] == session_id]\n",
    "        if directory_entry.empty:\n",
    "            print(f\"No directory entry found for session {session_id}\")\n",
    "            return\n",
    "\n",
    "        directory_path = directory_entry['directory_path'].values[0]\n",
    "        csv_path = os.path.join(directory_path, processed_dir, str(session_id) + calcium_csv_suffix)\n",
    "\n",
    "        if not os.path.exists(csv_path):\n",
    "            print(f\"Calcium signals file {'corrected ' if use_corrected_data else ''}not found for session {session_id}\")\n",
    "            return\n",
    "\n",
    "        calcium_signals_df = pd.read_csv(csv_path)\n",
    "        frame_numbers = calcium_signals_df['Frame']\n",
    "        calcium_signals = calcium_signals_df.drop('Frame', axis=1)\n",
    "\n",
    "        # Normalize the signals and calculate offsets\n",
    "        normalized_signals = (calcium_signals - calcium_signals.min()) / (calcium_signals.max() - calcium_signals.min())\n",
    "        offsets = np.arange(len(normalized_signals.columns)) * 1.2\n",
    "\n",
    "        plt.figure(figsize=(15, 10))\n",
    "        \n",
    "        # Assuming 'stimulation_frame_number' contains a list or similar; if it's a single number, adjust accordingly\n",
    "        stim_frame_numbers = self.directory_df.loc[\n",
    "            self.directory_df['session_id'] == session_id, 'stimulation_frame_number'\n",
    "        ].values[0]\n",
    "\n",
    "        # Plot red dotted lines for stimulation timestamps\n",
    "        for frame_number in stim_frame_numbers:\n",
    "            plt.axvline(x=frame_number, color='r', linestyle='--', linewidth=0.5)\n",
    "\n",
    "        # Plot each normalized calcium signal with an offset\n",
    "        for i, (roi_label, signal) in enumerate(normalized_signals.items()):\n",
    "            plt.plot(frame_numbers, signal + offsets[i], label=roi_label)\n",
    "\n",
    "        plt.xlabel('Frame Number')\n",
    "        plt.ylabel('Normalized Calcium Signal (A.U.)')\n",
    "        plt.title(f\"Time Series of ROIs for Session {session_id} ({'Corrected' if use_corrected_data else 'Uncorrected'})\")\n",
    "\n",
    "        plt.yticks(ticks=offsets + 0.5, labels=normalized_signals.columns)\n",
    "        plt.grid(False)\n",
    "        plt.tight_layout()\n",
    "\n",
    "        save_suffix = 'corrected_' if use_corrected_data else ''\n",
    "        save_dir = os.path.join(directory_path, 'processed_data', 'processed_image_analysis_output')\n",
    "        os.makedirs(save_dir, exist_ok=True)\n",
    "        save_path = os.path.join(save_dir, f\"{session_id}_{save_suffix}calcium_signals_plot.png\")\n",
    "\n",
    "        plt.savefig(save_path, dpi=300, bbox_inches='tight')\n",
    "        print(f\"Plot saved to {save_path}\")\n",
    "        plt.show()\n",
    "\n",
    "    def save_individual_roi_plots(self, session_id, use_corrected_data=False):\n",
    "        processed_dir = 'processed_data/processed_image_analysis_output'\n",
    "        cell_roi_dir = 'cell_roi_processed_data'\n",
    "        calcium_csv_suffix = '_corrected_calcium_signals.csv' if use_corrected_data else '_calcium_signals.csv'\n",
    "\n",
    "        directory_entry = self.directory_df[self.directory_df['session_id'] == session_id]\n",
    "        if directory_entry.empty:\n",
    "            print(f\"No directory entry found for session {session_id}\")\n",
    "            return\n",
    "\n",
    "        directory_path = directory_entry['directory_path'].values[0]\n",
    "        stimulation_times = directory_entry['stimulation_frame_number'].values[0]\n",
    "\n",
    "        processed_data_path = os.path.join(directory_path, processed_dir)\n",
    "        csv_path = os.path.join(processed_data_path, str(session_id) + calcium_csv_suffix)\n",
    "        roi_output_dir = os.path.join(processed_data_path, cell_roi_dir)\n",
    "\n",
    "        os.makedirs(roi_output_dir, exist_ok=True)\n",
    "\n",
    "        if not os.path.exists(csv_path):\n",
    "            print(f\"{'Corrected' if use_corrected_data else 'Uncorrected'} calcium signals file not found for session {session_id}\")\n",
    "            return\n",
    "\n",
    "        calcium_signals_df = pd.read_csv(csv_path)\n",
    "        frame_numbers = calcium_signals_df['Frame']\n",
    "        calcium_signals = calcium_signals_df.drop('Frame', axis=1)\n",
    "\n",
    "        for roi_label in calcium_signals:\n",
    "            plt.figure(figsize=(10, 5))\n",
    "            plt.plot(frame_numbers, calcium_signals[roi_label], label=roi_label)\n",
    "\n",
    "            for stim_time in stimulation_times:\n",
    "                plt.axvline(x=stim_time, color='red', linestyle='--', linewidth=1)\n",
    "\n",
    "            plt.title(f\"{roi_label} - Session {session_id} ({'Corrected' if use_corrected_data else 'Uncorrected'})\")\n",
    "            plt.xlabel('Frame Number')\n",
    "            plt.ylabel('Calcium Signal Intensity')\n",
    "            plt.legend()\n",
    "            plt.grid(True)\n",
    "\n",
    "            save_path = os.path.join(roi_output_dir, f\"{roi_label}_{'corrected_' if use_corrected_data else ''}signal_plot.png\")\n",
    "            plt.savefig(save_path, dpi=300, bbox_inches='tight')\n",
    "            plt.close()\n",
    "\n",
    "            print(f\"Plot for {roi_label} saved to {save_path}\")\n",
    "              \n",
    "    def save_individual_roi_plots_all_sessions(self, use_corrected_data=False):\n",
    "        results = {}\n",
    "        for session_id in self.directory_df['session_id'].tolist():\n",
    "            result = self.save_individual_roi_plots(session_id, use_corrected_data=use_corrected_data)\n",
    "            results[session_id] = result\n",
    "        return results\n",
    "        \n",
    "    def plot_roi_with_zoomed_stimulations(self, session_id):\n",
    "        processed_dir = 'processed_data/processed_image_analysis_output'\n",
    "        calcium_csv_suffix = '_calcium_signals.csv'\n",
    "\n",
    "        # Retrieve directory path and stimulation frames from DataFrame\n",
    "        directory_entry = self.directory_df[self.directory_df['session_id'] == session_id]\n",
    "        if directory_entry.empty:\n",
    "            print(f\"No directory entry found for session {session_id}\")\n",
    "            return\n",
    "\n",
    "        directory_path = directory_entry['directory_path'].values[0]\n",
    "        csv_path = os.path.join(directory_path, processed_dir, session_id + calcium_csv_suffix)\n",
    "        stimulation_frames = directory_entry['stimulation_frame_number'].iloc[0]  # Used directly as a list\n",
    "\n",
    "        # Read the calcium signals\n",
    "        calcium_signals_df = pd.read_csv(csv_path)\n",
    "        frame_numbers = calcium_signals_df['Frame']\n",
    "        calcium_signals = calcium_signals_df.drop('Frame', axis=1)\n",
    "        \n",
    "        # Determine the spacing factor based on the max calcium signal value\n",
    "        spacing_factor = calcium_signals.max().max() * 0.1  # For example, 10% of the max signal\n",
    "        \n",
    "        # Number of subplots based on the number of stimulations\n",
    "        num_stimulations = len(stimulation_frames)\n",
    "        num_rois = calcium_signals.shape[1]\n",
    "\n",
    "        # Create the figure with multiple subplots\n",
    "        fig, axs = plt.subplots(num_stimulations + 1, 1, figsize=(15, 5 * (num_stimulations + 1)), gridspec_kw={'height_ratios': [3] + [1]*num_stimulations})\n",
    "        \n",
    "        # Plot the full session signal in the first subplot\n",
    "        for i, col in enumerate(calcium_signals.columns):\n",
    "            axs[0].plot(frame_numbers, calcium_signals[col] + (i * spacing_factor), label=col)\n",
    "\n",
    "        # Add stimulation markers to the full session plot\n",
    "        for stim_frame in stimulation_frames:\n",
    "            axs[0].axvline(x=stim_frame, color='red', linestyle='--', linewidth=1)\n",
    "\n",
    "        # Zoom into each stimulation event in the subsequent subplots\n",
    "        for i, stim_frame in enumerate(stimulation_frames, start=1):\n",
    "            start_frame = max(stim_frame - 100, 0)\n",
    "            end_frame = min(stim_frame + 200, len(frame_numbers))\n",
    "            for j, col in enumerate(calcium_signals.columns):\n",
    "                signal_segment = calcium_signals[col][start_frame:end_frame]\n",
    "                frame_segment = frame_numbers[start_frame:end_frame]\n",
    "                axs[i].plot(frame_segment, signal_segment + (j * spacing_factor), label=col)\n",
    "\n",
    "            # Add a vertical line for the stimulation moment\n",
    "            axs[i].axvline(x=stim_frame, color='red', linestyle='--', linewidth=1)\n",
    "            axs[i].set_xlim([start_frame, end_frame])\n",
    "\n",
    "        # Adjust the layout and save the figure\n",
    "        plt.tight_layout()\n",
    "        plt.show()\n",
    "        save_path = os.path.join(directory_path, processed_dir, f\"{session_id}_detailed_ROI_analysis.png\")\n",
    "        fig.savefig(save_path, dpi=300)\n",
    "        plt.close(fig)\n",
    "\n",
    "        print(f\"Detailed ROI analysis figure saved to {save_path}\")\n",
    "        \n",
    "    def plot_and_save_roi_stimulations(self, session_id):\n",
    "        processed_dir = 'processed_data/processed_image_analysis_output'\n",
    "        calcium_csv_suffix = '_calcium_signals.csv'\n",
    "        \n",
    "\n",
    "        # Retrieve directory path from DataFrame\n",
    "        directory_entry = self.directory_df[self.directory_df['session_id'] == session_id]\n",
    "        if directory_entry.empty:\n",
    "            print(f\"No directory entry found for session {session_id}\")\n",
    "            return\n",
    "\n",
    "        directory_path = directory_entry['directory_path'].values[0]\n",
    "        csv_path = os.path.join(directory_path, processed_dir, session_id + calcium_csv_suffix)\n",
    "\n",
    "        if not os.path.exists(csv_path):\n",
    "            print(f\"Calcium signals file not found for session {session_id}\")\n",
    "            return\n",
    "\n",
    "        # Read calcium signals into DataFrame\n",
    "        calcium_signals_df = pd.read_csv(csv_path)\n",
    "        frame_numbers = calcium_signals_df['Frame']\n",
    "        calcium_signals = calcium_signals_df.drop('Frame', axis=1)\n",
    "\n",
    "        # Hardcoded stimulation frames\n",
    "        #stimulation_frames = [3587, 3788, 3990, 4191, 4393, 4595]\n",
    "        stimulation_frames = directory_entry['stimulation_frame_number'].iloc[0]  # Used directly as a list\n",
    "\n",
    "        # Ensure the output directory exists\n",
    "        roi_output_dir = os.path.join(directory_path, processed_dir, 'cell_roi_processed_data')\n",
    "        os.makedirs(roi_output_dir, exist_ok=True)\n",
    "\n",
    "        for roi_label in calcium_signals:\n",
    "            # Set up figure\n",
    "            num_plots = len(stimulation_frames) + 1\n",
    "            fig, axs = plt.subplots(num_plots, 1, figsize=(10, num_plots * 5))\n",
    "\n",
    "            # Plot the full signal\n",
    "            axs[0].plot(frame_numbers, calcium_signals[roi_label])\n",
    "            axs[0].set_title(f\"Full Session Calcium Signal for ROI {roi_label}\")\n",
    "            for stim_frame in stimulation_frames:\n",
    "                axs[0].axvline(x=stim_frame, color='red', linestyle='--', linewidth=0.5)\n",
    "            \n",
    "            # Plot zoomed-in stimulations\n",
    "            for idx, stim_frame in enumerate(stimulation_frames):\n",
    "                zoom_start = max(stim_frame - 100, 0)\n",
    "                zoom_end = min(stim_frame + 200, max(frame_numbers))\n",
    "                zoomed_signal = calcium_signals[roi_label][zoom_start:zoom_end]\n",
    "                zoomed_frame_numbers = frame_numbers[zoom_start:zoom_end]\n",
    "\n",
    "                axs[idx + 1].plot(zoomed_frame_numbers, zoomed_signal)\n",
    "                axs[idx + 1].axvline(x=stim_frame, color='red', linestyle='--', linewidth=0.5)\n",
    "                axs[idx + 1].set_xlim(zoom_start, zoom_end)\n",
    "                axs[idx + 1].set_title(f\"Stimulation at Frame {stim_frame}\")\n",
    "\n",
    "            # Finalize and save figure\n",
    "            plt.tight_layout()\n",
    "            fig.savefig(os.path.join(roi_output_dir, f\"{roi_label}_stimulation_plot.png\"), dpi=300)\n",
    "            plt.close()\n",
    "\n",
    "            print(f\"ROI {roi_label} plots saved in {roi_output_dir}\")\n",
    "            \n",
    "    def plot_and_save_roi_stimulations_all_sessions(self): \n",
    "        \n",
    "        results = {}\n",
    "        \n",
    "        for session_id in self.directory_df['session_id']:\n",
    "            result = self.plot_and_save_roi_stimulations(session_id)\n",
    "            results[session_id] = result\n",
    "        return results\n",
    "                          \n",
    "    def find_responsive_rois_first_stim_mean(self, session_id, pre_stim_duration=5, post_stim_duration=5, threshold=2):\n",
    "        processed_dir = 'processed_data/processed_image_analysis_output'\n",
    "        calcium_csv_suffix = '_calcium_signals.csv'\n",
    "\n",
    "        # Retrieve directory path from DataFrame\n",
    "        directory_entry = self.directory_df[self.directory_df['session_id'] == session_id]\n",
    "        if directory_entry.empty:\n",
    "            print(f\"No directory entry found for session {session_id}\")\n",
    "            return None\n",
    "\n",
    "        directory_path = directory_entry['directory_path'].values[0]\n",
    "        csv_path = os.path.join(directory_path, processed_dir, session_id + calcium_csv_suffix)\n",
    "\n",
    "        if not os.path.exists(csv_path):\n",
    "            print(f\"Calcium signals file not found for session {session_id}\")\n",
    "            return None\n",
    "\n",
    "        # Read calcium signals into DataFrame\n",
    "        calcium_signals_df = pd.read_csv(csv_path)\n",
    "        frame_numbers = calcium_signals_df['Frame']\n",
    "        calcium_signals = calcium_signals_df.drop('Frame', axis=1)  # Explicitly drop the 'Frame' column\n",
    "\n",
    "        # Use the hardcoded first stimulation frame\n",
    "        #first_stim_frame = [3587][0]  # Hardcoded first stimulation frame\n",
    "        first_stim_frame = directory_entry['stimulation_frame_number'].iloc[0][0]\n",
    "\n",
    "        responsive_rois = []\n",
    "        for roi_label in calcium_signals.columns:  # Iterate over ROI columns only\n",
    "            pre_stim_signal = calcium_signals.loc[(frame_numbers >= first_stim_frame-pre_stim_duration) & (frame_numbers < first_stim_frame), roi_label]\n",
    "            post_stim_signal = calcium_signals.loc[(frame_numbers >= first_stim_frame) & (frame_numbers < first_stim_frame+post_stim_duration), roi_label]\n",
    "\n",
    "            # Calculate the z-score for the difference in means\n",
    "            pre_mean = pre_stim_signal.mean()\n",
    "            post_mean = post_stim_signal.mean()\n",
    "            signal_change = post_mean - pre_mean\n",
    "\n",
    "            # Standard deviation of the pre-stimulus signal\n",
    "            pre_std = pre_stim_signal.std(ddof=1)  # Use ddof=1 for sample standard deviation\n",
    "            # Calculate the z-score\n",
    "            if pre_std > 0:\n",
    "                z_score = signal_change / pre_std\n",
    "            else:\n",
    "                z_score = 0\n",
    "            \n",
    "            #if abs(z_score) > threshold: # for absolute z-score\n",
    "            if z_score > threshold: # for positive z-score\n",
    "                responsive_rois.append(roi_label)\n",
    "                print(f\"ROI {roi_label} is responsive. Change: {signal_change:.2f}, Z-score: {z_score:.2f}\")\n",
    "\n",
    "\n",
    "        return responsive_rois\n",
    "    \n",
    "    def plot_responsive_rois_around_stim(self, session_id, pre_stim_duration=100, post_stim_duration=200, threshold=2):\n",
    "        responsive_rois = self.find_responsive_rois_first_stim_mean(session_id, pre_stim_duration=3, post_stim_duration=3, threshold=threshold)\n",
    "\n",
    "        if not responsive_rois:\n",
    "            print(\"No responsive ROIs found.\")\n",
    "            return\n",
    "\n",
    "        processed_dir = 'processed_data/processed_image_analysis_output'\n",
    "        calcium_csv_suffix = '_calcium_signals.csv'\n",
    "        directory_entry = self.directory_df[self.directory_df['session_id'] == session_id]\n",
    "        directory_path = directory_entry['directory_path'].values[0]\n",
    "        csv_path = os.path.join(directory_path, processed_dir, session_id + calcium_csv_suffix)\n",
    "\n",
    "        calcium_signals_df = pd.read_csv(csv_path)\n",
    "        #first_stim_frame = 3587  # Update this based on your actual first stim frame\n",
    "        first_stim_frame = directory_entry['stimulation_frame_number'].iloc[0][0]\n",
    "\n",
    "        plt.figure(figsize=(10, 6))\n",
    "\n",
    "        for roi_label in responsive_rois:\n",
    "            if roi_label in calcium_signals_df.columns:\n",
    "                roi_data = calcium_signals_df[[roi_label, 'Frame']]\n",
    "                \n",
    "                # Select data around the stimulation point\n",
    "                stim_start = max(first_stim_frame - pre_stim_duration, 0)\n",
    "                stim_end = min(first_stim_frame + post_stim_duration, max(calcium_signals_df['Frame']))\n",
    "                \n",
    "                roi_segment = roi_data[(roi_data['Frame'] >= stim_start) & (roi_data['Frame'] <= stim_end)]\n",
    "                \n",
    "                plt.plot(roi_segment['Frame'], roi_segment[roi_label], label=f'ROI {roi_label}')\n",
    "                plt.axvline(x=first_stim_frame, color='red', linestyle='--')\n",
    "\n",
    "        plt.xlabel('Frame Number')\n",
    "        plt.ylabel('Signal Intensity')\n",
    "        plt.title(f'Calcium Signals Around First Stimulation for Responsive ROIs in Session {session_id}')\n",
    "        plt.legend()\n",
    "        plt.tight_layout()\n",
    "\n",
    "        save_path = os.path.join(directory_path, processed_dir, f\"{session_id}_responsive_ROIs_around_stim.png\")\n",
    "        plt.savefig(save_path, dpi=300)\n",
    "        plt.close()\n",
    "\n",
    "        print(f\"Plot saved at {save_path}\")\n",
    "        \n",
    "    def plot_mean_and_sem_of_responsive_rois(self, session_id, pre_stim_duration=100, post_stim_duration=200, threshold=2):\n",
    "        responsive_rois = self.find_responsive_rois_first_stim_mean(session_id, pre_stim_duration, post_stim_duration, threshold)\n",
    "\n",
    "        if not responsive_rois:\n",
    "            print(\"No responsive ROIs found with a positive z-score.\")\n",
    "            return\n",
    "\n",
    "        processed_dir = 'processed_data/processed_image_analysis_output'\n",
    "        calcium_csv_suffix = '_calcium_signals.csv'\n",
    "        directory_entry = self.directory_df[self.directory_df['session_id'] == session_id]\n",
    "        directory_path = directory_entry['directory_path'].values[0]\n",
    "        csv_path = os.path.join(directory_path, processed_dir, session_id + calcium_csv_suffix)\n",
    "\n",
    "        calcium_signals_df = pd.read_csv(csv_path)\n",
    "        frame_numbers = calcium_signals_df['Frame']\n",
    "        \n",
    "        first_stim_frame = directory_entry['stimulation_frame_number'].iloc[0][0]  # Assuming the first element is the first stim frame\n",
    "\n",
    "        # Plot setup\n",
    "        plt.figure(figsize=(10, 6))\n",
    "        \n",
    "        #Compute mean and SEM only for the responsive ROIs\n",
    "        mean_response = calcium_signals_df[responsive_rois].mean(axis=1)\n",
    "        sem_response = calcium_signals_df[responsive_rois].sem(axis=1)\n",
    "\n",
    "        # Focus on the time around the first stimulation\n",
    "        stim_start = max(frame_numbers.searchsorted(first_stim_frame - pre_stim_duration), 0)\n",
    "        stim_end = min(frame_numbers.searchsorted(first_stim_frame + post_stim_duration), len(frame_numbers) - 1)\n",
    "        \n",
    "        # Extract the segment for plotting\n",
    "        frame_segment = frame_numbers.iloc[stim_start:stim_end + 1]\n",
    "        mean_segment = mean_response.iloc[stim_start:stim_end + 1]\n",
    "        sem_segment = sem_response.iloc[stim_start:stim_end + 1]\n",
    "\n",
    "        plt.figure(figsize=(10, 6))\n",
    "        plt.errorbar(frame_segment, mean_segment, yerr=sem_segment, fmt='-', color='blue', ecolor='lightblue', label='Mean +/- SEM')\n",
    "\n",
    "        # Stimulation line\n",
    "        plt.axvline(x=first_stim_frame, color='red', linestyle='--', label='First Stimulus')\n",
    "\n",
    "        # Labels and title\n",
    "        plt.xlabel('Frame Number')\n",
    "        plt.ylabel('Calcium Signal Intensity')\n",
    "        plt.title(f'Calcium Signals Around First Stimulation for Responsive ROIs in Session {session_id}')\n",
    "        plt.legend()\n",
    "        plt.tight_layout()\n",
    "\n",
    "        # Save the plot\n",
    "        save_path = os.path.join(directory_path, processed_dir, f\"{session_id}_responsive_ROIs_mean_sem.png\")\n",
    "        plt.savefig(save_path, dpi=300)\n",
    "        plt.close()\n",
    "\n",
    "        print(f\"Plot saved at {save_path}\")\n",
    "        \n",
    "    def plot_normalized_mean_and_sem_of_responsive_rois(self, session_id, pre_stim_duration=100, post_stim_duration=200, threshold=2):\n",
    "        responsive_rois = self.find_responsive_rois_first_stim_mean(session_id, pre_stim_duration, post_stim_duration, threshold)\n",
    "\n",
    "        if not responsive_rois:\n",
    "            print(\"No responsive ROIs found with a positive z-score.\")\n",
    "            return\n",
    "\n",
    "        processed_dir = 'processed_data/processed_image_analysis_output'\n",
    "        calcium_csv_suffix = '_calcium_signals.csv'\n",
    "        directory_entry = self.directory_df[self.directory_df['session_id'] == session_id]\n",
    "        directory_path = directory_entry['directory_path'].values[0]\n",
    "        csv_path = os.path.join(directory_path, processed_dir, session_id + calcium_csv_suffix)\n",
    "\n",
    "        calcium_signals_df = pd.read_csv(csv_path)\n",
    "        first_stim_frame = directory_entry['stimulation_frame_number'].iloc[0][0]  # Assuming the first element is the first stim frame\n",
    "\n",
    "        # Normalize the signals for each responsive ROI\n",
    "        normalized_signals = calcium_signals_df[responsive_rois].apply(lambda x: (x - x.min()) / (x.max() - x.min()))\n",
    "\n",
    "        # Compute mean and SEM for the normalized signals\n",
    "        mean_normalized_response = normalized_signals.mean(axis=1)\n",
    "        sem_normalized_response = normalized_signals.sem(axis=1)\n",
    "\n",
    "        # Focus on the time around the first stimulation\n",
    "        stim_start = max(first_stim_frame - pre_stim_duration, 0)\n",
    "        stim_end = min(first_stim_frame + post_stim_duration, len(calcium_signals_df))\n",
    "\n",
    "        # Corrected plotting section:\n",
    "        frame_mask = (calcium_signals_df['Frame'] >= stim_start-9) & (calcium_signals_df['Frame'] <= stim_end+100)\n",
    "\n",
    "        plt.figure(figsize=(10, 6))\n",
    "        plt.errorbar(calcium_signals_df.loc[frame_mask, 'Frame'], \n",
    "                    mean_normalized_response.loc[frame_mask], \n",
    "                    yerr=sem_normalized_response.loc[frame_mask], \n",
    "                    label='Normalized Mean +/- SEM', \n",
    "                    color='blue', \n",
    "                    ecolor='lightblue')\n",
    "\n",
    "\n",
    "\n",
    "        # Stimulation line\n",
    "        plt.axvline(x=first_stim_frame-1, color='red', linestyle='--', label='First Stimulus')\n",
    "\n",
    "        # Labels and title\n",
    "        plt.xlabel('Frame Number')\n",
    "        plt.ylabel('Normalized Calcium Signal Intensity')\n",
    "        plt.title(f'Normalized Calcium Signals Around First Stimulation for Responsive ROIs in Session {session_id}')\n",
    "        plt.legend()\n",
    "        plt.tight_layout()\n",
    "\n",
    "        # Save the plot\n",
    "        save_path = os.path.join(directory_path, processed_dir, f\"{session_id}_responsive_ROIs_normalized_mean_sem.png\")\n",
    "        plt.savefig(save_path, dpi=300)\n",
    "        plt.close()\n",
    "\n",
    "        print(f\"Normalized plot saved at {save_path}\")\n",
    "\n",
    "    def plot_normalized_mean_and_sem_of_all_stims(self, session_id, pre_stim_duration=100, post_stim_duration=200, threshold=2):\n",
    "        responsive_rois = self.find_responsive_rois_first_stim_mean(session_id, pre_stim_duration, post_stim_duration, threshold)\n",
    "\n",
    "        if not responsive_rois:\n",
    "            print(\"No responsive ROIs found with a positive z-score.\")\n",
    "            return\n",
    "\n",
    "        processed_dir = 'processed_data/processed_image_analysis_output'\n",
    "        calcium_csv_suffix = '_calcium_signals.csv'\n",
    "        directory_entry = self.directory_df[self.directory_df['session_id'] == session_id]\n",
    "        directory_path = directory_entry['directory_path'].values[0]\n",
    "        csv_path = os.path.join(directory_path, processed_dir, session_id + calcium_csv_suffix)\n",
    "\n",
    "        calcium_signals_df = pd.read_csv(csv_path)\n",
    "        stimulation_frames = directory_entry['stimulation_frame_number'].iloc[0]\n",
    "\n",
    "        # Normalize the signals for each responsive ROI\n",
    "        normalized_signals = calcium_signals_df[responsive_rois].apply(lambda x: (x - x.min()) / (x.max() - x.min()))\n",
    "\n",
    "        # Create a composite figure with subplots for each stimulation\n",
    "        num_stimulations = len(stimulation_frames)\n",
    "        \n",
    "        # Initialize numpy arrays for storing mean and SEM data\n",
    "        # Determine the response window size (modify this logic based on how you decide to handle edge cases)\n",
    "        response_window_size = pre_stim_duration + post_stim_duration\n",
    "        mean_responses = np.zeros((num_stimulations, response_window_size))\n",
    "        sem_responses = np.zeros((num_stimulations, response_window_size))\n",
    "        \n",
    "        \n",
    "        \n",
    "        fig, axs = plt.subplots(num_stimulations, 1, figsize=(10, 6 * num_stimulations))\n",
    "\n",
    "        for i, stim_frame in enumerate(stimulation_frames):\n",
    "            # Compute mean and SEM for the normalized signals focusing on the time around the stimulation\n",
    "            stim_start = max(stim_frame - pre_stim_duration, 0)\n",
    "            stim_end = min(stim_frame + post_stim_duration, len(calcium_signals_df))\n",
    "\n",
    "            frame_mask = (calcium_signals_df['Frame'] >= stim_start-9) & (calcium_signals_df['Frame'] <= stim_end+100)\n",
    "            mean_normalized_response = normalized_signals.loc[frame_mask].mean(axis=1)\n",
    "            sem_normalized_response = normalized_signals.loc[frame_mask].sem(axis=1)\n",
    "            \n",
    "            # Truncate or pad the response if necessary (this example assumes padding with zeros)\n",
    "            response_length = len(mean_normalized_response)\n",
    "            #print the length of the response\n",
    "            if response_length == response_window_size:\n",
    "                mean_responses[i, :] = mean_normalized_response.values\n",
    "                sem_responses[i, :] = sem_normalized_response.values\n",
    "            else:\n",
    "                # If the response length is less, pad the rest; if more, truncate (shouldn't occur with correct mask)\n",
    "                padded_mean = np.pad(mean_normalized_response.values, (0, response_window_size - response_length), 'constant', constant_values=(0, 0))\n",
    "                padded_sem = np.pad(sem_normalized_response.values, (0, response_window_size - response_length), 'constant', constant_values=(0, 0))\n",
    "                mean_responses[i, :] = padded_mean\n",
    "                sem_responses[i, :] = padded_sem\n",
    "\n",
    "            # Frame numbers for plotting\n",
    "            frame_numbers_for_plot = calcium_signals_df.loc[frame_mask, 'Frame']\n",
    "\n",
    "            # Filling between the SEM range around the mean\n",
    "            axs[i].fill_between(frame_numbers_for_plot,\n",
    "                                mean_normalized_response - sem_normalized_response,\n",
    "                                mean_normalized_response + sem_normalized_response,\n",
    "                                color='lightblue', alpha=0.5, label='SEM')\n",
    "\n",
    "            axs[i].plot(frame_numbers_for_plot,\n",
    "                        mean_normalized_response,\n",
    "                        color='blue', label=f'Normalized Mean (Stim {i+1})')\n",
    "\n",
    "            axs[i].axvline(x=stim_frame-1, color='red', linestyle='--', label='Stimulus')\n",
    "            axs[i].set_xlabel('Frame Number')\n",
    "            axs[i].set_ylabel('Normalized Calcium Signal Intensity')\n",
    "            axs[i].set_title(f'Normalized Signals Around Stim {i+1} for Responsive ROIs in Session {session_id}')\n",
    "            axs[i].legend()\n",
    "\n",
    "            plt.tight_layout()\n",
    "\n",
    "        # Save the composite figure\n",
    "        save_path = os.path.join(directory_path, processed_dir, f\"{session_id}_all_stims_responsive_ROIs_normalized_mean_sem.png\")\n",
    "        fig.savefig(save_path, dpi=300)\n",
    "        plt.close(fig)\n",
    "        \n",
    "        # Save the numpy arrays for later use\n",
    "        np.save(os.path.join(directory_path, processed_dir, f\"{session_id}_mean_responses.npy\"), mean_responses)\n",
    "        np.save(os.path.join(directory_path, processed_dir, f\"{session_id}_sem_responses.npy\"), sem_responses)\n",
    "\n",
    "        print(f\"Composite normalized plot saved and Mean and SEM response data saved at {save_path}\")\n",
    "        \n",
    "    def plot_overlaid_normalized_responses(self, session_id, pre_stim_duration=100, post_stim_duration=200, threshold=2):\n",
    "        responsive_rois = self.find_responsive_rois_first_stim_mean(session_id, pre_stim_duration, post_stim_duration, threshold)\n",
    "\n",
    "        if not responsive_rois:\n",
    "            print(\"No responsive ROIs found with a positive z-score.\")\n",
    "            return\n",
    "\n",
    "        processed_dir = 'processed_data/processed_image_analysis_output'\n",
    "        calcium_csv_suffix = '_calcium_signals.csv'\n",
    "        directory_entry = self.directory_df[self.directory_df['session_id'] == session_id]\n",
    "        directory_path = directory_entry['directory_path'].values[0]\n",
    "        csv_path = os.path.join(directory_path, processed_dir, session_id + calcium_csv_suffix)\n",
    "        stimulation_frames = directory_entry['stimulation_frame_number'].iloc[0]\n",
    "\n",
    "        calcium_signals_df = pd.read_csv(csv_path)\n",
    "        normalized_signals = calcium_signals_df[responsive_rois].apply(lambda x: (x - x.min()) / (x.max() - x.min()))\n",
    "\n",
    "        plt.figure(figsize=(10, 6))\n",
    "        colors = plt.cm.viridis(np.linspace(0, 1, len(stimulation_frames)))  # Color map for different stim intensities\n",
    "\n",
    "        for i, (stim_frame, color) in enumerate(zip(stimulation_frames, colors)):\n",
    "            stim_start = max(stim_frame - pre_stim_duration, 0)\n",
    "            stim_end = min(stim_frame + post_stim_duration, len(calcium_signals_df))\n",
    "\n",
    "            frame_mask = (calcium_signals_df['Frame'] >= stim_start-9) & (calcium_signals_df['Frame'] <= stim_end+100)\n",
    "            mean_normalized_response = normalized_signals.loc[frame_mask].mean(axis=1)\n",
    "            sem_normalized_response = normalized_signals.loc[frame_mask].sem(axis=1)\n",
    "\n",
    "            # Plotting the mean response with shaded SEM\n",
    "            frame_numbers_for_plot = calcium_signals_df.loc[frame_mask, 'Frame']\n",
    "            plt.fill_between(frame_numbers_for_plot,\n",
    "                            mean_normalized_response - sem_normalized_response,\n",
    "                            mean_normalized_response + sem_normalized_response,\n",
    "                            color=color, alpha=0.5)\n",
    "\n",
    "            plt.plot(frame_numbers_for_plot,\n",
    "                    mean_normalized_response,\n",
    "                    color=color, label=f'Stim {i+1}')\n",
    "\n",
    "        plt.axvline(x=stimulation_frames[0]-1, color='red', linestyle='--', label='First Stimulus')\n",
    "        plt.xlabel('Frame Number')\n",
    "        plt.ylabel('Normalized Calcium Signal Intensity')\n",
    "        plt.title(f'Overlaid Normalized Responses for Responsive ROIs in Session {session_id}')\n",
    "        plt.legend()\n",
    "        plt.tight_layout()\n",
    "\n",
    "        save_path = os.path.join(directory_path, processed_dir, f\"{session_id}_overlaid_normalized_responses.png\")\n",
    "        plt.savefig(save_path, dpi=300)\n",
    "        plt.close()\n",
    "\n",
    "        print(f\"Overlaid normalized responses plot saved at {save_path}\")\n",
    "        \n",
    "    def plot_mean_responses_from_file(self, session_id):\n",
    "        processed_dir = 'processed_data/processed_image_analysis_output'\n",
    "        directory_entry = self.directory_df[self.directory_df['session_id'] == session_id]\n",
    "        directory_path = directory_entry['directory_path'].values[0]\n",
    "        \n",
    "        # Construct the file path and load the data\n",
    "        mean_responses_path = os.path.join(directory_path, processed_dir, f\"{session_id}_mean_responses.npy\")\n",
    "        mean_responses = np.load(mean_responses_path)\n",
    "        \n",
    "\n",
    "        # Check if mean_responses is empty or not\n",
    "        if mean_responses.size == 0:\n",
    "            print(\"No data found in the mean responses file.\")\n",
    "            return\n",
    "        \n",
    "        #print the shape of the mean_responses\n",
    "        print(mean_responses.shape)\n",
    "        \n",
    "        num_stimulations = mean_responses.shape[0]\n",
    "        response_window_size = mean_responses.shape[1]\n",
    "        \n",
    "        # Plotting\n",
    "        plt.figure(figsize=(10, 6))\n",
    "        for i in range(num_stimulations):\n",
    "            plt.plot(mean_responses[i, :], label=f'Stim {i+1}')\n",
    "        \n",
    "        plt.xlabel('Time Point')\n",
    "        plt.ylabel('Normalized Mean Response')\n",
    "        plt.title(f'Normalized Mean Responses for All Stimulations in Session {session_id}')\n",
    "        plt.legend()\n",
    "        plt.tight_layout()\n",
    "        plt.show()\n",
    "    \n",
    "    def create_trial_locked_calcium_signals(self, session_id, use_corrected_data=False):\n",
    "        \"\"\"\n",
    "        Generate trial-locked calcium signal data for a given session ID, allowing\n",
    "        the choice between corrected and uncorrected data.\n",
    "        \n",
    "        Parameters\n",
    "        ----------\n",
    "        session_id : str\n",
    "            The session ID for which to generate trial-locked signals.\n",
    "        use_corrected_data : bool, optional\n",
    "            Whether to use corrected calcium signal data. The default is False, which uses uncorrected data.\n",
    "        \n",
    "        Returns\n",
    "        -------\n",
    "        tuple\n",
    "            A tuple containing the stimulation frame numbers, ROI data, and stimulation IDs.\n",
    "        \"\"\"\n",
    "\n",
    "        processed_dir = 'processed_data/processed_image_analysis_output'\n",
    "        calcium_csv_suffix = '_corrected_calcium_signals.csv' if use_corrected_data else '_calcium_signals.csv'\n",
    "\n",
    "        directory_entry = self.directory_df[self.directory_df['session_id'] == session_id]\n",
    "\n",
    "        if directory_entry.empty:\n",
    "            print(f\"No directory entry found for session {session_id}\")\n",
    "            return None, None, None\n",
    "\n",
    "        directory_path = directory_entry['directory_path'].values[0]\n",
    "        csv_path = os.path.join(directory_path, processed_dir, f\"{session_id}{calcium_csv_suffix}\")\n",
    "\n",
    "        if not os.path.exists(csv_path):\n",
    "            print(f\"Calcium signals file not found for session {session_id} using {'corrected' if use_corrected_data else 'uncorrected'} data\")\n",
    "            return None, None, None\n",
    "\n",
    "        calcium_signals_df = pd.read_csv(csv_path)\n",
    "        stim_frame_numbers = directory_entry['stimulation_frame_number'].values[0]\n",
    "        stimulation_ids = directory_entry['stimulation_ids'].values[0]\n",
    "\n",
    "        pre_stim_frames = 10\n",
    "        post_stim_frames = 100\n",
    "\n",
    "        roi_data = {roi: {} for roi in calcium_signals_df.columns if 'ROI' in roi}\n",
    "\n",
    "        for stim_id, stim_frame in zip(stimulation_ids, stim_frame_numbers):\n",
    "            start_idx = max(stim_frame - pre_stim_frames, 0) \n",
    "            end_idx = min(stim_frame + post_stim_frames, len(calcium_signals_df))\n",
    "\n",
    "            for roi in roi_data:\n",
    "                trial = calcium_signals_df.loc[start_idx:end_idx, roi]\n",
    "                roi_data[roi][(stim_id, stim_frame)] = trial.to_numpy()\n",
    "\n",
    "        return stim_frame_numbers, roi_data, stimulation_ids\n",
    "    \n",
    "    def process_all_sessions(self, use_corrected_data=False):\n",
    "        \"\"\"\n",
    "        Process all sessions using either corrected or uncorrected calcium signal data.\n",
    "\n",
    "        Parameters\n",
    "        ----------\n",
    "        use_corrected_data : bool, optional\n",
    "            Flag indicating whether to use corrected calcium signals. Defaults to False, \n",
    "            indicating uncorrected data should be used.\n",
    "\n",
    "        Returns\n",
    "        -------\n",
    "        dict\n",
    "            A dictionary with processed data for all sessions, keyed by session ID.\n",
    "        \"\"\"\n",
    "        all_data = {}\n",
    "        for session_id in self.directory_df['session_id'].unique():\n",
    "            stim_frame_numbers, roi_data, stimulation_ids = self.create_trial_locked_calcium_signals(session_id, use_corrected_data=use_corrected_data)\n",
    "            if stim_frame_numbers and roi_data and stimulation_ids:  # Ensure data was returned\n",
    "                all_data[session_id] = {\n",
    "                    'stim_frame_numbers': stim_frame_numbers,\n",
    "                    'roi_data': roi_data,\n",
    "                    'stimulation_ids': stimulation_ids\n",
    "                }\n",
    "        return all_data\n",
    "    \n",
    "    def process_all_sessions_entire_recording(self, use_corrected_data=False):\n",
    "        \"\"\"\n",
    "        Processes all sessions and stores calcium signal dataframes in a dictionary.\n",
    "\n",
    "        Parameters\n",
    "        ----------\n",
    "        use_corrected_data : bool, optional\n",
    "            Whether to use corrected calcium signal data. The default is False, which uses uncorrected data.\n",
    "\n",
    "        Returns\n",
    "        -------\n",
    "        dict\n",
    "            A dictionary where each key is a session ID and the value is the corresponding calcium_signals dataframe.\n",
    "        \"\"\"\n",
    "        processed_dir = 'processed_data/processed_image_analysis_output'\n",
    "        calcium_csv_suffix = '_corrected_calcium_signals.csv' if use_corrected_data else '_calcium_signals.csv'\n",
    "        session_data = {}\n",
    "\n",
    "        for session_id in self.directory_df['session_id'].unique():\n",
    "            directory_entry = self.directory_df[self.directory_df['session_id'] == session_id]\n",
    "\n",
    "            if directory_entry.empty:\n",
    "                print(f\"No directory entry found for session {session_id}\")\n",
    "                continue  # Skip this session and proceed with the next\n",
    "\n",
    "            directory_path = directory_entry['directory_path'].values[0]\n",
    "            csv_path = os.path.join(directory_path, processed_dir, f\"{session_id}{calcium_csv_suffix}\")\n",
    "\n",
    "            if not os.path.exists(csv_path):\n",
    "                print(f\"Calcium signals file not found for session {session_id} using {'corrected' if use_corrected_data else 'uncorrected'} data\")\n",
    "                continue  # Skip this session and proceed with the next\n",
    "\n",
    "            calcium_signals_df = pd.read_csv(csv_path)\n",
    "            # Store the dataframe in the dictionary with session_id as the key\n",
    "            session_data[session_id] = calcium_signals_df\n",
    "\n",
    "        return session_data\n",
    "            \n",
    "            \n",
    "    def preprocess_and_extract_signals(self, session_id):\n",
    "        \"\"\"\n",
    "        Renamed and extended functionality to include pre-processing of bioluminescence video data.\n",
    "        Corrects the \"Dark signal\" for each ROI by calculating the mean of the first 100 frames\n",
    "        of the signal and subtracts this value for each ROI from the entire series. Negative \n",
    "        values resulting from this subtraction are set as NaN.\n",
    "\n",
    "        Parameters\n",
    "        ----------\n",
    "        session_id : str\n",
    "            Unique identifier for the experimental session.\n",
    "\n",
    "        Returns\n",
    "        -------\n",
    "        dict\n",
    "            A dictionary containing processed and extracted calcium signal data for the session.\n",
    "        \"\"\"\n",
    "        \n",
    "        \n",
    "            \n",
    "        processed_dir = 'processed_data/processed_image_analysis_output'\n",
    "        calcium_csv_suffix = '_calcium_signals.csv'\n",
    "\n",
    "        directory_entry = self.directory_df[self.directory_df['session_id'] == session_id] #pull out the entry for the given session_id from the directory dataframe\n",
    "            \n",
    "        #pull out the list of stimulation frame numbers for the given session_id under the stimulation_frame_number column\n",
    "        stim_frame_numbers = directory_entry['stimulation_frame_number'].values[0]\n",
    "            \n",
    "            #pull out the stimulation label for the given session_id under the stimulation_label column\n",
    "        stimulation_ids = directory_entry['stimulation_ids'].values[0]\n",
    "            \n",
    "        if directory_entry.empty:\n",
    "            print(f\"No directory entry found for session {session_id}\")\n",
    "            return\n",
    "\n",
    "        directory_path = directory_entry['directory_path'].values[0]\n",
    "        csv_path = os.path.join(directory_path, processed_dir, session_id + calcium_csv_suffix)\n",
    "\n",
    "        if not os.path.exists(csv_path):\n",
    "            print(f\"Calcium signals file not found for session {session_id}\")\n",
    "            return\n",
    "        \n",
    "        # ... (existing code remains unchanged up to calcium_signals_df loading)\n",
    "\n",
    "        calcium_signals_df = pd.read_csv(csv_path) #import the calcium signals csv file\n",
    "        \n",
    "        # Correct the \"Dark signal\" for each ROI\n",
    "        for roi in calcium_signals_df.columns:\n",
    "            if 'ROI' in roi:  # Assuming ROI columns are prefixed with 'ROI'\n",
    "                # Calculate the mean of the first 100 frames for the dark signal\n",
    "                dark_signal_mean = calcium_signals_df[roi][:100].mean()\n",
    "                # Subtract the dark signal mean from the entire series for this ROI\n",
    "                calcium_signals_df[roi] = calcium_signals_df[roi] - dark_signal_mean\n",
    "                # Set negative values to NaN\n",
    "                calcium_signals_df.loc[calcium_signals_df[roi] < 0, roi] = np.nan\n",
    "\n",
    "            # Convert the values in the calcium_signals dataframe to integers with no decimal points\n",
    "            # Note: This may not be applicable anymore since you will have NaNs after correction\n",
    "            # calcium_signals_df = calcium_signals_df.astype(int)\n",
    "            \n",
    "            # ... (the rest of your existing code for extracting trial-locked signals)\n",
    "            #convert the values in the calcium_signals dataframe to integers with no decimal points\n",
    "            calcium_signals_df = calcium_signals_df.astype(int)\n",
    "            \n",
    "            # Parameters for alignment\n",
    "            pre_stim_frames = 10  # Number of frames before stimulation to include\n",
    "            post_stim_frames = 100  # Number of frames after stimulation to include\n",
    "            \n",
    "            # Create a nested dictionary where each key-value pair corresponds to a different ROI. \n",
    "            # For each ROI, you have another dictionary where the key is a tuple of (stimulation_id, stim_frame_number), \n",
    "            # and the value is a NumPy array containing the calcium signal values for a window around the stimulation frame.\n",
    "\n",
    "            # Initialize a nested dictionary to hold ROI, stimulation ID and frame number, and data\n",
    "            roi_data = {roi: {} for roi in calcium_signals_df.columns if 'ROI' in roi}\n",
    "\n",
    "            # Loop through each stimulation frame number and their corresponding stimulation IDs\n",
    "            for stim_id, stim_frame in zip(stimulation_ids, stim_frame_numbers):\n",
    "                # Calculate the index range for frames to extract\n",
    "                start_idx = max(stim_frame - pre_stim_frames, 0)  # Ensure index is not negative\n",
    "                end_idx = min(stim_frame + post_stim_frames, len(calcium_signals_df))  # Ensure index is within range\n",
    "\n",
    "                # Loop through each ROI column\n",
    "                for roi in roi_data:\n",
    "                    # Extract the relevant section of the calcium signals for the ROI\n",
    "                    trial = calcium_signals_df.loc[start_idx:end_idx, roi]\n",
    "\n",
    "                    # Store the trial data as a NumPy array in the nested dictionary\n",
    "                    # Using a tuple of (stimulation_id, stim_frame_number) as the key\n",
    "                    roi_data[roi][(stim_id, stim_frame)] = trial.to_numpy().astype(int)\n",
    "            \n",
    "        return  stim_frame_numbers, roi_data, stimulation_ids\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#instantiates an ImageAnalysis object\n",
    "project_folder = '/Volumes/MannySSD/cablam_imaging/raw_data_for_analysis' #path to the folder containing the raw data to be analyzed (i.e. the folder containing the folders for each experiment)\n",
    "analysis = ImageAnalysis(project_folder)\n",
    "print(analysis.directory_df)\n",
    "analysis.directory_df\n",
    "#expand the directory dataframe with the new columns\n",
    "analysis.expand_directory_df()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "analysis_cablam = ImageAnalysis(project_folder)\n",
    "analysis_cablam.expand_directory_df()\n",
    "analysis_cablam.directory_df = analysis_cablam.directory_df[(analysis_cablam.directory_df['sensor_type'] == 'cablam') & (analysis_cablam.directory_df['directory_name'].str.contains('05xfz'))]\n",
    "analysis_cablam.directory_df\n",
    "\n",
    "analysis_gcamp8 = ImageAnalysis(project_folder)\n",
    "analysis_gcamp8.expand_directory_df()\n",
    "analysis_gcamp8.directory_df = analysis_gcamp8.directory_df[(analysis_gcamp8.directory_df['sensor_type'] == 'gcamp8')]\n",
    "analysis_gcamp8.directory_df\n",
    "\n",
    "analysis_cablam1x = ImageAnalysis(project_folder)\n",
    "analysis_cablam1x.expand_directory_df()\n",
    "analysis_cablam1x.directory_df = analysis_cablam1x.directory_df[(analysis_cablam1x.directory_df['sensor_type'] == 'cablam') & (analysis_cablam1x.directory_df['directory_name'].str.contains('1xfz'))]\n",
    "analysis_cablam1x.directory_df\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "session_ids = analysis.directory_df['session_id']\n",
    "print(session_ids)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Usage example with a given session_id, assuming the session_id is present in the directory DataFrame and has a .tif file\n",
    "session_id = '1212232023'  # Replace with your actual session_id\n",
    "raw_data_path = analysis.get_session_raw_data(session_id) #get the raw data path for the given session_id\n",
    "\n",
    "# below is the code to generate the max projection image for the raw data at the raw_data_path \n",
    "if raw_data_path and not raw_data_path.startswith(\"No .tif file\"): #if the raw data path was found and does not start with \"No .tif file\"\n",
    "    max_proj_image = analysis.max_projection_mean_values(raw_data_path) #generate the max projection image \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Assuming you've already initialized your ImageAnalysis instance and populated directory_df:\n",
    "analysis.add_tiff_dimensions()\n",
    "\n",
    "# Now the directory_df has the dimensions for each TIFF file included\n",
    "print(analysis.directory_df.head())  # Display the updated DataFrame to verify\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "analysis.directory_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# run the analysis on all sessions in the directory_df\n",
    "\n",
    "#define a wrapper function to apply the max_projection_mean_values method to all sessions\n",
    "def analyze_session_max_projection(session_id):\n",
    "    \"\"\"\n",
    "    Wrapper function to apply max_projection_mean_values to a session's TIF file.\n",
    "\n",
    "    Parameters:\n",
    "    session_id (str): The session ID for which the TIF file will be processed.\n",
    "\n",
    "    Returns:\n",
    "    str: Path to the processed max projection TIFF file.\n",
    "    \"\"\"\n",
    "    # analysis is an instance of ImageAnalysis\n",
    "    tif_path = analysis.get_session_raw_data(session_id)\n",
    "    if isinstance(tif_path, str) and tif_path.endswith('.tif'):\n",
    "        return analysis.max_projection_mean_values(tif_path)\n",
    "    else:\n",
    "        return f\"No valid TIF file found for session {session_id}\"# Apply max_projection_mean_values to all sessions\n",
    "\n",
    "results = analysis.analyze_all_sessions(analyze_session_max_projection)\n",
    "\n",
    "# Output the results\n",
    "for session_id, result_path in results.items():\n",
    "    if isinstance(result_path, str):\n",
    "        print(f\"Session ID {session_id}: Max projection image saved at {result_path}\")\n",
    "    else:\n",
    "        print(f\"Session ID {session_id}: {result_path}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Analyze ROIs for all sessions\n",
    "analysis.analyze_all_rois()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# extract the calcium signal for a given session_id\n",
    "\n",
    "session_id = '1212232023'  # Replace with your actual session_id\n",
    "calcium_signals_path = analysis.extract_calcium_signals(session_id)\n",
    "print(f\"Calcium signals saved at: {calcium_signals_path}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#extract calcium signals for all sessions in the directory_df, confirms the location of the saved calcium signals and the location of the saved calcium signals\n",
    "\n",
    "all_results = analysis.analyze_all_calcium_signals()\n",
    "\n",
    "for session_id, csv_path in all_results.items():\n",
    "    if isinstance(csv_path, str):\n",
    "        print(f\"Session {session_id} - Calcium signals saved at: {csv_path}\")\n",
    "    else:\n",
    "        print(f\"Session {session_id} - Error: {csv_path}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "all_data = analysis.process_all_sessions(use_corrected_data=False)\n",
    "all_data_gcamp8 = analysis_gcamp8.process_all_sessions(use_corrected_data=False)\n",
    "all_data_cablam = analysis_cablam.process_all_sessions(use_corrected_data=True)\n",
    "all_data_cablam1x = analysis_cablam1x.process_all_sessions(use_corrected_data=True)\n",
    "\n",
    "#lets now extract the entire ROIs for all session in the directory_df and save as an attribuye \n",
    "all_data_cablam_session_data = analysis_cablam.process_all_sessions_entire_recording(use_corrected_data=True)\n",
    "all_data_cablam1x_session_data = analysis_cablam1x.process_all_sessions_entire_recording(use_corrected_data=True)\n",
    "all_data_gcamp8_session_data = analysis_gcamp8.process_all_sessions_entire_recording(use_corrected_data=False)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import importlib\n",
    "import BL_CalciumAnalysis.image_analysis_methods as iam\n",
    "\n",
    "importlib.reload(iam)\n",
    "from BL_CalciumAnalysis.image_analysis_methods import print_cells_per_recording\n",
    "\n",
    "print_cells_per_recording({\n",
    "    \"GCaMP\": all_data_gcamp8,\n",
    "    \"Cablam 1x\": all_data_cablam1x,\n",
    "    \"Cablam 0.5x\": all_data_cablam,\n",
    "})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "all_data\n",
    "all_data_gcamp8\n",
    "all_data_cablam1x\n",
    "all_data_cablam\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#print every llevel of all_data_cablam with descriptive text\n",
    "for session_id, session_data in all_data_gcamp8.items():\n",
    "    print(f\"Session ID: {session_id}\")\n",
    "    print(f\"Stimulation Frame Numbers: {session_data['stim_frame_numbers']}\")\n",
    "    print(f\"Stimulation IDs: {session_data['stimulation_ids']}\")\n",
    "    for roi, roi_data in session_data['roi_data'].items():\n",
    "        print(f\"ROI: {roi}\")\n",
    "        for key, value in roi_data.items():\n",
    "            print(f\"Stimulation ID, Frame Number: {key}\")\n",
    "            print(f\"Data: {value}\")\n",
    "    print(\"\\n\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#this function plots the mean respnonse for each session giveb a specific stim_id\n",
    "\n",
    "def plot_mean_response_for_session_with_nans(roi_data, stim_id):\n",
    "    \"\"\"\n",
    "    Plots the mean response for a given stim_id across all ROIs for a single session's data,\n",
    "    accounting for potential NaN values in the data.\n",
    "\n",
    "    :param roi_data: The roi_data for a single session (a dictionary with ROIs as keys and data as values).\n",
    "    :param stim_id: The stimulation ID to plot data for.\n",
    "    \"\"\"\n",
    "    selected_data = {}\n",
    "    for roi, stim_data in roi_data.items():\n",
    "        for (current_stim_id, _), data in stim_data.items():\n",
    "            if current_stim_id == stim_id:\n",
    "                # Select the data even if it contains NaNs; they will be ignored in the mean and std calculations\n",
    "                selected_data[roi] = data\n",
    "\n",
    "    # Ensure there is data to plot\n",
    "    if not selected_data:\n",
    "        print(f\"No data found for stim_id {stim_id}\")\n",
    "        return\n",
    "\n",
    "    # Use np.nanmean and np.nanstd to compute the statistics while ignoring NaNs\n",
    "    stacked_data = np.stack(list(selected_data.values()))\n",
    "    mean_response = np.nanmedian(stacked_data, axis=0)\n",
    "    sem_response = np.nanstd(stacked_data, axis=0, ddof=1) / np.sqrt(np.sum(~np.isnan(stacked_data), axis=0))\n",
    "    \n",
    "    # Count the number of contributing ROIs at each time point\n",
    "    valid_counts = np.sum(~np.isnan(stacked_data), axis=0)\n",
    "    print(f\"Number of contributing ROIs at each time point: {valid_counts}\")\n",
    "    \n",
    "    time_points = np.arange(-10, 101)  # Assuming the same time range as before\n",
    "\n",
    "    plt.figure(figsize=(10, 5))\n",
    "    plt.plot(time_points, mean_response, label='Mean Response')\n",
    "    plt.fill_between(time_points, mean_response - sem_response, mean_response + sem_response, alpha=0.3, label='SEM')\n",
    "\n",
    "    # Add red dotted lines at time point 0\n",
    "    plt.axvline(x=0, color='red', linestyle='--', linewidth=1)\n",
    "\n",
    "    plt.xlabel('Time (relative to stimulus)')\n",
    "    plt.ylabel('Calcium Signal')\n",
    "    plt.title(f'Median Calcium Response for Stim ID {stim_id}')\n",
    "    plt.legend()\n",
    "    plt.show()\n",
    "    \n",
    "    return valid_counts\n",
    "\n",
    "        \n",
    "# Now to iterate over all sessions and plot for a specific stim_id\n",
    "def plot_all_sessions_with_nans(all_data, stim_id=12):\n",
    "    for session_id, session_data in all_data.items():\n",
    "        print(f\"Plotting for session {session_id}\")\n",
    "        plot_mean_response_for_session_with_nans(session_data['roi_data'], stim_id)\n",
    "        \n",
    "#run the plot_all_sessions function\n",
    "\n",
    "\n",
    "plot_all_sessions_with_nans(all_data_cablam, stim_id=12)\n",
    "plot_all_sessions_with_nans(all_data_gcamp8, stim_id=12)\n",
    "\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def compile_pooled_responses_with_nans(all_data):\n",
    "    \"\"\"\n",
    "    Compiles the mean response and SEM for each stim_id pooled across all ROIs and all sessions,\n",
    "    accounting for potential NaN values in the data.\n",
    "\n",
    "    :param all_data: The dictionary containing all session data.\n",
    "    :return: A dictionary with the pooled mean responses and SEMs, considering NaNs.\n",
    "    \"\"\"\n",
    "    pooled_responses = {}\n",
    "\n",
    "    # Get all unique stim_ids from the data, considering all sessions and ROIs\n",
    "    unique_stim_ids = set()\n",
    "    for session_data in all_data.values():\n",
    "        for roi_data in session_data['roi_data'].values():\n",
    "            unique_stim_ids.update(stim_id for stim_id, _ in roi_data.keys())\n",
    "\n",
    "    # Aggregate data for each stim_id and calculate mean and SEM, ignoring NaNs\n",
    "    for stim_id in unique_stim_ids:\n",
    "        pooled_data = []\n",
    "        for session_data in all_data.items():\n",
    "            roi_data = session_data[1]['roi_data']  # Access session data\n",
    "            for roi, stim_data in roi_data.items():\n",
    "                for (current_stim_id, _), data in stim_data.items():\n",
    "                    if current_stim_id == stim_id:\n",
    "                        pooled_data.append(data)\n",
    "\n",
    "        # Check if there is any data collected for the stim_id\n",
    "        if pooled_data:\n",
    "            # Stack the pooled data and compute statistics ignoring NaN values\n",
    "            stacked_data = np.stack(pooled_data)\n",
    "            mean_response = np.nanmean(stacked_data, axis=0)\n",
    "            sem_response = np.nanstd(stacked_data, axis=0, ddof=1) / np.sqrt(np.sum(~np.isnan(stacked_data), axis=0))\n",
    "\n",
    "            # Store the computed mean response and SEM for each stim_id\n",
    "            if stim_id not in pooled_responses:\n",
    "                pooled_responses[stim_id] = {}\n",
    "            pooled_responses[stim_id]['mean_response'] = mean_response\n",
    "            pooled_responses[stim_id]['sem_response'] = sem_response\n",
    "\n",
    "    return pooled_responses\n",
    "\n",
    "pooled_nans_responses_gcamp8 = compile_pooled_responses_with_nans(all_data_gcamp8)\n",
    "pooled_nans_responses_cablam = compile_pooled_responses_with_nans(all_data_cablam)\n",
    "pooled_nans_responses_cablam1x = compile_pooled_responses_with_nans(all_data_cablam1x)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def plot_delta_f_over_f_with_nans(pooled_responses, specific_stim_ids=None, base_color='green', subtitle=''):\n",
    "        \"\"\"\n",
    "        Plots the normalized calcium responses (F/F) for all or specific stimulation IDs,\n",
    "        handling NaN values in the responses. The line opacity reflects the intensity of the stimulation ID.\n",
    "        \n",
    "        Parameters\n",
    "        ----------\n",
    "        pooled_responses : dict\n",
    "            A dictionary with stim IDs as keys and 'mean_response' and 'sem_response' as subkeys,\n",
    "            potentially containing NaN values.\n",
    "        specific_stim_ids : list of int, optional\n",
    "            A list of stimulation IDs to be plotted. If None, all stim IDs are plotted. If an invalid stim ID is\n",
    "            provided, a ValueError is raised.\n",
    "        base_color : str, optional\n",
    "            The color of the plot lines. The opacity of this color is adjusted based on the stimulation ID intensity.\n",
    "        \n",
    "        Raises\n",
    "        ------\n",
    "        ValueError\n",
    "            If a specified stim ID is not present in the data.\n",
    "        \"\"\"\n",
    "        plt.figure(figsize=(10, 5))\n",
    "        \n",
    "        if specific_stim_ids is not None:\n",
    "            invalid_stim_ids = set(specific_stim_ids) - set(pooled_responses.keys())\n",
    "            if invalid_stim_ids:\n",
    "                raise ValueError(f\"Invalid stim IDs provided: {invalid_stim_ids}\")\n",
    "            stim_ids = specific_stim_ids\n",
    "        else:\n",
    "            stim_ids = sorted(pooled_responses.keys())\n",
    "        \n",
    "        min_stim_id, max_stim_id = min(stim_ids), max(stim_ids)\n",
    "\n",
    "        for stim_id in stim_ids:\n",
    "            response = pooled_responses[stim_id]['mean_response']\n",
    "            baseline = np.nanmedian(response[:10])  # Use np.nanmean to ignore NaNs in baseline calculation\n",
    "            delta_f_over_f = (response - baseline) / baseline if baseline != 0 else np.zeros_like(response)\n",
    "            \n",
    "            alpha = 0.1 + 0.9 * (stim_id - min_stim_id) / (max_stim_id - min_stim_id)\n",
    "            time_points = np.arange(-10, len(response) - 10)\n",
    "\n",
    "            plt.plot(time_points, delta_f_over_f, label=f'Stim ID {stim_id}', color=base_color, alpha=alpha)\n",
    "\n",
    "        plt.xlabel('Time (relative to stimulus)')\n",
    "        plt.ylabel(r'$\\Delta F/F$')\n",
    "        # Set the main title and the custom subtitle\n",
    "        plt.suptitle('Normalized Calcium Responses (F/F) for Selected Stimulation IDs', fontsize=14)\n",
    "        plt.title(subtitle, fontsize=10)  # Set the subtitle based on the input\n",
    "        plt.legend()\n",
    "        plt.show()\n",
    "\n",
    "\n",
    "\n",
    "plot_delta_f_over_f_with_nans(pooled_nans_responses_gcamp8, specific_stim_ids=[12, 24, 36, 60, 120, 480], base_color='green', subtitle='GCaMP8s')\n",
    "plot_delta_f_over_f_with_nans(pooled_nans_responses_cablam, specific_stim_ids=[12, 24, 36, 60, 120, 480], base_color='red', subtitle='CaBLAM with 1/2x Fz Dilution')\n",
    "plot_delta_f_over_f_with_nans(pooled_nans_responses_cablam1x, specific_stim_ids=[12, 24, 36, 60, 120, 480], base_color='blue', subtitle='CaBLAM with 1x Fz Dilution')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "def plot_delta_f_over_f_with_nans(pooled_responses, specific_stim_ids=None, base_color='green', subtitle='', plot_style='mean'):\n",
    "    \"\"\"\n",
    "    Plots the normalized calcium responses (F/F) for all or specific stimulation IDs,\n",
    "    with options for plotting style including mean only or mean with SEM as dotted lines.\n",
    "    \n",
    "    Parameters\n",
    "    ----------\n",
    "    pooled_responses : dict\n",
    "        A dictionary with stim IDs as keys and 'mean_response' and 'sem_response' as subkeys,\n",
    "        potentially containing NaN values.\n",
    "    specific_stim_ids : list of int, optional\n",
    "        A list of stimulation IDs to be plotted.\n",
    "    base_color : str, optional\n",
    "        The color of the plot lines.\n",
    "    subtitle : str, optional\n",
    "        Custom subtitle text for the plot.\n",
    "    plot_style : str, optional\n",
    "        The plotting style: 'mean' (default) or 'mean_sem'.\n",
    "    \"\"\"\n",
    "    plt.figure(figsize=(10, 5))\n",
    "    \n",
    "    if specific_stim_ids is not None:\n",
    "        invalid_stim_ids = set(specific_stim_ids) - set(pooled_responses.keys())\n",
    "        if invalid_stim_ids:\n",
    "            raise ValueError(f\"Invalid stim IDs provided: {invalid_stim_ids}\")\n",
    "        stim_ids = specific_stim_ids\n",
    "    else:\n",
    "        stim_ids = sorted(pooled_responses.keys())\n",
    "    \n",
    "    min_stim_id, max_stim_id = min(stim_ids), max(stim_ids)\n",
    "\n",
    "    for stim_id in stim_ids:\n",
    "        response = pooled_responses[stim_id]['mean_response']\n",
    "        baseline = np.nanmedian(response[:10])\n",
    "        delta_f_over_f = (response - baseline) / baseline if baseline != 0 else np.zeros_like(response)\n",
    "        sem = pooled_responses[stim_id]['sem_response'] / baseline if baseline != 0 else np.zeros_like(response)\n",
    "\n",
    "        alpha = 0.1 + 0.9 * (stim_id - min_stim_id) / (max_stim_id - min_stim_id)\n",
    "        time_points = np.arange(-10, len(response) - 10)\n",
    "        \n",
    "        # Plot mean\n",
    "        plt.plot(time_points, delta_f_over_f, label=f'Stim ID {stim_id}', color=base_color, alpha=alpha)\n",
    "\n",
    "        # If 'mean_sem' style is chosen, also plot SEM as dotted lines\n",
    "        if plot_style == 'mean_sem':\n",
    "            plt.plot(time_points, delta_f_over_f + sem, linestyle='--', color=base_color, alpha=alpha)\n",
    "            plt.plot(time_points, delta_f_over_f - sem, linestyle='--', color=base_color, alpha=alpha)\n",
    "\n",
    "    plt.suptitle('Normalized Calcium Responses (F/F)', fontsize=14)\n",
    "    plt.title(subtitle, fontsize=10)\n",
    "    plt.xlabel('Time (relative to stimulus)')\n",
    "    plt.ylabel(r'$\\Delta F/F$')\n",
    "    plt.legend()\n",
    "    plt.show()\n",
    "    \n",
    "plot_delta_f_over_f_with_nans(pooled_nans_responses_gcamp8, specific_stim_ids=[12, 24, 36, 60, 120, 480], base_color='green', subtitle='GCaMP8s', plot_style='mean_sem')\n",
    "plot_delta_f_over_f_with_nans(pooled_nans_responses_cablam, specific_stim_ids=[12, 24, 36, 60, 120, 480], base_color='red', subtitle='CaBLAM with 1/2x Fz Dilution', plot_style='mean_sem')\n",
    "plot_delta_f_over_f_with_nans(pooled_nans_responses_cablam1x, specific_stim_ids=[12, 24, 36, 60, 120, 480], base_color='blue', subtitle='CaBLAM with 1x Fz Dilution', plot_style='mean_sem')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "\n",
    "def plot_delta_f_over_f_with_nans(pooled_responses, specific_stim_ids=None, base_color='green', \n",
    "                                  subtitle='', plot_style='mean', plot_mode='overlay'):\n",
    "    \"\"\"\n",
    "    Extended documentation...\n",
    "    \"\"\"\n",
    "    plt.figure(figsize=(10, 5))\n",
    "    \n",
    "    if plot_mode not in ['overlay', 'subplot']:\n",
    "        raise ValueError(\"plot_mode must be 'overlay' or 'subplot'\")\n",
    "    \n",
    "    if specific_stim_ids is not None:\n",
    "        stim_ids = specific_stim_ids\n",
    "    else:\n",
    "        stim_ids = sorted(pooled_responses.keys())\n",
    "    \n",
    "    # Calculate consistent color intensity for all plots\n",
    "    min_stim_id, max_stim_id = min(stim_ids), max(stim_ids)\n",
    "    alpha_values = {stim_id: 0.1 + 0.9 * (stim_id - min_stim_id) / (max_stim_id - min_stim_id) for stim_id in stim_ids}\n",
    "    \n",
    "    if plot_mode == 'overlay':\n",
    "        for stim_id in stim_ids:\n",
    "            response = pooled_responses[stim_id]['mean_response']\n",
    "            baseline = np.nanmedian(response[:10])\n",
    "            delta_f_over_f = (response - baseline) / baseline if baseline != 0 else np.zeros_like(response)\n",
    "            sem = pooled_responses[stim_id]['sem_response'] / baseline if baseline != 0 else np.zeros_like(response)\n",
    "\n",
    "            alpha = 0.1 + 0.9 * (stim_id - min_stim_id) / (max_stim_id - min_stim_id)\n",
    "            time_points = np.arange(-10, len(response) - 10)\n",
    "            \n",
    "            # Plot mean\n",
    "            plt.plot(time_points, delta_f_over_f, label=f'Stim ID {stim_id}', color=base_color, alpha=alpha)\n",
    "\n",
    "            # If 'mean_sem' style is chosen, also plot SEM as dotted lines\n",
    "            if plot_style == 'mean_sem':\n",
    "                plt.plot(time_points, delta_f_over_f + sem, linestyle='--', color=base_color, alpha=alpha)\n",
    "                plt.plot(time_points, delta_f_over_f - sem, linestyle='--', color=base_color, alpha=alpha)\n",
    "\n",
    "        plt.suptitle('Normalized Calcium Responses (F/F)', fontsize=14)\n",
    "        plt.title(subtitle, fontsize=10)\n",
    "        plt.xlabel('Time (relative to stimulus)')\n",
    "        plt.ylabel(r'$\\Delta F/F$')\n",
    "        plt.legend()\n",
    "        plt.show()\n",
    "\n",
    "    elif plot_mode == 'subplot':\n",
    "        # Calculate subplot size\n",
    "        num_plots = len(stim_ids)\n",
    "        fig, axs = plt.subplots(1, num_plots, figsize=(5 * num_plots, 5), sharey=True)\n",
    "        \n",
    "        for idx, stim_id in enumerate(stim_ids):\n",
    "            response = pooled_responses[stim_id]['mean_response']\n",
    "            baseline = np.nanmedian(response[:10])\n",
    "            delta_f_over_f = (response - baseline) / baseline if baseline != 0 else np.zeros_like(response)\n",
    "            sem = pooled_responses[stim_id]['sem_response'] / baseline if baseline != 0 else np.zeros_like(response)\n",
    "            \n",
    "            # Calculate alpha value for consistent color intensity\n",
    "            alpha = alpha_values[stim_id]\n",
    "            time_points = np.arange(-10, len(response) - 10)\n",
    "            \n",
    "            # Select the right subplot\n",
    "            ax = axs[idx] if num_plots > 1 else axs\n",
    "            # Plot mean\n",
    "            ax.plot(time_points, delta_f_over_f, label=f'Stim ID {stim_id}', color=base_color, alpha=alpha)\n",
    "\n",
    "            # If 'mean_sem' style is chosen, also plot SEM\n",
    "            if plot_style == 'mean_sem':\n",
    "                ax.fill_between(time_points, delta_f_over_f + sem, delta_f_over_f - sem, color=base_color, alpha=alpha*0.3)\n",
    "            \n",
    "            ax.set_title(f'Stim ID {stim_id}', fontsize=10)\n",
    "            ax.set_xlabel('Time (relative to stimulus)')\n",
    "            if idx == 0:  # Only add y-label to the first subplot\n",
    "                ax.set_ylabel(r'$\\Delta F/F$')\n",
    "            ax.legend()\n",
    "\n",
    "        plt.suptitle(f'Normalized Calcium Responses (F/F) - {subtitle}', fontsize=14)\n",
    "        plt.tight_layout()\n",
    "        plt.show()\n",
    "        \n",
    "\n",
    "    \n",
    "    \n",
    "plot_delta_f_over_f_with_nans(pooled_responses=pooled_nans_responses_gcamp8, \n",
    "                              specific_stim_ids=[12, 24, 36, 60, 120, 480], \n",
    "                              base_color='green', \n",
    "                              subtitle='GCaMP8s', \n",
    "                              plot_style='mean_sem', \n",
    "                              plot_mode='subplot')\n",
    "\n",
    "plot_delta_f_over_f_with_nans(pooled_responses=pooled_nans_responses_cablam,\n",
    "                                specific_stim_ids=[12, 24, 36, 60, 120, 480],\n",
    "                                base_color='red',\n",
    "                                subtitle='CaBLAM with 1/2x Fz Dilution',\n",
    "                                plot_style='mean_sem',\n",
    "                                plot_mode='subplot')\n",
    "\n",
    "plot_delta_f_over_f_with_nans(pooled_responses=pooled_nans_responses_cablam1x,\n",
    "                                specific_stim_ids=[12, 24, 36, 60, 120, 480],\n",
    "                                base_color='blue',\n",
    "                                subtitle='CaBLAM with 1x Fz Dilution',\n",
    "                                plot_style='mean_sem',\n",
    "                                plot_mode='subplot')\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def plot_overlay_delta_f_over_f_with_nans(pooled_responses_1, pooled_responses_2, specific_stim_ids=None,\n",
    "                                          color_1='green', color_2='red', subtitle_1='', subtitle_2='',\n",
    "                                          plot_style='mean_sem'):\n",
    "\n",
    "    plt.figure(figsize=(5 * len(specific_stim_ids), 5))\n",
    "\n",
    "    if specific_stim_ids is None:\n",
    "        raise ValueError(\"specific_stim_ids must be provided\")\n",
    "\n",
    "    for idx, stim_id in enumerate(specific_stim_ids):\n",
    "        ax = plt.subplot(1, len(specific_stim_ids), idx + 1)\n",
    "        \n",
    "        for pooled_responses, base_color, subtitle in zip([pooled_responses_1, pooled_responses_2],\n",
    "                                                          [color_1, color_2], [subtitle_1, subtitle_2]):\n",
    "            response = pooled_responses[stim_id]['mean_response']\n",
    "            baseline = np.nanmedian(response[:10])\n",
    "            delta_f_over_f = (response - baseline) / baseline if baseline != 0 else np.zeros_like(response)\n",
    "            sem = pooled_responses[stim_id]['sem_response'] / baseline if baseline != 0 else np.zeros_like(response)\n",
    "            \n",
    "            time_points = np.arange(-10, len(response) - 10)*10\n",
    "            \n",
    "            ax.plot(time_points, delta_f_over_f, label=f'{subtitle}, Stim ID {stim_id}', color=base_color)\n",
    "            if plot_style == 'mean_sem':\n",
    "                ax.fill_between(time_points, delta_f_over_f + sem, delta_f_over_f - sem, color=base_color, alpha=0.3)\n",
    "        \n",
    "        ax.set_title(f'Stim ID {stim_id}', fontsize=10)\n",
    "        ax.set_xlabel('Time (relative to stimulus, ms)')\n",
    "        if idx == 0:\n",
    "            ax.set_ylabel(r'$\\Delta F/F$')\n",
    "        ax.legend()\n",
    "        \n",
    "    plt.suptitle(f'Normalized Calcium Responses (F/F)', fontsize=14)\n",
    "    plt.tight_layout()\n",
    "    plt.show()\n",
    "    \n",
    "plot_overlay_delta_f_over_f_with_nans(pooled_responses_1=pooled_nans_responses_gcamp8, pooled_responses_2=pooled_nans_responses_cablam1x, specific_stim_ids=[12, 24, 36, 60, 120, 480],\n",
    "                                          color_1='green', color_2='blue', subtitle_1='', subtitle_2='',\n",
    "                                          plot_style='mean_sem')\n",
    "\n",
    "plot_overlay_delta_f_over_f_with_nans(pooled_responses_1=pooled_nans_responses_gcamp8, pooled_responses_2=pooled_nans_responses_cablam, specific_stim_ids=[12, 24, 36, 60, 120, 480],\n",
    "                                          color_1='green', color_2='red', subtitle_1='', subtitle_2='',\n",
    "                                          plot_style='mean_sem')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def plot_delta_f_over_f_with_nans(pooled_responses, specific_stim_ids=None, base_color='green', \n",
    "                                  subtitle='', plot_style='mean', normalization_method='peak'):\n",
    "    \"\"\"\n",
    "    Plots the normalized calcium responses (F/F) for all or specific stimulation IDs,\n",
    "    with options for plotting style including mean only or mean with SEM as shaded areas,\n",
    "    and different normalization methods.\n",
    "\n",
    "    Parameters\n",
    "    ----------\n",
    "    pooled_responses : dict\n",
    "        A dictionary with stim IDs as keys and 'mean_response' and 'sem_response' as subkeys,\n",
    "        potentially containing NaN values.\n",
    "    specific_stim_ids : list of int, optional\n",
    "        A list of stimulation IDs to be plotted.\n",
    "    base_color : str, optional\n",
    "        The color of the plot lines.\n",
    "    subtitle : str, optional\n",
    "        Custom subtitle text for the plot.\n",
    "    plot_style : str, optional\n",
    "        The plotting style: 'mean' (default) or 'mean_sem'.\n",
    "    normalization_method : str, optional\n",
    "        The normalization method: 'baseline' (default) or 'peak'.\n",
    "    \"\"\"\n",
    "    plt.figure(figsize=(10, 5))\n",
    "    \n",
    "    if specific_stim_ids is not None:\n",
    "        invalid_stim_ids = set(specific_stim_ids) - set(pooled_responses.keys())\n",
    "        if invalid_stim_ids:\n",
    "            raise ValueError(f\"Invalid stim IDs provided: {invalid_stim_ids}\")\n",
    "        stim_ids = specific_stim_ids\n",
    "    else:\n",
    "        stim_ids = sorted(pooled_responses.keys())\n",
    "    \n",
    "    for stim_id in stim_ids:\n",
    "        response = pooled_responses[stim_id]['mean_response']\n",
    "        baseline = np.nanmedian(response[:10])\n",
    "        delta_f_over_f = (response - baseline) / baseline if baseline != 0 else np.zeros_like(response)\n",
    "        \n",
    "        if normalization_method == 'peak':\n",
    "            peak_delta = np.nanmax(delta_f_over_f)\n",
    "            delta_f_over_f /= peak_delta if peak_delta != 0 else 1\n",
    "        \n",
    "        sem = pooled_responses[stim_id]['sem_response'] / baseline if baseline != 0 else np.zeros_like(response)\n",
    "        if normalization_method == 'peak' and peak_delta != 0:\n",
    "            sem /= peak_delta\n",
    "\n",
    "        alpha = 0.1 + 0.9 * (stim_id - min(stim_ids)) / (max(stim_ids) - min(stim_ids))\n",
    "        time_points = np.arange(-10, len(response) - 10)\n",
    "        \n",
    "        # Plot mean\n",
    "        plt.plot(time_points, delta_f_over_f, label=f'Stim ID {stim_id}', color=base_color, alpha=alpha)\n",
    "\n",
    "        # If 'mean_sem' style is chosen, also plot SEM as a shaded area\n",
    "        if plot_style == 'mean_sem':\n",
    "            plt.fill_between(time_points, delta_f_over_f - sem, delta_f_over_f + sem, color=base_color, alpha=0.3 * alpha)\n",
    "\n",
    "    plt.suptitle('Normalized Calcium Responses (F/F)', fontsize=14)\n",
    "    plt.title(subtitle, fontsize=10)\n",
    "    plt.xlabel('Time (relative to stimulus)')\n",
    "    plt.ylabel(r'$\\Delta F/F$')\n",
    "    plt.legend()\n",
    "    plt.show()\n",
    "\n",
    "plot_delta_f_over_f_with_nans(\n",
    "    pooled_responses=pooled_nans_responses_gcamp8, \n",
    "    specific_stim_ids=[12, 24, 36, 60, 120, 480],\n",
    "    base_color='green', \n",
    "    subtitle='GCaMP8s', \n",
    "    plot_style='mean_sem', \n",
    "    normalization_method='peak')\n",
    "\n",
    "\n",
    "plot_delta_f_over_f_with_nans(\n",
    "    pooled_responses=pooled_nans_responses_cablam, \n",
    "    specific_stim_ids=[12, 24, 36, 60, 120, 480],\n",
    "    base_color='red', \n",
    "    subtitle='cablam', \n",
    "    plot_style='mean_sem', \n",
    "    normalization_method='peak')\n",
    "\n",
    "plot_delta_f_over_f_with_nans(\n",
    "    pooled_responses=pooled_nans_responses_cablam1x, \n",
    "    specific_stim_ids=[12, 24, 36, 60, 120, 480],\n",
    "    base_color='blue', \n",
    "    subtitle='cablam1x', \n",
    "    plot_style='mean_sem', \n",
    "    normalization_method='peak')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def plot_delta_f_over_f_with_nans_maxnorm(pooled_responses, specific_stim_ids=None, base_color='green', \n",
    "                                  subtitle='', plot_style='mean', normalization_method='peak'):\n",
    "    \"\"\"\n",
    "    Plots the normalized calcium responses (F/F) for all or specific stimulation IDs,\n",
    "    with options for plotting style including mean only or mean with SEM as dotted lines,\n",
    "    and different normalization methods.\n",
    "\n",
    "    Parameters\n",
    "    ----------\n",
    "    pooled_responses : dict\n",
    "        A dictionary with stim IDs as keys and 'mean_response' and 'sem_response' as subkeys,\n",
    "        potentially containing NaN values.\n",
    "    specific_stim_ids : list of int, optional\n",
    "        A list of stimulation IDs to be plotted.\n",
    "    base_color : str, optional\n",
    "        The color of the plot lines.\n",
    "    subtitle : str, optional\n",
    "        Custom subtitle text for the plot.\n",
    "    plot_style : str, optional\n",
    "        The plotting style: 'mean' (default) or 'mean_sem'.\n",
    "    normalization_method : str, optional\n",
    "        The normalization method: 'baseline' (default) or 'peak'.\n",
    "    \"\"\"\n",
    "    plt.figure(figsize=(10, 5))\n",
    "    \n",
    "    if specific_stim_ids is not None:\n",
    "        invalid_stim_ids = set(specific_stim_ids) - set(pooled_responses.keys())\n",
    "        if invalid_stim_ids:\n",
    "            raise ValueError(f\"Invalid stim IDs provided: {invalid_stim_ids}\")\n",
    "        stim_ids = specific_stim_ids\n",
    "    else:\n",
    "        stim_ids = sorted(pooled_responses.keys())\n",
    "    \n",
    "    for stim_id in stim_ids:\n",
    "        response = pooled_responses[stim_id]['mean_response']\n",
    "        baseline = np.nanmedian(response[:10])\n",
    "        delta_f_over_f = (response - baseline) / baseline if baseline != 0 else np.zeros_like(response)\n",
    "        \n",
    "        if normalization_method == 'peak':\n",
    "            peak_delta = np.nanmax(delta_f_over_f)\n",
    "            delta_f_over_f /= peak_delta if peak_delta != 0 else 1\n",
    "        \n",
    "        sem = pooled_responses[stim_id]['sem_response'] / baseline if baseline != 0 else np.zeros_like(response)\n",
    "        if normalization_method == 'peak' and peak_delta != 0:\n",
    "            sem /= peak_delta\n",
    "\n",
    "        alpha = 0.1 + 0.9 * (stim_id - min(stim_ids)) / (max(stim_ids) - min(stim_ids))\n",
    "        time_points = np.arange(-10, len(response) - 10)\n",
    "        \n",
    "        # Plot mean\n",
    "        plt.plot(time_points, delta_f_over_f, label=f'Stim ID {stim_id}', color=base_color, alpha=alpha)\n",
    "\n",
    "        # If 'mean_sem' style is chosen, also plot SEM as dotted lines\n",
    "        if plot_style == 'mean_sem':\n",
    "            plt.plot(time_points, delta_f_over_f + sem, linestyle='--', color=base_color, alpha=alpha)\n",
    "            plt.plot(time_points, delta_f_over_f - sem, linestyle='--', color=base_color, alpha=alpha)\n",
    "\n",
    "    plt.suptitle('Normalized Calcium Responses (F/F)', fontsize=14)\n",
    "    plt.title(subtitle, fontsize=10)\n",
    "    plt.xlabel('Time (relative to stimulus)')\n",
    "    plt.ylabel(r'$\\Delta F/F$')\n",
    "    plt.legend()\n",
    "    plt.show()\n",
    "    \n",
    "plot_delta_f_over_f_with_nans_maxnorm(\n",
    "    pooled_responses=pooled_nans_responses_gcamp8, \n",
    "    specific_stim_ids=[12, 24, 36, 60, 120, 480],\n",
    "    base_color='green', \n",
    "    subtitle='GCaMP8s', \n",
    "    plot_style='mean_sem', \n",
    "    normalization_method='peak')\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def plot_overlay_delta_f_over_f_with_nans(pooled_responses_1, pooled_responses_2, specific_stim_ids=None,\n",
    "                                          color_1='green', color_2='red', subtitle_1='', subtitle_2='',\n",
    "                                          plot_style='mean_sem'):\n",
    "    \"\"\"\n",
    "    Plots an overlay of normalized calcium responses (F/F) for two sets of pooled responses\n",
    "    on the same axes for direct comparison, with options for plotting style including mean only\n",
    "    or mean with SEM as dotted lines.\n",
    "\n",
    "    Parameters\n",
    "    ----------\n",
    "    pooled_responses_1 : dict\n",
    "        The first set of pooled responses with stim IDs as keys and 'mean_response' and 'sem_response' as subkeys.\n",
    "    pooled_responses_2 : dict\n",
    "        The second set of pooled responses with stim IDs as keys and 'mean_response' and 'sem_response' as subkeys.\n",
    "    specific_stim_ids : list of int, optional\n",
    "        A list of stimulation IDs to be plotted.\n",
    "    color_1 : str, optional\n",
    "        The color of the plot lines for the first set of responses.\n",
    "    color_2 : str, optional\n",
    "        The color of the plot lines for the second set of responses.\n",
    "    subtitle_1 : str, optional\n",
    "        Custom subtitle text for the first set of responses.\n",
    "    subtitle_2 : str, optional\n",
    "        Custom subtitle text for the second set of responses.\n",
    "    plot_style : str, optional\n",
    "        The plotting style: 'mean' or 'mean_sem'.\n",
    "    \"\"\"\n",
    "    plt.figure(figsize=(5 * len(specific_stim_ids), 5))\n",
    "\n",
    "    if specific_stim_ids is None:\n",
    "        raise ValueError(\"specific_stim_ids must be provided\")\n",
    "\n",
    "    for idx, stim_id in enumerate(specific_stim_ids):\n",
    "        ax = plt.subplot(1, len(specific_stim_ids), idx + 1)\n",
    "        \n",
    "        for pooled_responses, base_color, subtitle in zip([pooled_responses_1, pooled_responses_2],\n",
    "                                                          [color_1, color_2], [subtitle_1, subtitle_2]):\n",
    "            response = pooled_responses[stim_id]['mean_response']\n",
    "            baseline = np.nanmedian(response[:10])\n",
    "            delta_f_over_f = (response - baseline) / baseline if baseline != 0 else np.zeros_like(response)\n",
    "            \n",
    "            \n",
    "            peak_delta = np.nanmax(delta_f_over_f)\n",
    "            delta_f_over_f /= peak_delta if peak_delta != 0 else 1\n",
    "            \n",
    "            sem = pooled_responses[stim_id]['sem_response'] / baseline if baseline != 0 else np.zeros_like(response)\n",
    "            sem /= peak_delta if peak_delta != 0 else 1\n",
    "\n",
    "            time_points = np.arange(-10, len(response) - 10)\n",
    "            \n",
    "            ax.plot(time_points, delta_f_over_f, label=f'{subtitle}, Stim ID {stim_id}', color=base_color)\n",
    "            if plot_style == 'mean_sem':\n",
    "                #ax.plot(time_points, delta_f_over_f + sem, linestyle='--', color=base_color)\n",
    "                #ax.plot(time_points, delta_f_over_f - sem, linestyle='--', color=base_color)\n",
    "                \n",
    "                #plot shaded area\n",
    "                ax.fill_between(time_points, delta_f_over_f + sem, delta_f_over_f - sem, color=base_color, alpha=0.3)\n",
    "                \n",
    "        \n",
    "        ax.set_title(f'Stim ID {stim_id}', fontsize=10)\n",
    "        ax.set_xlabel('Time (relative to stimulus)')\n",
    "        if idx == 0:\n",
    "            ax.set_ylabel(r'$\\Delta F/F$')\n",
    "        ax.legend()\n",
    "        \n",
    "    plt.suptitle('Normalized Calcium Responses (F/F)', fontsize=14)\n",
    "    plt.tight_layout()\n",
    "    plt.show()\n",
    "\n",
    "plot_overlay_delta_f_over_f_with_nans(pooled_responses_1=pooled_nans_responses_gcamp8, pooled_responses_2=pooled_nans_responses_cablam1x, specific_stim_ids=[12, 24, 36, 60, 120, 480],\n",
    "                                          color_1='green', color_2='blue', subtitle_1='', subtitle_2='',\n",
    "                                          plot_style='mean_sem')\n",
    "\n",
    "plot_overlay_delta_f_over_f_with_nans(pooled_responses_1=pooled_nans_responses_cablam1x, pooled_responses_2=pooled_nans_responses_cablam, specific_stim_ids=[12, 24, 36, 60, 120, 480],\n",
    "                                          color_1='red', color_2='blue', subtitle_1='', subtitle_2='',\n",
    "                                          plot_style='mean_sem')\n",
    "\n",
    "plot_overlay_delta_f_over_f_with_nans(pooled_responses_1=pooled_nans_responses_cablam1x, pooled_responses_2=pooled_nans_responses_cablam, specific_stim_ids=[12, 24, 36, 60, 120, 480, 960, 1920],\n",
    "                                          color_1='red', color_2='blue', subtitle_1='', subtitle_2='',\n",
    "                                          plot_style='mean')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def plot_overlay_delta_f_over_f_with_nans(pooled_responses_1, pooled_responses_2, specific_stim_ids=None,\n",
    "                                          color_1='green', color_2='red', subtitle_1='', subtitle_2='',\n",
    "                                          plot_style='mean_sem'):\n",
    "    \"\"\"\n",
    "    Plots an overlay of normalized calcium responses (F/F) for two sets of pooled responses\n",
    "    on the same axes for direct comparison, with options for plotting style including mean only\n",
    "    or mean with SEM as dotted lines, and calculations for time to peak and half-decay.\n",
    "\n",
    "    Parameters\n",
    "    ----------\n",
    "    ... [other parameters as before] ...\n",
    "    \"\"\"\n",
    "    bin_size_ms = 100  # Bin size in milliseconds\n",
    "\n",
    "    plt.figure(figsize=(5 * len(specific_stim_ids), 5))\n",
    "\n",
    "    if specific_stim_ids is None:\n",
    "        raise ValueError(\"specific_stim_ids must be provided\")\n",
    "\n",
    "    for idx, stim_id in enumerate(specific_stim_ids):\n",
    "        ax = plt.subplot(1, len(specific_stim_ids), idx + 1)\n",
    "\n",
    "        for pooled_responses, base_color, subtitle in zip([pooled_responses_1, pooled_responses_2],\n",
    "                                                          [color_1, color_2], [subtitle_1, subtitle_2]):\n",
    "            response = pooled_responses[stim_id]['mean_response']\n",
    "            baseline = np.nanmedian(response[:10])\n",
    "            delta_f_over_f = (response - baseline) / baseline if baseline != 0 else np.zeros_like(response)\n",
    "\n",
    "            peak_delta = np.nanmax(delta_f_over_f)\n",
    "            delta_f_over_f /= peak_delta if peak_delta != 0 else 1\n",
    "\n",
    "            sem = pooled_responses[stim_id]['sem_response'] / baseline if baseline != 0 else np.zeros_like(response)\n",
    "            sem /= peak_delta if peak_delta != 0 else 1\n",
    "\n",
    "            time_points = np.arange(-10, len(response) - 10) * bin_size_ms  # Convert to milliseconds\n",
    "\n",
    "            # Calculate time to peak\n",
    "            peak_index = np.nanargmax(delta_f_over_f)\n",
    "            \n",
    "            # This is assuming the stimulus occurs at index 10 of your response array, and each bin represents bin_size_ms milliseconds.\n",
    "            pre_stimulus_bins = 10\n",
    "            time_to_peak = (peak_index - pre_stimulus_bins) * bin_size_ms\n",
    "            \n",
    "            # Calculate half-decay time\n",
    "            half_decay_value = peak_delta / 2\n",
    "            # Find the first index after the peak where the value falls below half the peak\n",
    "            half_decay_index = np.where(delta_f_over_f[peak_index:] < half_decay_value)[0]\n",
    "            half_decay_time = (half_decay_index[0] + peak_index) * bin_size_ms if half_decay_index.size > 0 else np.nan\n",
    "            \n",
    "            ax.plot(time_points, delta_f_over_f, label=f'{subtitle}, Stim ID {stim_id}', color=base_color)\n",
    "            if plot_style == 'mean_sem':\n",
    "                ax.plot(time_points, delta_f_over_f + sem, linestyle='--', color=base_color)\n",
    "                ax.plot(time_points, delta_f_over_f - sem, linestyle='--', color=base_color)\n",
    "\n",
    "            print(f'{subtitle}, Stim ID {stim_id}: Time to peak = {time_to_peak} ms; Half-decay time = {half_decay_time} ms')\n",
    "            \n",
    "            #draw a line at the time to peak\n",
    "            ax.axvline(time_to_peak, color=base_color, linestyle='--', alpha=0.5)\n",
    "            \n",
    "\n",
    "        ax.set_title(f'Stim ID {stim_id}', fontsize=10)\n",
    "        ax.set_xlabel('Time (relative to stimulus) [ms]')\n",
    "        if idx == 0:\n",
    "            ax.set_ylabel(r'$\\Delta F/F$')\n",
    "        ax.legend()\n",
    "\n",
    "    plt.suptitle('Normalized Calcium Responses (F/F)', fontsize=14)\n",
    "    plt.tight_layout()\n",
    "    plt.show()\n",
    "\n",
    "plot_overlay_delta_f_over_f_with_nans(pooled_responses_1=pooled_nans_responses_gcamp8, pooled_responses_2=pooled_nans_responses_cablam, specific_stim_ids=[12, 24, 36, 60, 120, 480],\n",
    "                                          color_1='green', color_2='blue', subtitle_1='', subtitle_2='',\n",
    "                                          plot_style='mean')\n",
    "\n",
    "plot_overlay_delta_f_over_f_with_nans(pooled_responses_1=pooled_nans_responses_cablam, pooled_responses_2=pooled_nans_responses_cablam1x, specific_stim_ids=[12, 24, 36, 60, 120, 480, 960, 1920],\n",
    "                                          color_1='red', color_2='blue', subtitle_1='', subtitle_2='',\n",
    "                                          plot_style='mean')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "\n",
    "def plot_delta_f_over_f_subplots(pooled_responses, specific_stim_ids=None, base_color='green'):\n",
    "    \"\"\"\n",
    "    Plots normalized calcium responses (F/F) for all or specific stimulation IDs as subplots,\n",
    "    with the line opacity reflecting the intensity of the stimulation ID.\n",
    "    \n",
    "    Parameters\n",
    "    ----------\n",
    "    pooled_responses : dict\n",
    "        A dictionary with stim IDs as keys and 'mean_response' and 'sem_response' as subkeys.\n",
    "    specific_stim_ids : list of int, optional\n",
    "        A list of stimulation IDs to be plotted. If None (default), all stim IDs will be plotted.\n",
    "        If an invalid stim ID is provided, a ValueError will be raised.\n",
    "    base_color : str, optional\n",
    "        The color of the plot lines. Default is 'green'. This function will adjust the opacity of this color\n",
    "        based on the stimulation ID intensity.\n",
    "    \n",
    "    Raises\n",
    "    ------\n",
    "    ValueError\n",
    "        If a specified stim ID is not present in the data.\n",
    "    \n",
    "    Examples\n",
    "    --------\n",
    "    >>> plot_delta_f_over_f_subplots(pooled_responses) # Plots all responses as subplots with green lines\n",
    "    >>> plot_delta_f_over_f_subplots(pooled_responses, specific_stim_ids=[12, 24, 36], base_color='blue')\n",
    "        # Plots responses for stim IDs 12, 24, and 36 as subplots with blue lines\n",
    "    \"\"\"\n",
    "    # Check if specific_stim_ids have been provided\n",
    "    if specific_stim_ids is not None:\n",
    "        # Verify that the provided stim IDs are valid\n",
    "        invalid_stim_ids = set(specific_stim_ids) - set(pooled_responses.keys())\n",
    "        if invalid_stim_ids:\n",
    "            raise ValueError(f\"Invalid stim IDs provided: {invalid_stim_ids}\")\n",
    "        stim_ids = specific_stim_ids\n",
    "    else:\n",
    "        stim_ids = sorted(pooled_responses.keys())\n",
    "    \n",
    "    # Determine the number of subplots based on the number of stim IDs\n",
    "    num_subplots = len(stim_ids)\n",
    "    fig, axes = plt.subplots(num_subplots, 1, figsize=(10, 5 * num_subplots), sharex=True)\n",
    "    \n",
    "    if num_subplots == 1:\n",
    "        axes = [axes]  # Make sure axes is iterable for a single subplot case\n",
    "\n",
    "    # Get the min and max stim IDs for opacity scaling\n",
    "    min_stim_id, max_stim_id = min(stim_ids), max(stim_ids)\n",
    "    \n",
    "    for ax, stim_id in zip(axes, stim_ids):\n",
    "        response = pooled_responses[stim_id]['mean_response']\n",
    "        baseline = np.nanmean(response[:10])  # Adjust this index to match the pre-stimulus period\n",
    "        delta_f_over_f = (response - baseline) / baseline\n",
    "        \n",
    "        # Normalize the stim_id to get an alpha value between 0.1 and 1.0\n",
    "        alpha = 0.1 + 0.9 * (stim_id - min_stim_id) / (max_stim_id - min_stim_id)\n",
    "\n",
    "        time_points = np.arange(-10, len(response) - 10)  # Adjust the range as necessary\n",
    "\n",
    "        ax.plot(time_points, delta_f_over_f, label=f'Stim ID {stim_id}', color=base_color, alpha=alpha)\n",
    "        ax.set_ylabel(r'$\\Delta F/F$')\n",
    "        ax.legend()\n",
    "\n",
    "    # Set the xlabel for the last subplot\n",
    "    axes[-1].set_xlabel('Time (relative to stimulus)')\n",
    "    plt.suptitle('Normalized Calcium Responses (F/F) for Selected Stimulation IDs')\n",
    "    plt.tight_layout(rect=[0, 0.03, 1, 0.95])  # Adjust layout to accommodate the suptitle\n",
    "    plt.show()\n",
    "\n",
    "# Example usage:\n",
    "\n",
    "plot_delta_f_over_f_subplots(pooled_nans_responses_gcamp8, specific_stim_ids=[12, 24, 36, 60, 120, 480], base_color='green')\n",
    "plot_delta_f_over_f_subplots(pooled_nans_responses_cablam, specific_stim_ids=[12, 24, 36, 60, 120, 480], base_color='red')\n",
    "plot_delta_f_over_f_subplots(pooled_nans_responses_cablam1x, specific_stim_ids=[12, 24, 36, 60, 120, 480], base_color='blue')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from scipy.stats import ttest_ind\n",
    "\n",
    "def calculate_responsiveness(all_data, pre_stim_frames=10, post_stim_frames=10, alpha=0.01, return_dataframe=False):\n",
    "    \"\"\"\n",
    "    This function calculates and identifies responsive cells within calcium imaging data, applying statistical \n",
    "    tests to determine whether the change in signal post-stimulation is significant compared to the pre-stimulation \n",
    "    baseline. It stores detailed metrics including means, standard deviations, and p-values for each ROI across all sessions.\n",
    "\n",
    "    Parameters:\n",
    "    - all_data (dict): Nested dictionary containing the processed calcium signal data for multiple sessions, \n",
    "      structured with session IDs as top-level keys.\n",
    "    - pre_stim_frames (int): The number of frames before the stimulus used to calculate the baseline signal.\n",
    "    - post_stim_frames (int): The number of frames after the stimulus used for post-stimulus signal analysis.\n",
    "    - alpha (float): The significance level used to determine if a response is statistically significant.\n",
    "    - return_dataframe (bool): If set to True, the function also returns a pandas DataFrame containing the computed metrics.\n",
    "\n",
    "    Returns:\n",
    "    - dict: A nested dictionary containing calculated metrics for each session ID, ROI, and stimulus event. If \n",
    "      `return_dataframe` is True, it also returns a DataFrame alongside this dictionary.\n",
    "\n",
    "    The output dictionary follows a multi-level structure:\n",
    "    - Level 1 (Session Level): Keys are session IDs, and values are dictionaries containing data for each session.\n",
    "    - Level 2 (ROI Level): Within each session dictionary, keys are ROIs, and values are dictionaries with metrics for each ROI.\n",
    "    - Level 3 (Stimulus Event Level): For each ROI, keys are tuples of (stimulation_id, stim_frame_number), and values \n",
    "      are dictionaries containing the metrics calculated for each stimulus event.\n",
    "\n",
    "    Metrics included for each stimulus event:\n",
    "    - 'pre_stim_mean': Mean of the signal in the pre-stimulus period.\n",
    "    - 'pre_stim_sd': Standard deviation of the signal in the pre-stimulus period.\n",
    "    - 'post_stim_peak': Maximum signal value in the post-stimulus period (not normalized).\n",
    "    - 'post_stim_sd': Standard deviation of the signal in the post-stimulus period, excluding the peak value.\n",
    "    - 'p_value': P-value from the t-test comparing pre-stimulus and post-stimulus signals.\n",
    "    - 'is_responsive': Boolean indicating whether the ROI is considered responsive based on the p-value being below alpha.\n",
    "\n",
    "    \n",
    "    Returns:\n",
    "    dict or (dict, pd.DataFrame): A dictionary and optionally a DataFrame containing all metrics and SDs for each session ID, ROI, and stimulus.\n",
    "    \"\"\"\n",
    "    responsiveness_data = {}\n",
    "    dataframe_rows = []\n",
    "\n",
    "    for session_id, session_data in all_data.items():\n",
    "        session_responsiveness = {}\n",
    "        for roi, roi_data in session_data['roi_data'].items():\n",
    "            roi_responsiveness = {}\n",
    "            for (stim_id, stim_frame), signal_data in roi_data.items():\n",
    "                # Validate signal_data length\n",
    "                if signal_data.size >= (pre_stim_frames + post_stim_frames + 1):\n",
    "                    pre_stim_signal = signal_data[:pre_stim_frames]\n",
    "                    post_stim_signal = signal_data[pre_stim_frames + 1 : pre_stim_frames + 1 + post_stim_frames]\n",
    "                    \n",
    "  \n",
    "                    \n",
    "                    # New calculation for the entire array\n",
    "                    delta_f_f_full_array = (signal_data - np.mean(signal_data[:pre_stim_frames])) / np.mean(signal_data[:pre_stim_frames])\n",
    "                    \n",
    "                    \n",
    "\n",
    "                    # Calculate means and SDs\n",
    "                    pre_stim_mean = np.mean(pre_stim_signal)\n",
    "                    pre_stim_sd = np.std(pre_stim_signal)\n",
    "                    post_stim_peak = np.nanmax(post_stim_signal) if not np.isnan(np.nanmax(post_stim_signal)) else np.nan\n",
    "                    post_stim_sd = np.std(post_stim_signal[1:])  # Excluding the peak (stimulation point)\n",
    "                    post_stim_peak_index = np.nanargmax(post_stim_signal) if not np.isnan(post_stim_peak) else np.nan\n",
    "                    \n",
    "                    #calculate the median of the post_stim_signal and the median of the pre_stim_signal\n",
    "                    post_stim_median = np.median(post_stim_signal)\n",
    "                    pre_stim_median = np.median(pre_stim_signal)\n",
    "                    \n",
    "                    #calculate the mean of the post_stim_signal and the mean of the pre_stim_signal\n",
    "                    post_stim_mean = np.mean(post_stim_signal)\n",
    "                    \n",
    "                    # calculate the delta_f/f for the post_stim_signal and the pre_stim_signal and save entire array\n",
    "                    delta_f_f_post_stim = (post_stim_signal - pre_stim_mean) / pre_stim_mean\n",
    "                    \n",
    "                    # calculate the peak delta_f/f for the post_stim_signal and save the value \n",
    "                    peak_delta_f_f_post_stim = (post_stim_peak - pre_stim_mean) / pre_stim_mean\n",
    "            \n",
    "                    # Perform t-test between normalized pre-stimulus and post-stimulus signals\n",
    "                    t_stat, p_value = ttest_ind(pre_stim_signal, post_stim_signal, equal_var=False)\n",
    "\n",
    "                    # Determine responsiveness based on the p-value without explicit prior length check\n",
    "                    is_responsive = p_value < alpha if not np.isnan(p_value) else False\n",
    "                    \n",
    "                    # Time metrics calculations with safety checks\n",
    "                    half_peak_value = post_stim_peak / 2 if not np.isnan(post_stim_peak) else np.nan\n",
    "                    half_rise_index = np.where(post_stim_signal >= half_peak_value)[0][0] if np.any(post_stim_signal >= half_peak_value) else np.nan\n",
    "                    half_decay_index = np.where(post_stim_signal[post_stim_peak_index:] <= half_peak_value)[0][0] + post_stim_peak_index if post_stim_peak_index and np.any(post_stim_signal[post_stim_peak_index:] <= half_peak_value) else np.nan\n",
    "\n",
    "                    # Convert indices to milliseconds\n",
    "                    # Adjusted line with conditional to ensure a minimum of 100 ms:\n",
    "                    time_to_peak = max(100, post_stim_peak_index * 100) if not np.isnan(post_stim_peak_index) else np.nan\n",
    "                    half_rise_time = half_rise_index * 100 if not np.isnan(half_rise_index) else np.nan\n",
    "                    half_decay_time = half_decay_index * 100 if not np.isnan(half_decay_index) else np.nan\n",
    "\n",
    "                # Save all calculated metrics\n",
    "                roi_responsiveness[(stim_id, stim_frame)] = {\n",
    "                    'pre_stim_mean': pre_stim_mean,\n",
    "                    'pre_stim_sd': pre_stim_sd,\n",
    "                    'post_stim_peak': post_stim_peak,\n",
    "                    'post_stim_sd': post_stim_sd,\n",
    "                    'p_value': p_value,\n",
    "                    'post_stim_mean': post_stim_mean,\n",
    "                    'delta_f_f_post_stim': delta_f_f_post_stim,\n",
    "                    'pre_stim_median': pre_stim_median,\n",
    "                    'post_stim_median': post_stim_median,\n",
    "                    'peak_delta_f_f_post_stim': peak_delta_f_f_post_stim,\n",
    "                    'is_responsive': is_responsive\n",
    "            \n",
    "                }\n",
    "\n",
    "                # Append data for DataFrame\n",
    "                dataframe_rows.append({\n",
    "                    'session_id': session_id,\n",
    "                    'roi': roi,\n",
    "                    'stimulation_id': stim_id,\n",
    "                    'stim_frame_number': stim_frame,\n",
    "                    'pre_stim_mean': pre_stim_mean,\n",
    "                    'pre_stim_sd': pre_stim_sd,\n",
    "                    'post_stim_peak': post_stim_peak,\n",
    "                    'post_stim_sd': post_stim_sd,\n",
    "                    'post_stim_mean': post_stim_mean,\n",
    "                    'delta_f_f_post_stim': delta_f_f_post_stim*100,\n",
    "                    'pre_stim_median': pre_stim_median,\n",
    "                    'post_stim_median': post_stim_median,\n",
    "                    'peak_delta_f_f_post_stim': peak_delta_f_f_post_stim*100,\n",
    "                    'delta_f_f_full_array': delta_f_f_full_array*100,\n",
    "                    'raw_signal': signal_data,\n",
    "                    'p_value': p_value,\n",
    "                    'time_to_peak': time_to_peak,\n",
    "                    'half_rise_time': half_rise_time,\n",
    "                    'half_decay_time': half_decay_time,\n",
    "                    'is_responsive': is_responsive\n",
    "                })\n",
    "\n",
    "            session_responsiveness[roi] = roi_responsiveness\n",
    "        responsiveness_data[session_id] = session_responsiveness\n",
    "\n",
    "    # Create and return DataFrame if requested\n",
    "    if return_dataframe:\n",
    "        responsiveness_df = pd.DataFrame(dataframe_rows)\n",
    "        return responsiveness_data, responsiveness_df\n",
    "    else:\n",
    "        return responsiveness_data\n",
    "    \n",
    "    \n",
    "\n",
    "def filter_responsive_rois(all_data, responsiveness_data):\n",
    "    \"\"\"\n",
    "    Creates a new data structure similar to all_data but excludes the data for non-responsive ROIs \n",
    "    for specific stimulation IDs, maintaining only responsive ROI data.\n",
    "\n",
    "    Parameters:\n",
    "    all_data (dict): Original dictionary with the complete dataset.\n",
    "    responsiveness_data (dict): Dictionary containing responsiveness information for each ROI.\n",
    "\n",
    "    Returns:\n",
    "    dict: A new dictionary mirroring all_data's structure but excluding data for non-responsive ROIs per stimulus.\n",
    "    \"\"\"\n",
    "    filtered_data = {}\n",
    "\n",
    "    for session_id, session_content in all_data.items():\n",
    "        filtered_data[session_id] = {\n",
    "            'stim_frame_numbers': session_content['stim_frame_numbers'],\n",
    "            'roi_data': {},\n",
    "            'stimulation_ids': session_content['stimulation_ids']\n",
    "        }\n",
    "\n",
    "        for roi, roi_data in session_content['roi_data'].items():\n",
    "            filtered_roi_data = {}\n",
    "\n",
    "            for stim_key, signal_data in roi_data.items():\n",
    "                # Include the data only if the ROI is responsive for this stimulus\n",
    "                if responsiveness_data[session_id][roi].get(stim_key, {}).get('is_responsive', False):\n",
    "                    filtered_roi_data[stim_key] = signal_data\n",
    "            \n",
    "            # Update only if there's at least one responsive stim event for the ROI\n",
    "            if filtered_roi_data:\n",
    "                filtered_data[session_id]['roi_data'][roi] = filtered_roi_data\n",
    "\n",
    "    return filtered_data\n",
    "\n",
    "\n",
    "responsiveness_data, responsiveness_df = calculate_responsiveness(all_data, return_dataframe=True)\n",
    "responsiveness_data_gcamp8, responsiveness_df_gcamp8 = calculate_responsiveness(all_data_gcamp8, return_dataframe=True)\n",
    "responsiveness_data_cablam, responsiveness_df_cablam = calculate_responsiveness(all_data_cablam, return_dataframe=True)\n",
    "responsiveness_data_cablam1x, responsiveness_df_cablam1x = calculate_responsiveness(all_data_cablam1x, return_dataframe=True)\n",
    "\n",
    "filtered_data_gcamp8 = filter_responsive_rois(all_data_gcamp8, responsiveness_data_gcamp8)\n",
    "pooled_responses_filtered_gcamp8 = compile_pooled_responses(filtered_data_gcamp8)\n",
    "plot_delta_f_over_f(pooled_responses_filtered_gcamp8, specific_stim_ids=[12, 36, 60, 120, 480], base_color='green')\n",
    "\n",
    "filtered_data_cablam = filter_responsive_rois(all_data_cablam, responsiveness_data_cablam)\n",
    "pooled_responses_filtered_cablam = compile_pooled_responses(filtered_data_cablam)\n",
    "plot_delta_f_over_f(pooled_responses_filtered_cablam,specific_stim_ids=[12, 36, 60, 120, 480], base_color='blue')\n",
    "\n",
    "filtered_data_cablam1x = filter_responsive_rois(all_data_cablam1x, responsiveness_data_cablam1x)\n",
    "pooled_responses_filtered_cablam1x = compile_pooled_responses(filtered_data_cablam1x)\n",
    "plot_delta_f_over_f(pooled_responses_filtered_cablam1x,specific_stim_ids=[12, 36, 60, 120, 480], base_color='red')\n",
    "\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "responsiveness_df_gcamp8"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt\n",
    "from scipy.optimize import curve_fit\n",
    "\n",
    "\n",
    "class SensorDataPlotter:\n",
    "    def __init__(self, data_frames, sensor_names, sensor_box_colors, sensor_strip_colors):\n",
    "        \"\"\"\n",
    "        Initialize the object with a list of data frames, corresponding sensor names, and specific colors for each sensor.\n",
    "        :param data_frames: List of pandas DataFrames containing the sensor data.\n",
    "        :param sensor_names: List of strings representing the names of the sensors.\n",
    "        :param sensor_box_colors: Dictionary mapping sensor names to boxplot colors.\n",
    "        :param sensor_strip_colors: Dictionary mapping sensor names to stripplot colors.\n",
    "        \"\"\"\n",
    "        self.data_frames = data_frames\n",
    "        self.sensor_names = sensor_names\n",
    "        self.sensor_box_colors = sensor_box_colors\n",
    "        self.sensor_strip_colors = sensor_strip_colors\n",
    "        self.combined_df = None\n",
    "        \n",
    "    def prepare_for_plotting(self, df_column_name):\n",
    "        \"\"\"\n",
    "        Prepares a single dataframe suitable for plotting from multiple sensor dataframes.\n",
    "        :param df_column_name: The name of the column to use for the value in the plot.\n",
    "        \"\"\"\n",
    "        # Add a 'sensor_name' column to each DataFrame and concatenate them into a single DataFrame\n",
    "        frames = []\n",
    "        for df, name in zip(self.data_frames, self.sensor_names):\n",
    "            df = df.copy()  # Make a copy to avoid modifying the original DataFrame\n",
    "            df['sensor_name'] = name\n",
    "            df['value'] = df[df_column_name]\n",
    "            frames.append(df)\n",
    "        # Concatenate all Dataframes into a single DataFrame\n",
    "        self.combined_df = pd.concat(frames, ignore_index=True)\n",
    "        \n",
    "        #filter the self.combined_df to only include responsive ROIs when is_responsive is True based on if the entry is True or False\n",
    "        self.combined_df = self.combined_df[self.combined_df['is_responsive'] == True]\n",
    "        \n",
    "        # Ensure the value column is present and has the correct data type for plotting\n",
    "        if df_column_name not in self.combined_df.columns:\n",
    "            raise ValueError(f\"The column '{df_column_name}' does not exist in the DataFrame.\") # Raise an error if the column does not exist\n",
    "        self.combined_df[df_column_name] = pd.to_numeric(self.combined_df[df_column_name], errors='coerce') # Convert to numeric where eoors are coerced which means invalid parsing will be set as NaN\n",
    "\n",
    "    \n",
    "    def plot_data(self, df_column_name, selected_stim_ids, box_width=.8, strip_size=3, fig_size=(12, 8), dpi=300):\n",
    "        \"\"\"\n",
    "        Plots the data using boxplot and stripplot for selected stimulation IDs.\n",
    "        :param df_column_name: The name of the column to use for the value in the plot.\n",
    "        :param selected_stim_ids: List of stimulation IDs to plot. If None, plot all.\n",
    "        :param box_width: The width of the boxplots.\n",
    "        :param strip_size: The size of the points in the stripplots.\n",
    "        :param fig_size: Tuple representing the figure size (width, height) in inches.\n",
    "        :param dpi: The resolution in dots per inch.\n",
    "        \"\"\"\n",
    "        \n",
    "        ### check varuable types and raise errors if necessary ###\n",
    "        ##########################################################\n",
    "       \n",
    "        df_column_name = str(df_column_name)\n",
    "        \n",
    "        if selected_stim_ids is not None:\n",
    "            if not isinstance(selected_stim_ids, list):\n",
    "                raise ValueError(\"The selected_stim_ids parameter must be a list of stimulation IDs.\")\n",
    "            if not all(isinstance(stim_id, int) for stim_id in selected_stim_ids):\n",
    "                raise ValueError(\"All elements in the selected_stim_ids list must be integers.\")\n",
    "            \n",
    "        if not isinstance(box_width, (int, float)):\n",
    "            raise ValueError(\"The box_width parameter must be an integer or float.\")\n",
    "        if not isinstance(strip_size, (int, float)):\n",
    "            raise ValueError(\"The strip_size parameter must be an integer or float.\")\n",
    "        if not isinstance(fig_size, tuple) or len(fig_size) != 2:\n",
    "            raise ValueError(\"The fig_size parameter must be a tuple of two integers.\")\n",
    "        if not all(isinstance(val, (int, float)) for val in fig_size):\n",
    "            raise ValueError(\"The fig_size parameter must contain only integers or floats.\")\n",
    "        if not isinstance(dpi, int):\n",
    "            raise ValueError(\"The dpi parameter must be an integer.\")\n",
    "        \n",
    "    \n",
    "        \n",
    "        ### import, and filter the combined_df for the selected stimulation IDs if provided###\n",
    "        #####################################################################################\n",
    "       \n",
    "        #check if the combined_df is None and if so, call the prepare_for_plotting method \n",
    "        if self.combined_df is None:\n",
    "            self.prepare_for_plotting(df_column_name)\n",
    "       \n",
    "            \n",
    "        # Filter the combined DataFrame for the selected stimulation IDs if provided\n",
    "        if selected_stim_ids is not None:\n",
    "            self.combined_df = self.combined_df[self.combined_df['stimulation_id'].isin(selected_stim_ids)]\n",
    "            \n",
    "        # Raise an error if no data is available after filtering\n",
    "        if self.combined_df.empty:\n",
    "            raise ValueError(\"No data available for the selected stimulation IDs.\")\n",
    "        \n",
    "\n",
    "        \n",
    "        ### set up the boxplot and stripplot properties ###\n",
    "        ####################################################\n",
    "        \n",
    "        # Boxplot properties will have black edges and lines\n",
    "        boxprops = {'edgecolor': 'k', 'linewidth': 1.5}\n",
    "        lineprops = {'color': 'k', 'linewidth': 1.5}\n",
    "        \n",
    "        boxplot_kwargs = {\n",
    "            'boxprops': boxprops, 'medianprops': lineprops,\n",
    "            'whiskerprops': lineprops, 'capprops': lineprops,\n",
    "            'width': box_width, 'palette': self.sensor_box_colors,\n",
    "            'hue_order': self.sensor_names\n",
    "        }\n",
    "\n",
    "        # Stripplot properties\n",
    "        stripplot_kwargs = {\n",
    "            'linewidth': 0.1, 'size': strip_size, 'alpha': 0.3,\n",
    "            'palette': self.sensor_strip_colors, 'hue_order': self.sensor_names\n",
    "        }\n",
    "        \n",
    "        # Plotting with specified figure size and resolution\n",
    "        plt.figure(figsize=fig_size, dpi=dpi)\n",
    "        ax = plt.subplot()\n",
    "\n",
    "        sns.stripplot(\n",
    "            x='stimulation_id', y=df_column_name, hue='sensor_name',\n",
    "            data=self.combined_df, ax=ax, jitter=0.3, dodge=True,\n",
    "            **stripplot_kwargs\n",
    "        )\n",
    "        \n",
    "        ## error bars on the boxplot are the 95% confidence interval\n",
    "        sns.boxplot(\n",
    "            x='stimulation_id', y=df_column_name, hue='sensor_name',\n",
    "            data=self.combined_df, ax=ax, fliersize=0,\n",
    "            **boxplot_kwargs\n",
    "        )\n",
    "        \n",
    "        ### set the axis labels and ticks properties ### \n",
    "        ################################################\n",
    "            \n",
    "        # Set the font size of the x-axis and y-axis labels \n",
    "        ax.set_xlabel('Stimulation ID', fontsize=18)\n",
    "        ax.set_ylabel(df_column_name, fontsize=18)\n",
    "        \n",
    "        # Set the font size of the x-axis and y-axis ticks\n",
    "        ax.tick_params(axis='x', labelsize=24)\n",
    "        ax.tick_params(axis='y', labelsize=24)\n",
    "        ax.legend_.remove()\n",
    "        \n",
    "        #set the font to arial and the font size to 24\n",
    "        plt.rcParams['font.sans-serif'] = 'Arial'\n",
    "        plt.tight_layout()  # Adjust layout to fit legend#\n",
    "        plt.show()\n",
    "\n",
    "    def plot_mean_with_error(self, df_column_name, error_type='SEM', selected_stim_ids=None, xlim=None, ylim= None, fig_size=(8, 6), dpi=300):\n",
    "        \"\"\"\n",
    "        Plots the mean values with error bars for selected stimulation IDs across sensors, using consistent colors.\n",
    "        :param df_column_name: The name of the column to use for the value in the plot.\n",
    "        :param error_type: The type of error to display ('SD' for Standard Deviation or 'SEM' for Standard Error of the Mean).\n",
    "        :param selected_stim_ids: List of stimulation IDs to plot. If None, plot all.\n",
    "        :param fig_size: Tuple representing the figure size (width, height) in inches.\n",
    "        :param dpi: The resolution in dots per inch.\n",
    "        \"\"\"\n",
    "        if self.combined_df is None:\n",
    "            self.prepare_for_plotting(df_column_name)\n",
    "        \n",
    "        # Filter for selected stimulation IDs if provided\n",
    "        if selected_stim_ids is not None:\n",
    "            plot_df = self.combined_df[self.combined_df['stimulation_id'].isin(selected_stim_ids)]\n",
    "        else:\n",
    "            plot_df = self.combined_df\n",
    "\n",
    "        plt.figure(figsize=fig_size, dpi=dpi)\n",
    "        ax = plt.subplot()\n",
    "        \n",
    "        \n",
    "\n",
    "        # Plot the mean with error bars for each sensor\n",
    "        for sensor_name in self.sensor_names:\n",
    "            sensor_data = plot_df[plot_df['sensor_name'] == sensor_name]\n",
    "            means = sensor_data.groupby('stimulation_id')[df_column_name].mean()\n",
    "            errors = sensor_data.groupby('stimulation_id')[df_column_name].std() if error_type == 'SD' else sensor_data.groupby('stimulation_id')[df_column_name].sem()\n",
    "            \n",
    "            ax.errorbar(means.index, means, yerr=errors, label=sensor_name,\n",
    "                        fmt='-o', capsize=5, color=self.sensor_box_colors[sensor_name])\n",
    "        \n",
    "        # Set the font size of the x-axis and y-axis labels \n",
    "        ax.set_xlabel('Stimulation ID', fontsize=18)\n",
    "        ax.set_ylabel(df_column_name, fontsize=18)\n",
    "        \n",
    "        # Set the font size of the x-axis and y-axis ticks\n",
    "        ax.tick_params(axis='x', labelsize=24)\n",
    "        ax.tick_params(axis='y', labelsize=24)\n",
    "        \n",
    "        ax.set_title('Mean ' + df_column_name + ' by Stimulation ID across Sensors', fontsize=14)\n",
    "        ax.legend(title='Sensor', loc='upper left')\n",
    "                # Set custom axis limits if provided\n",
    "        if xlim:\n",
    "            plt.xlim(xlim)\n",
    "        if ylim:\n",
    "            plt.ylim(ylim)\n",
    "            \n",
    "        plt.tight_layout()\n",
    "        plt.show()\n",
    "                \n",
    "    def plot_time_series(self, full_array_column, selected_stim_ids=None, fig_size=(10, 8), dpi=300):\n",
    "        \"\"\"\n",
    "        Plots time series data for selected stimulation IDs for each sensor separately.\n",
    "        :param full_array_column: The name of the column with time series data.\n",
    "        :param selected_stim_ids: List of stimulation IDs to plot. If None, plot all available.\n",
    "        :param fig_size: Tuple representing the figure size of each subplot.\n",
    "        :param dpi: The resolution in dots per inch.\n",
    "        \"\"\"\n",
    "        if self.combined_df is None:\n",
    "            raise ValueError(\"Data has not been prepared for plotting. Call prepare_for_plotting first.\")\n",
    "        \n",
    "        # Get unique stimulation IDs to plot\n",
    "        stim_ids = selected_stim_ids if selected_stim_ids is not None else self.combined_df['stimulation_id'].unique()\n",
    "        num_stim_ids = len(stim_ids)\n",
    "        num_sensors = len(self.sensor_names)\n",
    "        \n",
    "        # Create a figure with subplots for each sensor and stimulation ID\n",
    "        fig, axes = plt.subplots(num_sensors, num_stim_ids, figsize=(fig_size[0] * num_stim_ids, fig_size[1] * num_sensors), dpi=dpi, sharey=True)\n",
    "\n",
    "        if num_sensors == 1 or num_stim_ids == 1:  # If there's only one sensor or one stim ID, axes will not be a 2D array\n",
    "            axes = np.array(axes).reshape(num_sensors, -1)\n",
    "\n",
    "        for row_idx, sensor_name in enumerate(self.sensor_names):\n",
    "            for col_idx, stim_id in enumerate(stim_ids):\n",
    "                ax = axes[row_idx, col_idx]\n",
    "                sensor_stim_data = self.combined_df[(self.combined_df['sensor_name'] == sensor_name) & (self.combined_df['stimulation_id'] == stim_id)]\n",
    "                \n",
    "                if not sensor_stim_data.empty:\n",
    "                    sample_size =  len(sensor_stim_data.iloc[0][full_array_column])\n",
    "                    time_vector = (np.arange(sample_size) - 10) * 100  # Adjust time_vector for 100 ms intervals\n",
    "\n",
    "                    # Plot all individual responses in grey using the time_vector\n",
    "                    for _, row in sensor_stim_data.iterrows():\n",
    "                        ax.plot(time_vector, row[full_array_column], color='gainsboro', alpha=0.3)\n",
    "\n",
    "                    # Calculate and plot the median response in the sensor's color\n",
    "                    median_response = np.nanmedian([row[full_array_column] for _, row in sensor_stim_data.iterrows()], axis=0)\n",
    "                    ax.plot(time_vector, median_response, color=self.sensor_box_colors[sensor_name])\n",
    "                    \n",
    "\n",
    "                ax.set_title(f'Stim ID {stim_id} - {sensor_name}', fontsize=14)\n",
    "                ax.set_xlabel('Time (ms)', fontsize=18)\n",
    "                if col_idx == 0:\n",
    "                    ax.set_ylabel('F/F', fontsize=18)\n",
    "                ax.tick_params(axis='x', labelsize=24)\n",
    "                ax.tick_params(axis='y', labelsize=24)\n",
    "  \n",
    "\n",
    "        plt.tight_layout()\n",
    "        plt.rcParams['font.sans-serif'] = 'Arial'\n",
    "        plt.show()\n",
    "        \n",
    "    def exp_decay(self, t, A, tau, C):\n",
    "        \"\"\"\n",
    "        Exponential decay function used for fitting the photobleaching.\n",
    "        :param t: Time variable.\n",
    "        :param A: Amplitude.\n",
    "        :param tau: Decay constant.\n",
    "        :param C: Offset.\n",
    "        \"\"\"\n",
    "        return A * np.exp(-t / tau) + C\n",
    "\n",
    "    def correct_photobleaching(self, full_array_column, fit_start):\n",
    "        \"\"\"\n",
    "        Applies exponential decay fitting to correct for photobleaching in the time series data.\n",
    "        :param full_array_column: The column name in the DataFrame containing the time series data.\n",
    "        :param fit_start: The index where to start fitting the exponential decay, typically after the response decay.\n",
    "        \"\"\"\n",
    "        corrected_column = f\"{full_array_column}_corrected\"\n",
    "        self.combined_df[corrected_column] = np.nan\n",
    "\n",
    "        for i, row in self.combined_df.iterrows():\n",
    "            time_series = np.array(row[full_array_column])\n",
    "            t = np.arange(len(time_series))\n",
    "\n",
    "            # Fit the exponential decay function to the photobleaching portion of the data\n",
    "            try:\n",
    "                # Initial parameters: A close to the average of the fit range, tau as a reasonable guess, C close to min of the fit range\n",
    "                p0 = [np.mean(time_series[fit_start:]), 100, np.min(time_series[fit_start:])]\n",
    "                params, _ = curve_fit(self.exp_decay, t[fit_start:], time_series[fit_start:], p0=p0)\n",
    "\n",
    "                # Generate the bleach correction curve\n",
    "                bleach_correction = self.exp_decay(t, *params)\n",
    "\n",
    "                # Correct the time series data\n",
    "                corrected_time_series = time_series / bleach_correction\n",
    "\n",
    "                # Store the corrected time series in the DataFrame\n",
    "                self.combined_df.at[i, corrected_column] = list(corrected_time_series)\n",
    "            except RuntimeError as e:\n",
    "                print(f\"Error fitting photobleaching: {e}\")\n",
    "                # If fitting fails, keep the original data\n",
    "                self.combined_df.at[i, corrected_column] = row[full_array_column]\n",
    "\n",
    "        return self.combined_df\n",
    "\n",
    "###################################################################\n",
    "#compare all three sensors\n",
    "###################################################################\n",
    "# Sensor names\n",
    "sensor_names = ['CaBLAM', 'CaBLAM1x', 'GCaMP8s']\n",
    "\n",
    "# Dictionaries for sensor colors (boxplot and stripplot)\n",
    "sensor_box_colors = {\n",
    "    'CaBLAM': '#ffcccc',   # Light red\n",
    "    'CaBLAM1x': '#ccccff', # Light blue\n",
    "    'GCaMP8s': '#d3d3d3'   # Light grey\n",
    "}\n",
    "\n",
    "sensor_strip_colors = {\n",
    "    'CaBLAM': '#ff0000',   # Dark red\n",
    "    'CaBLAM1x': '#0000ff', # Dark blue\n",
    "    'GCaMP8s': '#808080'   # Dark grey\n",
    "}\n",
    "\n",
    "# Initialize the SensorDataPlotter object\n",
    "allthree_plotter = SensorDataPlotter(\n",
    "    data_frames=[responsiveness_df_cablam, responsiveness_df_cablam1x, responsiveness_df_gcamp8],\n",
    "    sensor_names=sensor_names,\n",
    "    sensor_box_colors=sensor_box_colors,\n",
    "    sensor_strip_colors=sensor_strip_colors\n",
    ")\n",
    "# Prepare the data and plot\n",
    "allthree_plotter.plot_data('peak_delta_f_f_post_stim', selected_stim_ids=[12, 36, 60, 120, 480])\n",
    "allthree_plotter.plot_data('peak_delta_f_f_post_stim', selected_stim_ids=[12])\n",
    "\n",
    "\n",
    "# Prepare the data and plot\n",
    "allthree_plotter.plot_data('post_stim_mean', selected_stim_ids=[12, 36, 60, 120, 480])\n",
    "allthree_plotter.plot_data('time_to_peak', selected_stim_ids=[12, 36, 60, 120, 480])\n",
    "#allthree_plotter.plot_data('half_decay_time', selected_stim_ids=[12, 36, 60, 120, 480])\n",
    "\n",
    "allthree_plotter.plot_mean_with_error('peak_delta_f_f_post_stim', error_type='SEM')\n",
    "\n",
    "###################################################################\n",
    "#compare CaBLAM and CaBLAM1x\n",
    "##################################################################\n",
    "cablamvscablam1x_plotter = SensorDataPlotter(\n",
    "    data_frames=[responsiveness_df_cablam, responsiveness_df_cablam1x],\n",
    "    sensor_names=['CaBLAM', 'CaBLAM1x'],\n",
    "    sensor_box_colors={\n",
    "        'CaBLAM': '#ffcccc',   # Light red\n",
    "        'CaBLAM1x': '#ccccff'  # Light blue\n",
    "    },\n",
    "    sensor_strip_colors={\n",
    "        'CaBLAM': '#ff0000',   # Dark red\n",
    "        'CaBLAM1x': '#0000ff'  # Dark blue\n",
    "    }\n",
    ")\n",
    "\n",
    "cablamvscablam1x_plotter.plot_data('peak_delta_f_f_post_stim', selected_stim_ids=[12, 36, 60, 120, 480])\n",
    "cablamvscablam1x_plotter.plot_data('time_to_peak', selected_stim_ids=[12, 36, 60, 120, 480])\n",
    "cablamvscablam1x_plotter.plot_mean_with_error('peak_delta_f_f_post_stim', error_type='SEM', selected_stim_ids=[12, 36, 60, 120, 480], ylim=None)\n",
    "cablamvscablam1x_plotter.plot_time_series('delta_f_f_full_array', selected_stim_ids=[12, 36, 60, 120, 480])\n",
    "\n",
    "\n",
    "\n",
    "###################################################################\n",
    "#compare CaBLAM and GCaMP8s\n",
    "##################################################################\n",
    "\n",
    "# Sensor names\n",
    "sensor_names_cablamvsgcamp = ['CaBLAM', 'GCaMP8s']\n",
    "\n",
    "# Dictionaries for sensor colors (boxplot and stripplot)\n",
    "sensor_box_colors2 = {\n",
    "    'CaBLAM': '#ccccff',   # Light blue\n",
    "    'GCaMP8s': '#d3d3d3'   # Light grey\n",
    "}\n",
    "\n",
    "sensor_strip_colors2 = {\n",
    "    'CaBLAM': '#0000ff',   # Dark blue\n",
    "    'GCaMP8s': '#808080'   # Dark grey\n",
    "}\n",
    "# Initialize the SensorDataPlotter object\n",
    "cablamvsgcamp_plotter = SensorDataPlotter(\n",
    "    data_frames=[responsiveness_df_cablam, responsiveness_df_gcamp8],\n",
    "    sensor_names=sensor_names_cablamvsgcamp,\n",
    "    sensor_box_colors=sensor_box_colors2,\n",
    "    sensor_strip_colors=sensor_strip_colors2\n",
    ") \n",
    "\n",
    "cablamvsgcamp_plotter.plot_data('peak_delta_f_f_post_stim',selected_stim_ids=[12, 36, 60, 120, 480])\n",
    "cablamvsgcamp_plotter.plot_data('time_to_peak',selected_stim_ids=[12, 36, 60, 120, 480])\n",
    "\n",
    "cablamvsgcamp_plotter.plot_mean_with_error('peak_delta_f_f_post_stim', error_type='SEM' ,selected_stim_ids=[12, 36, 60, 120, 480], ylim=(0, 1.5))\n",
    "cablamvsgcamp_plotter.plot_time_series('delta_f_f_full_array', selected_stim_ids=[12, 36, 60, 120, 480])\n",
    "\n",
    "\n",
    "\n",
    "###################################################################\n",
    "# analyze for only GCaMP8s\n",
    "##################################################################\n",
    "\n",
    "# Sensor names\n",
    "sensor_names_gcamp = ['GCaMP8s']\n",
    "\n",
    "# Dictionaries for sensor colors (boxplot and stripplot)\n",
    "sensor_box_colors_gcamp = {\n",
    "    'GCaMP8s': '#d3d3d3'   # Light grey\n",
    "}\n",
    "\n",
    "sensor_strip_colors_gcamp = {\n",
    "    'GCaMP8s': '#808080'   # Dark grey\n",
    "}\n",
    "\n",
    "# Initialize the SensorDataPlotter object\n",
    "gcamp_plotter = SensorDataPlotter(\n",
    "    data_frames=[responsiveness_df_gcamp8],\n",
    "    sensor_names=sensor_names_gcamp,\n",
    "    sensor_box_colors=sensor_box_colors_gcamp,\n",
    "    sensor_strip_colors=sensor_strip_colors_gcamp\n",
    ")\n",
    "\n",
    "gcamp_plotter.plot_data('peak_delta_f_f_post_stim', selected_stim_ids=[12, 36, 60, 120, 480])\n",
    "gcamp_plotter.plot_data('time_to_peak', selected_stim_ids=[12, 36, 60, 120, 480])\n",
    "gcamp_plotter.plot_mean_with_error('peak_delta_f_f_post_stim', error_type='SEM', selected_stim_ids=[12, 36, 60, 120, 480], ylim=None)\n",
    "gcamp_plotter.plot_time_series('delta_f_f_full_array', selected_stim_ids=[12, 36, 60, 120, 480])\n",
    "gcamp_plotter.plot\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_n_per_sensor_stim_from_plotter(plotter, metric, stim_ids):\n",
    "    \"\"\"\n",
    "    Returns the number of neurons used in the plot_data boxplots per sensor and stimulus,\n",
    "    based on plotter.combined_df (which includes only responsive neurons).\n",
    "    \"\"\"\n",
    "    # Ensure combined_df is reset\n",
    "    plotter.prepare_for_plotting(metric)\n",
    "\n",
    "    df = plotter.combined_df\n",
    "    df = df[df['stimulation_id'].isin(stim_ids)]\n",
    "\n",
    "    summary = (\n",
    "        df.groupby(['sensor_name', 'stimulation_id'])\n",
    "          .size()\n",
    "          .reset_index(name='n_responsive_neurons')\n",
    "          .sort_values(['sensor_name', 'stimulation_id'])\n",
    "    )\n",
    "    return summary\n",
    "\n",
    "stim_ids = [12, 120]\n",
    "n_summary = get_n_per_sensor_stim_from_plotter(allthree_plotter, 'peak_delta_f_f_post_stim', stim_ids)\n",
    "print(n_summary)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def report_sample_sizes_from_plotter(plotter, df_column_name, selected_stim_ids=None, auto_reset=True):\n",
    "    if auto_reset:\n",
    "        plotter.prepare_for_plotting(df_column_name)\n",
    "\n",
    "    df = plotter.combined_df.copy()\n",
    "\n",
    "    if selected_stim_ids is not None:\n",
    "        df = df[df['stimulation_id'].isin(selected_stim_ids)]\n",
    "\n",
    "    summary_df = (\n",
    "        df.groupby(['sensor_name', 'stimulation_id'])\n",
    "          .size()\n",
    "          .reset_index(name='n_responsive_rois')\n",
    "          .sort_values(by=['sensor_name', 'stimulation_id'])\n",
    "    )\n",
    "\n",
    "    print(\"\\nSample size report (responsive ROIs used per group):\")\n",
    "    for _, row in summary_df.iterrows():\n",
    "        print(f\"  {row['sensor_name']}  Stim {row['stimulation_id']}: n = {row['n_responsive_rois']}\")\n",
    "\n",
    "    return summary_df\n",
    "\n",
    "report_sample_sizes_from_plotter(cablamvsgcamp_plotter, 'peak_delta_f_f_post_stim', selected_stim_ids=[12, 60, 480])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "report_sample_sizes_from_plotter(cablamvscablam1x_plotter, 'peak_delta_f_f_post_stim', selected_stim_ids=[12, 36, 60, 120, 480])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "def plot_stim_responsiveness(df, stim_ids=None, include='responsive', y_lim=None, x_lim=None, mean_color='black', figsize=(15, 5)):\n",
    "    \"\"\"\n",
    "    Plots the delta F/F response for given stimulation IDs, filtering based on responsiveness if specified.\n",
    "    Individual replicates are plotted in light grey, while the mean response is plotted in a user-defined color.\n",
    "    Adds a red dotted line at the stimulation onset, considering the user-defined x-axis limits.\n",
    "    User can define the y-axis limits, x-axis limits, and the figure size.\n",
    "\n",
    "    Parameters:\n",
    "    - df (pd.DataFrame): DataFrame containing the responsiveness data.\n",
    "    - stim_ids (list): List of stimulation IDs to plot. If None, all unique IDs in the DataFrame will be used.\n",
    "    - include (str): Can be 'responsive', 'non-responsive', or 'both' to filter units based on responsiveness.\n",
    "    - y_lim (tuple): A tuple of (min, max) for y-axis limits. If None, limits are automatically determined.\n",
    "    - x_lim (tuple): A tuple of (min, max) for x-axis limits. If None, defaults to the entire range of the data.\n",
    "    - mean_color (str): Color for the mean response line.\n",
    "    - figsize (tuple): Figure dimension as (width, height).\n",
    "\n",
    "    Returns:\n",
    "    - fig (plt.Figure): The created figure.\n",
    "    \"\"\"\n",
    "    # Filter based on responsiveness if required\n",
    "    if include == 'responsive':\n",
    "        df = df[df['is_responsive'] == True]\n",
    "    elif include == 'non-responsive':\n",
    "        df = df[df['is_responsive'] == False]\n",
    "\n",
    "    # If stim_ids is not provided, get the unique IDs from the DataFrame and sort them\n",
    "    if stim_ids is None:\n",
    "        stim_ids = sorted(df['stimulation_id'].unique())\n",
    "    else:\n",
    "        stim_ids = sorted(stim_ids)\n",
    "\n",
    "    # Create a figure and axes with subplots\n",
    "    n_stims = len(stim_ids)\n",
    "    fig, axes = plt.subplots(1, n_stims, figsize=figsize, sharey=True)\n",
    "\n",
    "    # Adjust if we only have one subplot to make sure 'axes' is iterable\n",
    "    if n_stims == 1:\n",
    "        axes = [axes]\n",
    "\n",
    "    # Set the y-axis limit if specified\n",
    "    if y_lim:\n",
    "        plt.setp(axes, ylim=y_lim)\n",
    "\n",
    "    # Adjust the x-axis to align with the pre-stimulus, stimulus onset, and post-stimulus periods\n",
    "    stim_index = 10  # Index at which stimulation occurs\n",
    "    total_frames = 111  # Total number of frames, including pre-stim, stim, and post-stim\n",
    "\n",
    "    # Iterate through each sorted stimulation ID and plot\n",
    "    for ax, stim_id in zip(axes, stim_ids):\n",
    "        stim_df = df[df['stimulation_id'] == stim_id]\n",
    "\n",
    "        # Assuming 'delta_f_f_full_array' contains lists, we will need to extract them\n",
    "        delta_f_f_values = np.vstack(stim_df['delta_f_f_full_array'].values)\n",
    "\n",
    "        # Adjust the time vector to account for the stimulation index\n",
    "        time_vector = np.arange(-stim_index, total_frames - stim_index)\n",
    "\n",
    "        # Plot individual replicates in light grey\n",
    "        for trace in delta_f_f_values:\n",
    "            ax.plot(time_vector, trace, color='lightgrey', linewidth=0.5)\n",
    "\n",
    "        # Calculate mean response\n",
    "        mean_response = np.nanmean(delta_f_f_values, axis=0)\n",
    "\n",
    "        # Plot the mean response in user-defined color\n",
    "        ax.plot(time_vector, mean_response, color=mean_color, label=f'Stim ID {stim_id}')\n",
    "\n",
    "        # Set the x-axis limit if specified\n",
    "        if x_lim:\n",
    "            ax.set_xlim(x_lim)\n",
    "\n",
    "        # Add a vertical line at stimulation onset if within the x_lim range\n",
    "        if not x_lim or (x_lim and x_lim[0] <= 0 <= x_lim[1]):\n",
    "            ax.axvline(x=0, color='red', linestyle='--', label='Stimulation Onset')\n",
    "\n",
    "        ax.set_title(f'Stim ID {stim_id}')\n",
    "        ax.set_xlabel('Time (relative to stimulus)')\n",
    "        ax.set_ylabel('F/F')\n",
    "        ax.legend()\n",
    "        #hide legend\n",
    "        ax.get_legend().remove()\n",
    "        \n",
    "        \n",
    "\n",
    "    # To prevent x-axis labels from overlapping\n",
    "    plt.tight_layout()\n",
    "\n",
    "    return fig\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "# Usage example:\n",
    "# Assuming 'responsiveness_df_cablam' is your DataFrame\n",
    "# Usage example with user-defined x-axis limits:\n",
    "plot_fig = plot_stim_responsiveness(\n",
    "    df=responsiveness_df_cablam,\n",
    "    stim_ids = [12, 24, 36, 60, 120, 480],\n",
    "    include='responsive',\n",
    "   \n",
    "    x_lim=(-15,105),  # Set x-axis limits as needed\n",
    "    mean_color='blue', #what other color optuions are there?\n",
    "    figsize=(20, 6)\n",
    ")\n",
    "\n",
    "# Usage example:\n",
    "# Assuming 'responsiveness_df_cablam' is your DataFrame\n",
    "# Usage example with user-defined x-axis limits:\n",
    "plot_fig = plot_stim_responsiveness(\n",
    "    df=responsiveness_df_cablam,\n",
    "    stim_ids = [12, 24, 36, 60, 120, 480],\n",
    "    include='responsive',\n",
    "  \n",
    "    x_lim=(-15,10),  # Set x-axis limits as needed\n",
    "    mean_color='blue',\n",
    "    figsize=(20, 6)#what other color optuions are there?\n",
    ")    \n",
    "plot_fig = plot_stim_responsiveness(\n",
    "    df=responsiveness_df_gcamp8,\n",
    "    stim_ids = [12, 24, 36, 60, 120, 480],\n",
    "    include='responsive',\n",
    "    \n",
    "    x_lim=(-15,10),  # Set x-axis limits as needed\n",
    "    mean_color='blue', #what other color optuions are there?\n",
    "    figsize=(20, 6)\n",
    ")\n",
    "\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def plot_stim_responsiveness(df, stim_ids=None, include='both', y_lim=None, x_lim=None, mean_color='black', figsize=(15, 5)):\n",
    "    \"\"\"\n",
    "    Plots the delta F/F response for given stimulation IDs, filtering based on responsiveness if specified.\n",
    "    Individual replicates are plotted in light grey, while the mean response is plotted in a user-defined color.\n",
    "    Adds a red dotted line at the stimulation onset, considering the user-defined x-axis limits.\n",
    "    Prints the number of responsive and unresponsive units for each stimulus ID on the plot.\n",
    "    User can define the y-axis limits, x-axis limits, and the figure size.\n",
    "\n",
    "    Parameters:\n",
    "    - df (pd.DataFrame): DataFrame containing the responsiveness data.\n",
    "    - stim_ids (list): List of stimulation IDs to plot. If None, all unique IDs in the DataFrame will be used.\n",
    "    - include (str): Can be 'responsive', 'non-responsive', or 'both' to filter units based on responsiveness.\n",
    "    - y_lim (tuple): A tuple of (min, max) for y-axis limits. If None, limits are automatically determined.\n",
    "    - x_lim (tuple): A tuple of (min, max) for x-axis limits. If None, defaults to the entire range of the data.\n",
    "    - mean_color (str): Color for the mean response line.\n",
    "    - figsize (tuple): Figure dimension as (width, height).\n",
    "\n",
    "    Returns:\n",
    "    - fig (plt.Figure): The created figure.\n",
    "    \"\"\"\n",
    "    # Prepare responsive and non-responsive DataFrames if needed\n",
    "    df_responsive = df[df['is_responsive'] == True] if include in ['responsive', 'both'] else pd.DataFrame()\n",
    "    df_unresponsive = df[df['is_responsive'] == False] if include in ['non-responsive', 'both'] else pd.DataFrame()\n",
    "\n",
    "    # If stim_ids is not provided, get the unique IDs from the DataFrame and sort them\n",
    "    if stim_ids is None:\n",
    "        stim_ids = sorted(df['stimulation_id'].unique())\n",
    "    else:\n",
    "        stim_ids = sorted(stim_ids)\n",
    "\n",
    "    # Create a figure and axes with subplots\n",
    "    n_stims = len(stim_ids)\n",
    "    fig, axes = plt.subplots(1, n_stims, figsize=figsize, sharey=True)\n",
    "\n",
    "    # Adjust if we only have one subplot to make sure 'axes' is iterable\n",
    "    if n_stims == 1:\n",
    "        axes = [axes]\n",
    "\n",
    "    # Set the y-axis limit if specified\n",
    "    if y_lim:\n",
    "        plt.setp(axes, ylim=y_lim)\n",
    "\n",
    "    # Set the x-axis limit if specified\n",
    "    if x_lim:\n",
    "        plt.setp(axes, xlim=x_lim)\n",
    "\n",
    "    # Adjust the x-axis to align with the pre-stimulus, stimulus onset, and post-stimulus periods\n",
    "    stim_index = 10  # Index at which stimulation occurs\n",
    "    total_frames = 111  # Total number of frames, including pre-stim, stim, and post-stim\n",
    "\n",
    "    # Iterate through each sorted stimulation ID and plot\n",
    "    for ax, stim_id in zip(axes, stim_ids):\n",
    "        if include in ['responsive', 'both']:\n",
    "            stim_df = df_responsive[df_responsive['stimulation_id'] == stim_id]\n",
    "            delta_f_f_values = np.vstack(stim_df['delta_f_f_full_array'].values)\n",
    "            \n",
    "        if include in ['non-responsive', 'both']:\n",
    "            stim_df_nonres = df_unresponsive[df_unresponsive['stimulation_id'] == stim_id]\n",
    "            delta_f_f_values_nonres = np.vstack(stim_df_nonres['delta_f_f_full_array'].values) if not stim_df_nonres.empty else np.array([])\n",
    "            \n",
    "        # Adjust the time vector to account for the stimulation index\n",
    "        time_vector = np.arange(-stim_index, total_frames - stim_index)\n",
    "        \n",
    "        # Plot individual replicates in light grey\n",
    "        for trace in delta_f_f_values_nonres:\n",
    "            ax.plot(time_vector, trace, color='lightgrey', linewidth=0.5, alpha=0.5)\n",
    "        for trace in delta_f_f_values:\n",
    "            ax.plot(time_vector, trace, color='lightgrey', linewidth=0.5)\n",
    "\n",
    "        # Calculate mean response\n",
    "        mean_response = np.nanmean(delta_f_f_values, axis=0)\n",
    "\n",
    "        # Plot the mean response in user-defined color\n",
    "        ax.plot(time_vector, mean_response, color=mean_color, label=f'Stim ID {stim_id}')\n",
    "\n",
    "        # Set the x-axis limit if specified\n",
    "        if x_lim:\n",
    "            ax.set_xlim(x_lim)\n",
    "\n",
    "        # Add a vertical line at stimulation onset if within the x_lim range\n",
    "        if not x_lim or (x_lim and x_lim[0] <= 0 <= x_lim[1]):\n",
    "            ax.axvline(x=0, color='red', linestyle='--', label='Stimulation Onset')\n",
    "\n",
    "        # Print the counts on the plot\n",
    "        ax.text(0.95, 0.95, f'Responsive: {len(delta_f_f_values)}\\nUnresponsive: {len(delta_f_f_values_nonres)}',\n",
    "                verticalalignment='top', horizontalalignment='right',\n",
    "                transform=ax.transAxes, color='black', fontsize=8, bbox=dict(boxstyle=\"round,pad=0.3\", edgecolor='black', facecolor='white', alpha=0.5))\n",
    "\n",
    "        ax.set_title(f'Stim ID {stim_id}')\n",
    "        ax.set_xlabel('Time (relative to stimulus)')\n",
    "        ax.set_ylabel('F/F')\n",
    "        ax.legend().remove()\n",
    "\n",
    "    # To prevent x-axis labels from overlapping\n",
    "    plt.tight_layout()\n",
    "\n",
    "    return fig\n",
    "# Usage example:\n",
    "# Assuming 'responsiveness_df_cablam' is your DataFrame\n",
    "plot_fig = plot_stim_responsiveness(\n",
    "    df=responsiveness_df_cablam,\n",
    "    stim_ids = [12, 24, 36, 60, 120, 480],\n",
    "    include='both',\n",
    "    y_lim=None,\n",
    "    x_lim=(-10, 100),\n",
    "    mean_color='red',\n",
    "    figsize=(20, 6)\n",
    ")\n",
    "\n",
    "# Assuming 'responsiveness_df_cablam' is your DataFrame\n",
    "plot_fig = plot_stim_responsiveness(\n",
    "    df=responsiveness_df_gcamp8,\n",
    "    include='both',\n",
    "    y_lim=None,\n",
    "    x_lim=(-10, 100),\n",
    "    mean_color='black',\n",
    "    figsize=(20, 6)\n",
    ")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "\n",
    "def plot_stim_responsiveness(df, stim_ids=None, include='both', y_lim=None, x_lim=None, mean_color='black', figsize=(15, 5)):\n",
    "    \"\"\"\n",
    "    Plots the delta F/F response for given stimulation IDs, filtering based on responsiveness if specified.\n",
    "    Individual replicates are plotted in light grey, while the mean response is plotted in a user-defined color.\n",
    "    Adds a red dotted line at the stimulation onset, considering the user-defined x-axis limits.\n",
    "    Prints the number of responsive and unresponsive units for each stimulus ID on the plot.\n",
    "    User can define the y-axis limits, x-axis limits, and the figure size.\n",
    "\n",
    "    Parameters:\n",
    "    - df (pd.DataFrame): DataFrame containing the responsiveness data.\n",
    "    - stim_ids (list): List of stimulation IDs to plot. If None, all unique IDs in the DataFrame will be used.\n",
    "    - include (str): Can be 'responsive', 'non-responsive', or 'both' to filter units based on responsiveness.\n",
    "    - y_lim (tuple): A tuple of (min, max) for y-axis limits. If None, limits are automatically determined.\n",
    "    - x_lim (tuple): A tuple of (min, max) for x-axis limits. If None, defaults to the entire range of the data.\n",
    "    - mean_color (str): Color for the mean response line.\n",
    "    - figsize (tuple): Figure dimension as (width, height).\n",
    "\n",
    "    Returns:\n",
    "    - fig (plt.Figure): The created figure.\n",
    "    \"\"\"\n",
    "\n",
    "    # If stim_ids is not provided, get the unique IDs from the DataFrame and sort them\n",
    "    if stim_ids is None:\n",
    "        stim_ids = sorted(df['stimulation_id'].unique())\n",
    "    else:\n",
    "        stim_ids = sorted(stim_ids)\n",
    "    \n",
    "    # Adjust the x-axis to align with the pre-stimulus, stimulus onset, and post-stimulus periods\n",
    "    stim_index = 9  # Index at which stimulation occurs\n",
    "    total_frames = 111  # Total number of frames, including pre-stim, stim, and post-stim\n",
    "    sampling_interval = 100  # Time per index in ms at 10Hz sampling rate\n",
    "\n",
    "    # Create a figure and axes with subplots\n",
    "    n_stims = len(stim_ids)\n",
    "    fig, axes = plt.subplots(1, n_stims, figsize=figsize, sharey=True)\n",
    "\n",
    "    # Adjust if we only have one subplot to make sure 'axes' is iterable\n",
    "    if n_stims == 1:\n",
    "        axes = [axes]\n",
    "\n",
    "    # Set the y-axis limit if specified\n",
    "    if y_lim:\n",
    "        plt.setp(axes, ylim=y_lim)\n",
    "\n",
    "    # Set the x-axis limit if specified\n",
    "    if x_lim is not None:\n",
    "        new_x_lim = (x_lim[0] * sampling_interval, x_lim[1] * sampling_interval)\n",
    "        plt.setp(axes, xlim=new_x_lim)\n",
    "\n",
    "\n",
    "\n",
    "    for ax, stim_id in zip(axes, stim_ids):\n",
    "        # Filter the DataFrame based on the current stim_id\n",
    "        stim_df = df[df['stimulation_id'] == stim_id]\n",
    "        if include != 'both':\n",
    "            stim_df = stim_df[stim_df['is_responsive'] == (include == 'responsive')]\n",
    "\n",
    "        # Get the delta_f_f_full_array values for plotting\n",
    "        delta_f_f_values = np.vstack(stim_df['delta_f_f_full_array'].values)\n",
    "\n",
    "        # Calculate the time vector considering the stimulation index\n",
    "        time_vector = np.arange(-stim_index, total_frames - stim_index) * sampling_interval\n",
    "\n",
    "        # Plot individual replicates in light grey\n",
    "        for trace in delta_f_f_values:\n",
    "            ax.plot(time_vector, trace, color='lightgrey', linewidth=0.5)\n",
    "\n",
    "        # Calculate mean response and plot in the specified mean_color\n",
    "        mean_response = np.nanmedian(delta_f_f_values, axis=0)\n",
    "        ax.plot(time_vector, mean_response, color=mean_color, label=f'Stim ID {stim_id}')\n",
    "\n",
    "        # Add vertical line at stimulation onset if it's within the x-axis limits\n",
    "        if x_lim is None or (0 >= x_lim[0] and 0 <= x_lim[1]):\n",
    "            ax.axvline(x=0, color='red', linestyle='--', label='Stimulation Onset')\n",
    "\n",
    "        # Count and display the number of responsive and unresponsive units for this stim_id\n",
    "        num_responsive = len(stim_df[stim_df['is_responsive'] == True])\n",
    "        num_unresponsive = len(stim_df[stim_df['is_responsive'] == False])\n",
    "        info_text = f'Responsive: {num_responsive}'\n",
    "        ax.text(0.95, 0.95, info_text, transform=ax.transAxes, fontsize=9,\n",
    "                verticalalignment='top', horizontalalignment='right',\n",
    "                bbox=dict(facecolor='white', alpha=0.5, edgecolor='black', boxstyle='round'))\n",
    "\n",
    "        # Set titles and labels\n",
    "        ax.set_title(f'Stim ID {stim_id}')\n",
    "        ax.set_xlabel('ms', fontsize=24)\n",
    "        ax.set_ylabel('F/F$_o$ (%)', fontsize=24)\n",
    "        #make y-axis labels larger\n",
    "        ax.tick_params(axis='y', labelsize=18)\n",
    "        ax.tick_params(axis='x', labelsize=18)\n",
    "        ax.legend().remove()\n",
    "\n",
    "    # To prevent x-axis labels from overlapping\n",
    "    plt.tight_layout()\n",
    "\n",
    "    return fig\n",
    "\n",
    "plot_stim_responsiveness(\n",
    "    df=responsiveness_df_cablam,\n",
    "    include='responsive',\n",
    "    y_lim=None,\n",
    "    x_lim=(-10, 100),\n",
    "    mean_color='red',\n",
    "    figsize=(20, 6)\n",
    ")\n",
    "\n",
    "plot_stim_responsiveness(\n",
    "    df=responsiveness_df_cablam1x,\n",
    "    include='responsive',\n",
    "    y_lim=None,\n",
    "    x_lim=(-10, 100),\n",
    "    mean_color='blue',\n",
    "    figsize=(20, 6)\n",
    ")\n",
    "\n",
    "plot_stim_responsiveness(\n",
    "    df=responsiveness_df_cablam,\n",
    "    include='responsive',\n",
    "    stim_ids = [12, 24, 36, 60, 120, 480],\n",
    "    y_lim=None,\n",
    "    x_lim=(-10, 100),\n",
    "    mean_color='red',\n",
    "    figsize=(20, 6)\n",
    ")\n",
    "\n",
    "plot_stim_responsiveness(\n",
    "    df=responsiveness_df_cablam1x,\n",
    "    stim_ids = [12, 24, 36, 60, 120, 480],\n",
    "    include='responsive',\n",
    "    y_lim=None,\n",
    "    x_lim=(-10, 100),\n",
    "    mean_color='blue',\n",
    "    figsize=(20, 6)\n",
    ")\n",
    "\n",
    "plot_stim_responsiveness(\n",
    "    df=responsiveness_df_gcamp8,\n",
    "    include='responsive',\n",
    "    y_lim=None,\n",
    "    x_lim=(-10, 100),\n",
    "    mean_color='black',\n",
    "    figsize=(20, 6)\n",
    ")\n",
    "\n",
    "plot_fig = plot_stim_responsiveness(\n",
    "    df=responsiveness_df_cablam,\n",
    "    stim_ids = [12, 24, 36, 60, 120, 480],\n",
    "    include='responsive',\n",
    "    y_lim=None,\n",
    "    x_lim=(-10, 10),\n",
    "    mean_color='red',\n",
    "    figsize=(20, 6)\n",
    ")\n",
    "\n",
    "# Assuming 'responsiveness_df_cablam' is your DataFrame\n",
    "plot_fig = plot_stim_responsiveness(\n",
    "    df=responsiveness_df_gcamp8,\n",
    "    include='responsive',\n",
    "    y_lim=None,\n",
    "    x_lim=(-10, 10),\n",
    "    mean_color='black',\n",
    "    figsize=(20, 6)\n",
    ")\n",
    "\n",
    "# Assuming 'responsiveness_df_cablam' is your DataFrame\n",
    "plot_fig = plot_stim_responsiveness(\n",
    "    df=responsiveness_df_gcamp8,\n",
    "    include='responsive',\n",
    "    y_lim=None,\n",
    "    x_lim=(-5, 20),\n",
    "    mean_color='black',\n",
    "    figsize=(20, 6)\n",
    ")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "from scipy.signal import fftconvolve\n",
    "\n",
    "def calculate_template(dataframe, stimulation_id_col, is_responsive_col, delta_f_f_full_array_col, stimulation_id_val=12):\n",
    "    # Filter the dataframe to get the relevant data\n",
    "    template_data = dataframe[(dataframe[stimulation_id_col] == stimulation_id_val) & (dataframe[is_responsive_col] == True)]\n",
    "    delta_f_f_full_arrays = template_data[delta_f_f_full_array_col].values\n",
    "    #for to be sure that the data is a numpy and not a pandas array\n",
    "    delta_f_f_full_arrays = np.array(delta_f_f_full_arrays)\n",
    "    \n",
    "    #stack the arrays of delta_f_f_full_arrays\n",
    "    delta_f_f_full_arrays = np.vstack(delta_f_f_full_arrays) #stack the arrays of delta_f_f_full_arrays by row\n",
    "    # Calculate the median across each ROI (each row)\n",
    "    template = np.nanmedian(delta_f_f_full_arrays, axis=0)\n",
    "    \n",
    "    #normalize the template by the euclidean norm\n",
    "    template = template / np.linalg.norm(template)\n",
    "    \n",
    "    #print the number of NANs in the template\n",
    "    print(f'Number of NaNs in the template: {np.sum(np.isnan(template))}')\n",
    "    \n",
    "    #only use from the 10th frame to the 50th fram\n",
    "    template = template[10:14]\n",
    "    return template\n",
    "\n",
    "\n",
    "def interpolate_signal(time_series_np):\n",
    "    \"\"\"Interpolate missing values in a time series.\"\"\"\n",
    "    time_series_pd = pd.Series(time_series_np)\n",
    "    time_series_interpolated = time_series_pd.interpolate()\n",
    "    # Forward-fill or back-fill to handle NaNs at the beginning or end\n",
    "    time_series_interpolated = time_series_interpolated.fillna(method='bfill').fillna(method='ffill')\n",
    "    return time_series_interpolated.values\n",
    "\n",
    "\n",
    "def template_matching(session_id, roi_data, template_data):\n",
    "    session_id = str(session_id)\n",
    "    session_data = roi_data[session_id]\n",
    "    results = {}\n",
    "    results[session_id] = {}\n",
    "    \n",
    "    for roi_id, time_series_data in session_data.items():\n",
    "        time_series_data_np = np.array(time_series_data.values)\n",
    "        nan_count = np.sum(np.isnan(time_series_data_np))\n",
    "        \n",
    "        print(f'Number of NaNs in the time series data for ROI {roi_id}: {nan_count}')\n",
    "        print(f'Total number of elements in the time series data for ROI {roi_id}: {len(time_series_data_np)}')\n",
    "        \n",
    "        # Interpolate NaNs if they are present\n",
    "        if nan_count > 0:\n",
    "            time_series_data_np = interpolate_signal(time_series_data_np)\n",
    "            # Check if the interpolation was successful\n",
    "            nan_count = np.sum(np.isnan(time_series_data_np))\n",
    "            if nan_count > 0:\n",
    "                print(f'Interpolation failed for ROI {roi_id}: Still contains NaNs after interpolation.')\n",
    "                continue\n",
    "        \n",
    "        # Apply matched filtering\n",
    "        filtered_signal = fftconvolve(time_series_data_np, template_data[::-1], mode='same')\n",
    "        \n",
    "        # Threshold calculation may need to handle NaNs if they are still present\n",
    "        threshold = np.nanstd(filtered_signal) * 3\n",
    "        \n",
    "        # Find peaks\n",
    "        peaks = np.where(filtered_signal > threshold)[0]\n",
    "        results[session_id][roi_id] = {\n",
    "            'peaks': peaks, \n",
    "            'filtered_signal': filtered_signal, \n",
    "            'threshold': threshold, \n",
    "            'original_signal': time_series_data_np, \n",
    "            'template': template_data\n",
    "        }\n",
    "        \n",
    "    return results\n",
    "\n",
    "session_id = 2112242023  # Choose a session ID\n",
    "stimulation_id_col = 'stimulation_id'\n",
    "is_responsive_col = 'is_responsive'\n",
    "#delta_f_f_full_array_col = 'delta_f_f_full_array'\n",
    "delta_f_f_full_array_col = 'raw_signal'\n",
    "\n",
    "\n",
    "cablam_template = calculate_template(responsiveness_df_cablam, stimulation_id_col, is_responsive_col, delta_f_f_full_array_col)\n",
    "\n",
    "print(list(cablam_filtered_responsive_rois.keys()))\n",
    "\n",
    "template_matching_results = template_matching(session_id, cablam_filtered_responsive_rois, cablam_template)\n",
    "\n",
    "\n",
    "plt.plot(cablam_template)\n",
    "#plt.plot(cablam_template[::-1])\n",
    "\n",
    "#plot separately the peaks and the filtered signal on two different subplots\n",
    "plt.figure(figsize=(15, 5))\n",
    "plt.subplot(1, 2, 1)\n",
    "plt.plot(template_matching_results['2112242023']['ROI_10']['original_signal'])\n",
    "plt.plot(template_matching_results['2112242023']['ROI_10']['peaks'], template_matching_results['2112242023']['ROI_10']['original_signal'][template_matching_results['2112242023']['ROI_10']['peaks']], 'ro')\n",
    "\n",
    "\n",
    "template_matching_results['2112242023']['ROI_10']['filtered_signal']\n",
    "plt.plot(template_matching_results['2112242023']['ROI_10']['filtered_signal'])\n",
    "\n",
    "\n",
    "# Plot original signal and peaks\n",
    "plt.subplot(2, 1, 1)\n",
    "plt.title('Original Signal and Detected Peaks')\n",
    "plt.plot(template_matching_results['2112242023']['ROI_10']['original_signal'], label='Original Signal')\n",
    "plt.plot(template_matching_results['2112242023']['ROI_10']['peaks'],\n",
    "         template_matching_results['2112242023']['ROI_10']['original_signal'][template_matching_results['2112242023']['ROI_10']['peaks']],\n",
    "         'ro', label='Detected Peaks')\n",
    "plt.legend()\n",
    "\n",
    "# Plot filtered signal and threshold line\n",
    "plt.subplot(2, 1, 2)\n",
    "plt.title('Filtered Signal and Detection Threshold')\n",
    "plt.plot(template_matching_results['2112242023']['ROI_10']['filtered_signal'], label='Filtered Signal')\n",
    "plt.axhline(y=template_matching_results['2112242023']['ROI_10']['threshold'], color='r', linestyle='--', label='Detection Threshold')\n",
    "\n",
    "#zoom in on the peaks\n",
    "plt.legend()\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()\n",
    "\n",
    "###################################################################\n",
    "# null distribution and significance threshold\n",
    "##################################################################\n",
    "\n",
    "\n",
    "\n",
    "def create_null_distribution_and_match(dataframe, norm_template, stimulation_id_col, is_responsive_col, delta_f_f_full_array_col, stimulation_id_val=12, num_iterations=8000):\n",
    "    \"\"\"\n",
    "    Create a null distribution by shuffling time-locked responses and then applying template matching with the actual 1AP template.\n",
    "    \n",
    "    - dataframe: DataFrame containing the experimental data.\n",
    "    - norm_template: The original 1AP template array to use for matching normalized.\n",
    "    - stimulation_id_col: Column name for stimulation IDs.\n",
    "    - is_responsive_col: Column name indicating if an ROI is responsive.\n",
    "    - delta_f_f_full_array_col: Column name where time-locked array data is stored.\n",
    "    - stimulation_id_val: The specific stimulation ID value to filter by.\n",
    "    - num_iterations: Number of shuffles to perform for the null distribution.\n",
    "    \"\"\"\n",
    "\n",
    "    \n",
    "    # Filter the dataframe for responsive ROIs with the specific stimulation ID\n",
    "    template_data = dataframe[(dataframe[stimulation_id_col] == stimulation_id_val) & (dataframe[is_responsive_col] == True)]\n",
    "    delta_f_f_full_arrays = template_data[delta_f_f_full_array_col].values\n",
    "    print(\"Data type and shape of one sample array:\", type(delta_f_f_full_arrays[0]), delta_f_f_full_arrays[0].shape)\n",
    "    \n",
    "    # Ensure data is in numpy array format and interpolate to handle NaNs\n",
    "    delta_f_f_full_arrays = np.array([interpolate_signal(np.array(x)) for x in delta_f_f_full_arrays])\n",
    "    \n",
    "    scores_null = []\n",
    "    for _ in range(num_iterations):\n",
    "        # Shuffle each time-locked response array\n",
    "        shuffled_data = [np.random.permutation(array) for array in delta_f_f_full_arrays]\n",
    "        # Stack the shuffled arrays\n",
    "        shuffled_stacked = np.vstack(shuffled_data)\n",
    "        \n",
    "        # Apply template matching using fftconvolve\n",
    "        filtered_signal = fftconvolve(shuffled_stacked.mean(axis=0), norm_template[::-1], mode='same')\n",
    "        max_score = np.max(filtered_signal)\n",
    "        scores_null.append(max_score)\n",
    "        \n",
    "    \n",
    "    threshold = np.percentile(null_scores, 95)  # 95th percentile as threshold\n",
    "    \n",
    "    return scores_null, threshold\n",
    "\n",
    "def template_matching_vs_null(session_id, roi_data, norm_template, significance_threshold):\n",
    "    session_id = str(session_id)\n",
    "    session_data = roi_data[session_id]\n",
    "    results = {}\n",
    "    results[session_id] = {}\n",
    "\n",
    "\n",
    "    for roi_id, time_series_data in session_data.items():\n",
    "        time_series_data_np = np.array(time_series_data.values)\n",
    "        nan_count = np.sum(np.isnan(time_series_data_np))\n",
    "        \n",
    "        print(f'Number of NaNs in the time series data for ROI {roi_id}: {nan_count}')\n",
    "        print(f'Total number of elements in the time series data for ROI {roi_id}: {len(time_series_data_np)}')\n",
    "        \n",
    "        # Interpolate NaNs if they are present\n",
    "        if nan_count > 0:\n",
    "            time_series_data_np = interpolate_signal(time_series_data_np)\n",
    "            # Check if the interpolation was successful\n",
    "            nan_count = np.sum(np.isnan(time_series_data_np))\n",
    "            if nan_count > 0:\n",
    "                print(f'Interpolation failed for ROI {roi_id}: Still contains NaNs after interpolation.')\n",
    "                continue\n",
    "\n",
    "        # Apply matched filtering\n",
    "        filtered_signal = fftconvolve(time_series_data_np, norm_template[::-1], mode='same')\n",
    "        \n",
    "        # Calculate the standard deviation of the filtered signal to set a local threshold\n",
    "        local_threshold = np.nanstd(filtered_signal) * 3\n",
    "\n",
    "        # Find peaks using the local threshold\n",
    "        peaks = np.where(filtered_signal > local_threshold)[0]\n",
    "\n",
    "        # Evaluate against the significance threshold from null distribution\n",
    "        max_filtered_value = np.max(filtered_signal)\n",
    "        is_significant = max_filtered_value > significance_threshold\n",
    "        \n",
    "        results[session_id][roi_id] = {\n",
    "            'peaks': peaks, \n",
    "            'filtered_signal': filtered_signal, \n",
    "            'local_threshold': local_threshold,\n",
    "            'max_filtered_value': max_filtered_value,\n",
    "            'is_significant': is_significant,\n",
    "            'original_signal': time_series_data_np, \n",
    "            'template': norm_template\n",
    "        }\n",
    "        \n",
    "    return results\n",
    "# \n",
    "# \n",
    "# Example usage\n",
    "session_id = 2112242023  # Choose a session ID\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "# Assuming you have a DataFrame `responsiveness_df` structured correctly\n",
    "null_scores, threshold = create_null_distribution_and_match(responsiveness_df_cablam, cablam_template, stimulation_id_col = 'stimulation_id', is_responsive_col = 'is_responsive', delta_f_f_full_array_col = 'delta_f_f_full_array', stimulation_id_val=12)\n",
    "\n",
    "#asses the null distribution and significance threshold\n",
    "\n",
    "\n",
    "print(\"Null distribution scores:\", null_scores)\n",
    "threshold = np.percentile(null_scores, 95)  # 95th percentile as threshold\n",
    "print(\"Significance Threshold:\", threshold)\n",
    "\n",
    "\n",
    "    \n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Call the renamed function\n",
    "#results = template_matching_vs_null(session_id, cablam_filtered_responsive_rois, cablam_template, significance_threshold)\n",
    "\n",
    "all_results = {}  # Dictionary to store results from all sessions\n",
    "session_ids = ['2112242023', '2212242023', '2312242023']\n",
    "for session_id in session_ids:\n",
    "    print(f\"Processing session ID: {session_id}\")\n",
    "    #create the null distribution and calculate the threshold\n",
    "    null_scores, threshold = create_null_distribution_and_match(responsiveness_df_cablam, cablam_template, stimulation_id_col = 'stimulation_id', is_responsive_col = 'is_responsive', delta_f_f_full_array_col = 'delta_f_f_full_array', stimulation_id_val=12)\n",
    "    all_results = template_matching_vs_null(session_id, cablam_filtered_responsive_rois, cablam_template, threshold)\n",
    "    all_results[session_id] = results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Iterate through each session and each ROI in the results\n",
    "for session_id, session_results in all_results.items():\n",
    "    print(f\"Session ID: {session_id}\")  # Print the session ID\n",
    "    for roi_id, data in session_results[session_id].items():\n",
    "        # Print relevant data for each ROI\n",
    "        print(f\"  ROI {roi_id}:\")\n",
    "        #print(f\"    Max Filtered Value = {data['max_filtered_value']}\")\n",
    "        print(f\"    Significant = {data['is_significant']}\")\n",
    "        #print(f\"    Peaks Detected = {len(data['peaks'])} at positions {data['peaks']}\")\n",
    "        #print()  # Add a newline for better readability between ROIs\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def debug_peak_alignment(template_matching_results, session_id, window_radius, num_segments_to_plot=5):\n",
    "    \"\"\"\n",
    "    Plots individual normalized segments of the original signal at detected peaks, \n",
    "    aligned with the template for debugging.\n",
    "\n",
    "    Parameters:\n",
    "    template_matching_results (dict): The dictionary containing the matching results.\n",
    "    session_id (str): The session ID to use in the template_matching_results.\n",
    "    window_radius (int): The number of data points to include on either side of the peak.\n",
    "    num_segments_to_plot (int): The number of individual segments to plot for debugging.\n",
    "    \"\"\"\n",
    "    \n",
    "    #convert the session_id to a string\n",
    "    session_id = str(session_id)\n",
    "    \n",
    "    # Extract the relevant data from the results\n",
    "    session_results = template_matching_results[session_id]\n",
    "    first_roi_id = next(iter(session_results))\n",
    "    template = session_results[first_roi_id]['template']\n",
    "    \n",
    "    # Normalize the template for comparison\n",
    "    template_norm = (template - np.min(template)) / (np.max(template) - np.min(template))\n",
    "\n",
    "    # Set up the plot\n",
    "    plt.figure(figsize=(10, 6))\n",
    "    \n",
    "    # Plot the template\n",
    "    plt.plot(template_norm, label='Template', color='black', linewidth=2, alpha=0.7)\n",
    "    \n",
    "    # Loop through each ROI in the session (we'll just take the first one for debugging)\n",
    "    roi_id = first_roi_id\n",
    "    roi_results = session_results[roi_id]\n",
    "    original_signal = roi_results['original_signal']\n",
    "    peaks = roi_results['peaks']\n",
    "    \n",
    "    # Loop over a few peaks to plot individual segments\n",
    "    for peak_idx, peak in enumerate(peaks[:num_segments_to_plot]):\n",
    "        # Make sure we don't go out of bounds\n",
    "        if peak - window_radius < 0 or peak + window_radius > len(original_signal):\n",
    "            continue\n",
    "        \n",
    "        # Extract and normalize the segment\n",
    "        segment = original_signal[peak - window_radius:peak + window_radius]\n",
    "        segment_norm = (segment - np.min(segment)) / (np.max(segment) - np.min(segment))\n",
    "        \n",
    "        # Overlay the normalized segment on the template\n",
    "        plt.plot(np.arange(-window_radius, window_radius), segment_norm, alpha=0.5, label=f'Segment at Peak {peak_idx+1}')\n",
    "    \n",
    "    plt.title(f'Individual Detected Events vs Template for ROI {roi_id}')\n",
    "    plt.xlabel('Time Relative to Peak')\n",
    "    plt.ylabel('Normalized Signal Amplitude')\n",
    "    plt.legend()\n",
    "    plt.show()\n",
    "    \n",
    "# Usage of the function:\n",
    "# Assuming template_matching_results is your results dictionary and '2112242023' is your session ID\n",
    "debug_peak_alignment(template_matching_results, 2112242023, window_radius=5)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "\n",
    "def plot_peak_matches_from_results(template_matching_results, session_id, window_radius):\n",
    "    \"\"\"\n",
    "    Plots segments of the original signal at detected peaks alongside the template\n",
    "    for a specific session from the template_matching_results dictionary.\n",
    "\n",
    "    Parameters:\n",
    "    template_matching_results (dict): The dictionary containing the matching results.\n",
    "    session_id (str): The session ID to use in the template_matching_results.\n",
    "    window_radius (int): The number of data points to include on either side of the peak.\n",
    "    \"\"\"\n",
    "    # Extract the relevant data from the results\n",
    "    session_results = template_matching_results[session_id]\n",
    "    \n",
    "    # Loop through each ROI in the session\n",
    "    for roi_id, roi_results in session_results.items():\n",
    "        original_signal = roi_results['original_signal']\n",
    "        peaks = roi_results['peaks']\n",
    "        template = roi_results['template']  # Assuming the template is stored in the results\n",
    "\n",
    "        # Set up the plot\n",
    "        plt.figure(figsize=(14, 7))\n",
    "        plt.title(f'ROI {roi_id} Detected Peaks vs Template')\n",
    "        \n",
    "        # Plot the template\n",
    "        plt.plot(template, label='Template', color='black', linewidth=2)\n",
    "\n",
    "        # Overlay segments of the original signal centered around the peaks\n",
    "        for peak in peaks:\n",
    "            # Make sure we don't go out of bounds\n",
    "            if peak - window_radius < 0 or peak + window_radius > len(original_signal):\n",
    "                continue\n",
    "\n",
    "            # Extract the segment\n",
    "            segment = original_signal[peak - window_radius:peak + window_radius]\n",
    "            \n",
    "            # Normalize the segment for better comparison\n",
    "            segment = (segment - np.min(segment)) / (np.max(segment) - np.min(segment))\n",
    "            segment *= np.max(template)  # Scale to match the template amplitude\n",
    "\n",
    "            # Plot the segment\n",
    "            plt.plot(range(peak - window_radius, peak + window_radius), segment, alpha=0.5)\n",
    "        \n",
    "        plt.xlabel('Time')\n",
    "        plt.ylabel('Signal Amplitude')\n",
    "        plt.legend()\n",
    "        plt.show()\n",
    "\n",
    "# Usage of the function:\n",
    "# Assuming template_matching_results is your results dictionary and '2112242023' is your session ID\n",
    "plot_peak_matches_from_results(template_matching_results, '2112242023', window_radius=50)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def plot_responsive_vs_nonresponsive_histogram(dataframe, metric, bins=30, alpha=0.5, title=None):\n",
    "    \"\"\"\n",
    "    Plots overlaid histograms for responsive and non-responsive units based on a specified metric.\n",
    "\n",
    "    Parameters:\n",
    "    dataframe (pd.DataFrame): The DataFrame containing the responsiveness data and the metric to plot.\n",
    "    metric (str): The name of the column in the DataFrame representing the metric to plot.\n",
    "    bins (int): The number of bins for the histograms.\n",
    "    alpha (float): The transparency level for the histogram bars.\n",
    "    title (str): The title for the plot. If None, a default title will be set.\n",
    "\n",
    "    Returns:\n",
    "    None: The function plots the histograms but does not return any value.\n",
    "    \"\"\"\n",
    "    \n",
    "    # Filter responsive and non-responsive units\n",
    "    responsive_units = dataframe[dataframe['is_responsive'] == True]\n",
    "    non_responsive_units = dataframe[dataframe['is_responsive'] == False]\n",
    "    \n",
    "    # Plot histograms\n",
    "    plt.figure(figsize=(10, 6))\n",
    "    \n",
    "    # Histogram for responsive units\n",
    "    plt.hist(responsive_units[metric], bins=bins, alpha=alpha, label='Responsive Trials')\n",
    "\n",
    "    # Histogram for non-responsive units\n",
    "    plt.hist(non_responsive_units[metric], bins=bins, alpha=alpha, label='Non-responsive Trials')\n",
    "    \n",
    "\n",
    "    plt.xlabel(metric)\n",
    "    plt.ylabel('Count')\n",
    "    plt.title(title if title else f'Distribution of {metric} for Responsive vs. Non-responsive Trials')\n",
    "    \n",
    "    #add a text that states the total number of responsive and non-responsive units at the top right corner of the plot and the percentage of responsive units relative to the total number of units\n",
    "    total_units = len(dataframe)\n",
    "    total_responsive = len(responsive_units)\n",
    "    total_non_responsive = len(non_responsive_units)\n",
    "    \n",
    "\n",
    "    #place the text seomwhere else on the plot that is not the top right corner\n",
    "    plt.text(0.5, 0.5, f'Total Trials: {total_units}\\nResponsive: {total_responsive} ({total_responsive / total_units:.1%})',\n",
    "                horizontalalignment='center', verticalalignment='center', transform=plt.gca().transAxes)\n",
    "    \n",
    "    \n",
    "    \n",
    "    plt.legend()\n",
    "    plt.show()\n",
    "    \n",
    "def plot_responsive_vs_nonresponsive_scatter(dataframe, x_metric, y_metric, title=None):\n",
    "    \"\"\"\n",
    "    Plots a scatter plot to compare the relationship between two metrics, differentiating\n",
    "    between responsive and non-responsive units.\n",
    "\n",
    "    Parameters:\n",
    "    dataframe (pd.DataFrame): The DataFrame containing the responsiveness data.\n",
    "    x_metric (str): The name of the column in the DataFrame for the x-axis.\n",
    "    y_metric (str): The name of the column in the DataFrame for the y-axis.\n",
    "    title (str): The title for the plot. If None, a default title will be set.\n",
    "\n",
    "    Returns:\n",
    "    None: The function plots the scatter plot but does not return any value.\n",
    "    \"\"\"\n",
    "    \n",
    "    # Separate responsive and non-responsive units\n",
    "    responsive_units = dataframe[dataframe['is_responsive'] == True]\n",
    "    non_responsive_units = dataframe[dataframe['is_responsive'] == False]\n",
    "    \n",
    "    # Create the scatter plot\n",
    "    plt.figure(figsize=(10, 6))\n",
    "    \n",
    "    # Scatter plot for responsive units\n",
    "    plt.scatter(responsive_units[x_metric], responsive_units[y_metric], \n",
    "                alpha=0.7, label='Responsive Trials', edgecolors='w')\n",
    "    \n",
    "    # Scatter plot for non-responsive units\n",
    "    plt.scatter(non_responsive_units[x_metric], non_responsive_units[y_metric], \n",
    "                alpha=0.7, label='Non-responsive Trials', edgecolors='w')\n",
    "    \n",
    "    plt.xlabel(x_metric)\n",
    "    plt.ylabel(y_metric)\n",
    "    plt.title(title if title else f'Relationship between {x_metric} and {y_metric}')\n",
    "    plt.legend()\n",
    "    plt.grid(True)\n",
    "    plt.show()\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "# Example usage:\n",
    "plot_responsive_vs_nonresponsive_histogram(responsiveness_df_gcamp8, 'post_stim_peak', 30)\n",
    "plot_responsive_vs_nonresponsive_histogram(responsiveness_df_cablam, 'post_stim_peak', 30)\n",
    "plot_responsive_vs_nonresponsive_histogram(responsiveness_df_cablam1x, 'post_stim_peak', 30)\n",
    "\n",
    "plot_responsive_vs_nonresponsive_scatter(responsiveness_df_gcamp8, 'pre_stim_mean', 'post_stim_peak')\n",
    "plot_responsive_vs_nonresponsive_scatter(responsiveness_df_cablam, 'pre_stim_mean', 'post_stim_peak')\n",
    "plot_responsive_vs_nonresponsive_scatter(responsiveness_df_cablam1x, 'pre_stim_mean', 'post_stim_peak')\n",
    "\n",
    "plot_responsive_vs_nonresponsive_scatter(responsiveness_df_gcamp8, 'pre_stim_mean', 'peak_delta_f_f_post_stim')\n",
    "plot_responsive_vs_nonresponsive_scatter(responsiveness_df_cablam, 'pre_stim_mean', 'peak_delta_f_f_post_stim')\n",
    "plot_responsive_vs_nonresponsive_scatter(responsiveness_df_cablam1x, 'pre_stim_mean', 'peak_delta_f_f_post_stim')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def plot_aggregated_responsive_vs_nonresponsive_scatter(dataframe, x_metric, y_metric, stimulus_id, title=None):\n",
    "    \"\"\"\n",
    "    Plots a scatter plot to compare the relationship between two metrics for a specific stimulus ID,\n",
    "    differentiating between responsive and non-responsive units.\n",
    "\n",
    "    Parameters:\n",
    "    dataframe (pd.DataFrame): The DataFrame containing the responsiveness data.\n",
    "    x_metric (str): The name of the column in the DataFrame for the x-axis.\n",
    "    y_metric (str): The name of the column in the DataFrame for the y-axis.\n",
    "    stimulus_id (int): The specific stimulus ID to filter the responsiveness data by.\n",
    "    title (str): The title for the plot. If None, a default title will be set.\n",
    "\n",
    "    Returns:\n",
    "    None: The function plots the scatter plot but does not return any value.\n",
    "    \"\"\"\n",
    "    \n",
    "    # Filter for the specific stimulus ID\n",
    "    specific_stim_data = dataframe[dataframe['stimulation_id'] == stimulus_id]\n",
    "    \n",
    "    # Group by session_id and roi to aggregate data\n",
    "    grouped = specific_stim_data.groupby(['session_id', 'roi'])\n",
    "    \n",
    "    # For each group, determine if the ROI is responsive to the specific stimulus\n",
    "    aggregated_data = grouped.agg({\n",
    "        'is_responsive': 'max',  # max will be True if the ROI is responsive at least once\n",
    "        x_metric: 'mean',  # mean of the pre-stimulus metric\n",
    "        y_metric: 'mean'   # mean of the post-stimulus metric\n",
    "    }).reset_index()\n",
    "    \n",
    "    # Now we have aggregated data with one row per ROI per session\n",
    "    # We separate responsive and non-responsive ROIs\n",
    "    responsive_units = aggregated_data[aggregated_data['is_responsive'] == True]\n",
    "    non_responsive_units = aggregated_data[aggregated_data['is_responsive'] == False]\n",
    "    \n",
    "    # Create the scatter plot\n",
    "    plt.figure(figsize=(10, 6))\n",
    "    \n",
    "    # Scatter plot for responsive units\n",
    "    plt.scatter(responsive_units[x_metric], responsive_units[y_metric],\n",
    "                alpha=0.7, label='Responsive Units', edgecolors='w', color='blue')\n",
    "    \n",
    "    # Scatter plot for non-responsive units\n",
    "    plt.scatter(non_responsive_units[x_metric], non_responsive_units[y_metric],\n",
    "                alpha=0.7, label='Non-responsive Units', edgecolors='w', color='red')\n",
    "    \n",
    "    #add linear trendlines to the scatter plot for responsive and non-responsive units\n",
    "    responsive_units_fit = np.polyfit(responsive_units[x_metric], responsive_units[y_metric], 1)\n",
    "    non_responsive_units_fit = np.polyfit(non_responsive_units[x_metric], non_responsive_units[y_metric], 1)\n",
    "\n",
    "    plt.plot(responsive_units[x_metric], responsive_units_fit[0] * responsive_units[x_metric] + responsive_units_fit[1], color='blue', linestyle='--')\n",
    "    plt.plot(non_responsive_units[x_metric], non_responsive_units_fit[0] * non_responsive_units[x_metric] + non_responsive_units_fit[1], color='red', linestyle='--')\n",
    "\n",
    "    \n",
    "    plt.xlabel('Mean ' + x_metric)\n",
    "    plt.ylabel('Mean ' + y_metric)\n",
    "    plt.title(title if title else f'Relationship between {x_metric} and {y_metric} for Stimulus ID {stimulus_id}')\n",
    "    plt.legend()\n",
    "    plt.grid(True)\n",
    "    plt.show()\n",
    "    \n",
    "    \n",
    "def plot_responsive_vs_nonresponsive_histogram_for_stimulus(dataframe, metric, stimulus_id, bins=30, alpha=0.5, title=None):\n",
    "    \"\"\"\n",
    "    Plots overlaid histograms for responsive and non-responsive units based on a specified metric and stimulus ID.\n",
    "\n",
    "    Parameters:\n",
    "    dataframe (pd.DataFrame): The DataFrame containing the responsiveness data and the metric to plot.\n",
    "    metric (str): The name of the column in the DataFrame representing the metric to plot.\n",
    "    stimulus_id (int): The specific stimulus ID to filter the responsiveness data by.\n",
    "    bins (int): The number of bins for the histograms.\n",
    "    alpha (float): The transparency level for the histogram bars.\n",
    "    title (str): The title for the plot. If None, a default title will be set.\n",
    "\n",
    "    Returns:\n",
    "    None: The function plots the histograms but does not return any value.\n",
    "    \"\"\"\n",
    "    \n",
    "    # Filter the DataFrame for the specific stimulus ID\n",
    "    df_filtered = dataframe[dataframe['stimulation_id'] == stimulus_id]\n",
    "    \n",
    "    # Filter responsive and non-responsive units\n",
    "    responsive_units = df_filtered[df_filtered['is_responsive'] == True]\n",
    "    non_responsive_units = df_filtered[df_filtered['is_responsive'] == False]\n",
    "    \n",
    "    # Plot histograms\n",
    "    plt.figure(figsize=(10, 6))\n",
    "    \n",
    "    # Histogram for responsive units\n",
    "    plt.hist(responsive_units[metric], bins=bins, alpha=alpha, label='Responsive Units')\n",
    "\n",
    "    # Histogram for non-responsive units\n",
    "    plt.hist(non_responsive_units[metric], bins=bins, alpha=alpha, label='Non-responsive Units')\n",
    "\n",
    "    plt.xlabel(metric)\n",
    "    plt.ylabel('Count')\n",
    "    plt.title(title if title else f'Distribution of {metric} for Stimulus ID {stimulus_id}')\n",
    "\n",
    "    # Adding text for total counts and percentages\n",
    "    total_units = len(df_filtered)\n",
    "    total_responsive = len(responsive_units)\n",
    "    total_non_responsive = len(non_responsive_units)\n",
    "    plt.text(0.5, 0.5, f'Total Units: {total_units}\\nResponsive: {total_responsive} ({total_responsive / total_units:.1%})',\n",
    "             horizontalalignment='center', verticalalignment='center', transform=plt.gca().transAxes)\n",
    "\n",
    "    plt.legend()\n",
    "    plt.show()\n",
    "\n",
    "# Example usage:\n",
    "def plot_responsive_vs_nonresponsive_histogram_for_stimulus(dataframe, metric, stimulus_id, bins=30, title=None):\n",
    "    \"\"\"\n",
    "    Plots overlaid histograms with transparent bins and colored outlines for responsive and \n",
    "    non-responsive units based on a specified metric and stimulus ID.\n",
    "\n",
    "    Parameters:\n",
    "    dataframe (pd.DataFrame): The DataFrame containing the responsiveness data and the metric to plot.\n",
    "    metric (str): The name of the column in the DataFrame representing the metric to plot.\n",
    "    stimulus_id (int): The specific stimulus ID to filter the responsiveness data by.\n",
    "    bins (int or sequence): The number of bins for the histograms or the sequence of bin edges.\n",
    "    title (str): The title for the plot. If None, a default title will be set.\n",
    "\n",
    "    Returns:\n",
    "    None: The function plots the histograms but does not return any value.\n",
    "    \"\"\"\n",
    "\n",
    "    # Filter the DataFrame for the specific stimulus ID\n",
    "    df_filtered = dataframe[dataframe['stimulation_id'] == stimulus_id]\n",
    "    \n",
    "    # Determine the range for the histograms\n",
    "    data_min = df_filtered[metric].min()\n",
    "    data_max = df_filtered[metric].max()\n",
    "    bin_edges = np.linspace(data_min, data_max, bins + 1)  # +1 because bin edges are one more than bin count\n",
    "    \n",
    "    # Filter responsive and non-responsive units\n",
    "    responsive_units = df_filtered[df_filtered['is_responsive'] == True]\n",
    "    non_responsive_units = df_filtered[df_filtered['is_responsive'] == False]\n",
    "    \n",
    "    # Plot histograms with transparent bins and colored outlines\n",
    "    plt.figure(figsize=(10, 6))\n",
    "    \n",
    "    # Histogram for responsive units\n",
    "    plt.hist(responsive_units[metric], bins=bin_edges, edgecolor='blue', linewidth=1.5, facecolor='none', label='Responsive Units')\n",
    "    \n",
    "    # Histogram for non-responsive units\n",
    "    plt.hist(non_responsive_units[metric], bins=bin_edges, edgecolor='orange', linewidth=1.5, facecolor='none', label='Non-responsive Units')\n",
    "    \n",
    "    plt.xlabel(metric)\n",
    "    plt.ylabel('Count')\n",
    "    plt.title(title if title else f'Distribution of {metric} for Stimulus ID {stimulus_id}')\n",
    "\n",
    "    # Adding text for total counts and percentages\n",
    "    total_units = len(df_filtered)\n",
    "    total_responsive = len(responsive_units)\n",
    "    total_non_responsive = len(non_responsive_units)\n",
    "    plt.text(0.7, 0.85, f'Total Units: {total_units}\\nResponsive: {total_responsive}\\nNon-responsive: {total_non_responsive}\\nPercentage Responsive: {total_responsive / total_units:.2%}',\n",
    "             horizontalalignment='center', verticalalignment='center', transform=plt.gca().transAxes, fontsize=9)\n",
    "\n",
    "    plt.legend(loc='upper right')\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "def plot_histogram_with_complete_outline(dataframe, metric, stimulus_id, bins=30, responsive_color='blue', non_responsive_color='orange', title=None):\n",
    "    \"\"\"\n",
    "    Plots histograms with a complete outline around each group for responsive and non-responsive units.\n",
    "    \n",
    "    Parameters:\n",
    "    dataframe (pd.DataFrame): The DataFrame containing the responsiveness data.\n",
    "    metric (str): The column name of the metric to be plotted.\n",
    "    stimulus_id (int): The specific stimulus ID to filter the responsiveness data by.\n",
    "    bins (int): The number of bins for the histograms.\n",
    "    responsive_color (str): Color for the outline of the responsive units histogram.\n",
    "    non_responsive_color (str): Color for the outline of the non-responsive units histogram.\n",
    "    title (str): The title for the plot.\n",
    "\n",
    "    Returns:\n",
    "    None: The function plots the histograms with outlined edges.\n",
    "    \"\"\"\n",
    "    \n",
    "    # Filter the DataFrame for the specific stimulus ID\n",
    "    df_filtered = dataframe[dataframe['stimulation_id'] == stimulus_id]\n",
    "\n",
    "    # Separate responsive and non-responsive units\n",
    "    responsive = df_filtered[df_filtered['is_responsive']]\n",
    "    non_responsive = df_filtered[~df_filtered['is_responsive']]\n",
    "\n",
    "    # Determine the bin edges for consistent bin widths\n",
    "    all_data = df_filtered[metric]\n",
    "    data_range = (all_data.min(), all_data.max())\n",
    "    bin_edges = np.linspace(data_range[0], data_range[1], bins+1)\n",
    "\n",
    "    # Create histograms for the counts\n",
    "    responsive_counts, res_edges = np.histogram(responsive[metric], bins=bin_edges)\n",
    "    non_responsive_counts, non_res_edges = np.histogram(non_responsive[metric], bins=bin_edges)\n",
    "\n",
    "    # Plot histograms\n",
    "    plt.figure(figsize=(10, 6))\n",
    "    plt.hist(responsive[metric], bins=bin_edges, color=responsive_color, alpha=0.5, label='Responsive Units')\n",
    "    plt.hist(non_responsive[metric], bins=bin_edges, color=non_responsive_color, alpha=0.5, label='Non-responsive Units')\n",
    "\n",
    "    # Draw the complete outline for responsive units histogram\n",
    "    plt.step(np.concatenate(([res_edges[0]], res_edges)), np.concatenate(([0], responsive_counts, [0])), where='post', color=responsive_color, linewidth=2)\n",
    "\n",
    "    # Draw the complete outline for non-responsive units histogram\n",
    "    plt.step(np.concatenate(([non_res_edges[0]], non_res_edges)), np.concatenate(([0], non_responsive_counts, [0])), where='post', color=non_responsive_color, linewidth=2)\n",
    "\n",
    "    # Set labels and title\n",
    "    plt.xlabel(metric)\n",
    "    plt.ylabel('Count')\n",
    "    if title is not None:\n",
    "        plt.title(title)\n",
    "    else:\n",
    "        plt.title(f'Distribution of {metric} for Stimulus ID {stimulus_id}')\n",
    "\n",
    "    # Display the legend\n",
    "    plt.legend(loc='upper right')\n",
    "\n",
    "    plt.show()\n",
    "\n",
    "# Example usage:\n",
    "#plot_aggregated_responsive_vs_nonresponsive_scatter(responsiveness_df_cablam, 'pre_stim_median', 'peak_delta_f_f_post_stim', 36)\n",
    "#plot_aggregated_responsive_vs_nonresponsive_scatter(responsiveness_df_gcamp8, 'pre_stim_median', 'peak_delta_f_f_post_stim', 36)\n",
    "#plot_aggregated_responsive_vs_nonresponsive_scatter(responsiveness_df_cablam1x, 'pre_stim_median', 'peak_delta_f_f_post_stim', 36)\n",
    "\n",
    "plot_responsive_vs_nonresponsive_histogram_for_stimulus(responsiveness_df_cablam, 'peak_delta_f_f_post_stim', 36, bins=20)\n",
    "plot_responsive_vs_nonresponsive_histogram_for_stimulus(responsiveness_df_gcamp8, 'peak_delta_f_f_post_stim', 36, bins=20)\n",
    "plot_responsive_vs_nonresponsive_histogram_for_stimulus(responsiveness_df_cablam1x, 'peak_delta_f_f_post_stim', 36, bins=20)\n",
    "\n",
    "\n",
    "plot_histogram_with_complete_outline(responsiveness_df_gcamp8, 'peak_delta_f_f_post_stim', 24, bins=15)\n",
    "plot_histogram_with_complete_outline(responsiveness_df_cablam, 'peak_delta_f_f_post_stim', 24, bins=15)\n",
    "plot_histogram_with_complete_outline(responsiveness_df_cablam1x, 'peak_delta_f_f_post_stim', 24, bins=1)   \n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "\n",
    "def get_sample_size_summary(df, stim_ids, label, count_responsive=False):\n",
    "    \"\"\"\n",
    "    Summarizes sample sizes (n) for each stimulation ID in the given DataFrame.\n",
    "\n",
    "    Parameters:\n",
    "    df (pd.DataFrame): The input DataFrame with 'session_id', 'roi', 'stimulation_id', and 'is_responsive'.\n",
    "    stim_ids (list of int): List of stimulation IDs to include.\n",
    "    label (str): Name of the group (e.g., 'CaBLAM', 'GCaMP8s').\n",
    "    count_responsive (bool): If True, also reports how many neurons were responsive.\n",
    "\n",
    "    Returns:\n",
    "    pd.DataFrame: Summary table with columns: ['Sensor', 'Stim', 'n_total', 'n_responsive', 'percent_responsive']\n",
    "    \"\"\"\n",
    "    results = []\n",
    "\n",
    "    for stim_id in stim_ids:\n",
    "        df_stim = df[df['stimulation_id'] == stim_id]\n",
    "\n",
    "        # Group by unique neuron per session\n",
    "        grouped = df_stim.groupby(['session_id', 'roi'])\n",
    "\n",
    "        # Aggregate responsiveness\n",
    "        aggregated = grouped.agg({\n",
    "            'is_responsive': 'max'  # True if responsive at least once\n",
    "        }).reset_index()\n",
    "\n",
    "        n_total = len(aggregated)\n",
    "        if count_responsive:\n",
    "            n_resp = aggregated['is_responsive'].sum()\n",
    "            percent_resp = (n_resp / n_total) * 100 if n_total > 0 else 0\n",
    "            results.append({\n",
    "                'Sensor': label,\n",
    "                'Stim': stim_id,\n",
    "                'n_total': n_total,\n",
    "                'n_responsive': int(n_resp),\n",
    "                'percent_responsive': round(percent_resp, 1)\n",
    "            })\n",
    "        else:\n",
    "            results.append({\n",
    "                'Sensor': label,\n",
    "                'Stim': stim_id,\n",
    "                'n_total': n_total\n",
    "            })\n",
    "\n",
    "    return pd.DataFrame(results)\n",
    "\n",
    "stim_ids = [12, 120]\n",
    "summary_cablam = get_sample_size_summary(responsiveness_df_cablam, stim_ids, label='CaBLAM')\n",
    "summary_cablam1x = get_sample_size_summary(responsiveness_df_cablam1x, stim_ids, label='CaBLAM1x')\n",
    "summary_gcamp8s = get_sample_size_summary(responsiveness_df_gcamp8, stim_ids, label='GCaMP8s')\n",
    "\n",
    "# Combine all\n",
    "summary_all = pd.concat([summary_cablam, summary_cablam1x, summary_gcamp8s], ignore_index=True)\n",
    "\n",
    "# View\n",
    "print(summary_all)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The below is to properly process and correct the dark signal/camera noise "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def process_biolumi_calcium_signal(session_id, directory_df):\n",
    "    processed_dir = 'processed_data/processed_image_analysis_output'\n",
    "    calcium_csv_suffix = '_calcium_signals.csv'\n",
    "    directory_df['session_id'] = directory_df['session_id'].astype(int)\n",
    "    directory_entry = directory_df[directory_df['session_id'] == session_id]\n",
    "\n",
    "    # Check if the directory_entry is empty\n",
    "    if directory_entry.empty:\n",
    "        print(f\"No directory entry found for session {session_id}. Please check the session_id.\")\n",
    "        return None\n",
    "    \n",
    "    directory_path = directory_entry['directory_path'].values[0]\n",
    "    csv_path = os.path.join(directory_path, processed_dir, str(session_id) + calcium_csv_suffix)\n",
    "\n",
    "    \n",
    "    if not os.path.exists(csv_path):\n",
    "        print(f\"Calcium signals file not found for session {session_id}\")\n",
    "        return None\n",
    "\n",
    "    calcium_signals_df = pd.read_csv(csv_path) # import the calcium signals csv file\n",
    "    \n",
    "    # Correct the \"Dark signal\" for each ROI\n",
    "    for roi in calcium_signals_df.columns:\n",
    "        if 'ROI' in roi:  # Assuming ROI columns are prefixed with 'ROI'\n",
    "            dark_signal_median = calcium_signals_df[roi][:300].median() # Calculate the median of the first 100 frames\n",
    "            calcium_signals_df[roi] = calcium_signals_df[roi] - dark_signal_median\n",
    "            calcium_signals_df.loc[calcium_signals_df[roi] < 0, roi] = np.nan\n",
    "    \n",
    "    \n",
    "    #save the corrected calcium signals to a new csv file in the same directory\n",
    "    corrected_csv_path = os.path.join(directory_path, processed_dir, str(session_id) + '_corrected' + calcium_csv_suffix)\n",
    "    calcium_signals_df.to_csv(corrected_csv_path, index=False)\n",
    "    \n",
    "            \n",
    "    return calcium_signals_df\n",
    "\n",
    "# New function to process all session IDs\n",
    "def process_all_sessions(directory_df):\n",
    "    unique_sessions = directory_df['session_id'].unique()\n",
    "    for session_id in unique_sessions:\n",
    "        print(f\"Processing session ID: {session_id}\")\n",
    "        process_biolumi_calcium_signal(session_id, directory_df)\n",
    "        print(f\"Completed processing for session ID: {session_id}\")\n",
    "\n",
    "\n",
    "# Example usage:\n",
    "session_id = 2212242023\n",
    "biolumi_calcium_signals_df = process_biolumi_calcium_signal(session_id, analysis.directory_df)\n",
    "process_all_sessions(analysis.directory_df)\n",
    "                \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "biolumi_calcium_signals_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def process_all_sessions(self):\n",
    "    all_data = {}\n",
    "    # Iterate over all unique session IDs\n",
    "    for session_id in self.directory_df['session_id'].unique():\n",
    "        # Adjusted to unpack three values here\n",
    "        stim_frame_numbers, roi_data, stimulation_ids = self.create_trial_locked_calcium_signals(session_id)\n",
    "        all_data[session_id] = {\n",
    "            'stim_frame_numbers': stim_frame_numbers,\n",
    "            'roi_data': roi_data,\n",
    "            'stimulation_ids': stimulation_ids  # You can decide whether you need to store this or not\n",
    "        }\n",
    "    return all_data\n",
    "\n",
    "def create_trial_locked_calcium_signals(self, session_id):\n",
    "    \"\"\"\n",
    "        dictionary with session IDs as keys. Each session contains its own dictionary with keys for stim_frame_numbers, roi_data, and stimulation_ids. \n",
    "    Within roi_data, the data is keyed by tuples, where each tuple consists of a stimulation_id and a stim_frame_number, \n",
    "    and associated with these tuples are NumPy arrays of the recorded signals.\n",
    "    \n",
    "    Outline of dictionary structure:\n",
    "    Level 1: The top-level dictionary contains Session IDs as keys.\n",
    "    Example: '2312072023', '1112072023'\n",
    "    \n",
    "    Level 2: Each Session ID key maps to a dictionary that contains three keys:\n",
    "    'stim_frame_numbers': List of frame numbers where stimuli were applied.\n",
    "    'roi_data': Nested dictionary with ROI signal data.\n",
    "    'stimulation_ids': List of identifiers for each stimulus type.\n",
    "    \n",
    "    Level 3: The 'roi_data' dictionary has:\n",
    "    Keys: Names of the ROIs (e.g., 'ROI_1').\n",
    "    Values: Another dictionary for each ROI, which I'll describe in the next level.\n",
    "    \n",
    "    Level 4 (within 'roi_data'): Here's where the tuple comes into play.\n",
    "    Keys: Tuples containing (stimulation_id, stim_frame_number).\n",
    "    stimulation_id: A unique identifier for the type of stimulation.\n",
    "    stim_frame_number: The frame number when this stimulation occurred.\n",
    "    Values: NumPy arrays with the calcium signal data corresponding to each ROI following a stimulus event.\n",
    "    \n",
    "    all_data : dict\n",
    "    A dictionary containing processed calcium signal data for multiple sessions.\n",
    "\n",
    "    Each key in `all_data` represents a unique session ID corresponding to an individual experimental session.\n",
    "\n",
    "    Keys\n",
    "    ----\n",
    "    session_id : str\n",
    "        A unique identifier for the experimental session. The `session_id` is likely a string that represents the date and additional identifying information of the session.\n",
    "\n",
    "    Values\n",
    "    ------\n",
    "    A dictionary containing the following keys:\n",
    "\n",
    "    stim_frame_numbers : list of int\n",
    "        A list of integers representing the frame numbers at which stimuli were applied.\n",
    "\n",
    "    roi_data : dict of dict\n",
    "        A nested dictionary where each top-level key is an ROI label (e.g., 'ROI_1') and the value is another dictionary mapping a tuple of `(stimulation_id, stim_frame_number)` to a NumPy array of signal data.\n",
    "\n",
    "        Keys\n",
    "        ----\n",
    "        (stimulation_id, stim_frame_number) : tuple\n",
    "            `stimulation_id` : int\n",
    "                An integer representing a unique identifier for a type of stimulus applied during the experimental session.\n",
    "\n",
    "            `stim_frame_number` : int\n",
    "                An integer indicating the frame number at which the stimulus was applied.\n",
    "\n",
    "        Values\n",
    "        ------\n",
    "        signal_data : numpy.ndarray\n",
    "            An array containing the calcium signal values recorded for the ROI after the corresponding stimulus event.\n",
    "\n",
    "    stimulation_ids : list of int\n",
    "        A list of unique identifiers for each type of stimulation used in the session.\n",
    "\n",
    "    Example\n",
    "    -------\n",
    "    >>> all_data['2312072023']['stim_frame_numbers']\n",
    "    [3582, 3784, 3986, 4187, 4389, 4590, 4792, 4994, 5195, 5397]\n",
    "    >>> all_data['2312072023']['roi_data']['ROI_1'][(60, 3582)]\n",
    "    array([...signal values...])\n",
    "    >>> all_data['2312072023']['stimulation_ids']\n",
    "    [12, 24, 36, 60, 120, 480]\n",
    "    \"\"\"\n",
    "    \n",
    "    \n",
    "    processed_dir = 'processed_data/processed_image_analysis_output'\n",
    "    calcium_csv_suffix = '_calcium_signals.csv'\n",
    "\n",
    "    directory_entry = self.directory_df[self.directory_df['session_id'] == session_id] #pull out the entry for the given session_id from the directory dataframe\n",
    "    \n",
    "    #pull out the list of stimulation frame numbers for the given session_id under the stimulation_frame_number column\n",
    "    stim_frame_numbers = directory_entry['stimulation_frame_number'].values[0]\n",
    "    \n",
    "    #pull out the stimulation label for the given session_id under the stimulation_label column\n",
    "    stimulation_ids = directory_entry['stimulation_ids'].values[0]\n",
    "    \n",
    "    if directory_entry.empty:\n",
    "        print(f\"No directory entry found for session {session_id}\")\n",
    "        return\n",
    "\n",
    "    directory_path = directory_entry['directory_path'].values[0]\n",
    "    csv_path = os.path.join(directory_path, processed_dir, session_id + calcium_csv_suffix)\n",
    "\n",
    "    if not os.path.exists(csv_path):\n",
    "        print(f\"Calcium signals file not found for session {session_id}\")\n",
    "        return\n",
    "\n",
    "    calcium_signals_df = pd.read_csv(csv_path) #import the calcium signals csv file \n",
    "    #convert the values in the calcium_signals dataframe to integers with no decimal points\n",
    "    calcium_signals_df = calcium_signals_df.astype(int)\n",
    "    \n",
    "    # Parameters for alignment\n",
    "    pre_stim_frames = 10  # Number of frames before stimulation to include\n",
    "    post_stim_frames = 100  # Number of frames after stimulation to include\n",
    "    \n",
    "    # Create a nested dictionary where each key-value pair corresponds to a different ROI. \n",
    "    # For each ROI, you have another dictionary where the key is a tuple of (stimulation_id, stim_frame_number), \n",
    "    # and the value is a NumPy array containing the calcium signal values for a window around the stimulation frame.\n",
    "\n",
    "    # Initialize a nested dictionary to hold ROI, stimulation ID and frame number, and data\n",
    "    roi_data = {roi: {} for roi in calcium_signals_df.columns if 'ROI' in roi}\n",
    "\n",
    "    # Loop through each stimulation frame number and their corresponding stimulation IDs\n",
    "    for stim_id, stim_frame in zip(stimulation_ids, stim_frame_numbers):\n",
    "        # Calculate the index range for frames to extract\n",
    "        start_idx = max(stim_frame - pre_stim_frames, 0)  # Ensure index is not negative\n",
    "        end_idx = min(stim_frame + post_stim_frames, len(calcium_signals_df))  # Ensure index is within range\n",
    "\n",
    "        # Loop through each ROI column\n",
    "        for roi in roi_data:\n",
    "            # Extract the relevant section of the calcium signals for the ROI\n",
    "            trial = calcium_signals_df.loc[start_idx:end_idx, roi]\n",
    "\n",
    "            # Store the trial data as a NumPy array in the nested dictionary\n",
    "            # Using a tuple of (stimulation_id, stim_frame_number) as the key\n",
    "            roi_data[roi][(stim_id, stim_frame)] = trial.to_numpy().astype(int)\n",
    "    \n",
    "    return  stim_frame_numbers, roi_data, stimulation_ids\n",
    "\n",
    "# Example usage:\n",
    "session_id = 2212242023\n",
    "stim_frame_numbers, roi_data, stimulation_ids = create_trial_locked_calcium_signals(analysis, session_id)\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "BELOW HERE IS OLDER FUCNTIONS --must sort through"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def plot_mean_response(roi_data, stim_id=12):\n",
    "    selected_data = {}\n",
    "    for roi, stim_data in roi_data.items():\n",
    "        for stim_key, data in stim_data.items():\n",
    "            if stim_key[0] == stim_id:\n",
    "                if roi not in selected_data:\n",
    "                    selected_data[roi] = []\n",
    "                selected_data[roi].append(data)\n",
    "\n",
    "    for roi in selected_data.keys():\n",
    "        selected_data[roi] = np.stack(selected_data[roi], axis=0)\n",
    "\n",
    "    all_roi_data = np.stack(list(selected_data.values()), axis=0)\n",
    "    mean_response = np.mean(all_roi_data, axis=0)\n",
    "    sem_response = np.std(all_roi_data, axis=0, ddof=1) / np.sqrt(all_roi_data.shape[0])\n",
    "\n",
    "    # Flatten the mean_response if it's 2D\n",
    "    if mean_response.ndim == 2 and mean_response.shape[0] == 1:\n",
    "        mean_response = mean_response.flatten()\n",
    "    if sem_response.ndim == 2 and sem_response.shape[0] == 1:\n",
    "        sem_response = sem_response.flatten()\n",
    "\n",
    "    time_points = np.arange(-10, 51)\n",
    "\n",
    "    plt.figure(figsize=(10, 5))\n",
    "    plt.plot(time_points, mean_response, label='Mean Response')\n",
    "    plt.fill_between(time_points, mean_response - sem_response, mean_response + sem_response, alpha=0.3, label='SEM')\n",
    "    \n",
    "    #add red dotted lines at time point 0 \n",
    "    plt.axvline(x=-1, color='red', linestyle='--', linewidth=1)   \n",
    "    \n",
    "    plt.xlabel('Frame Number (relative to stimulus)')\n",
    "    plt.ylabel('Calcium Signal')\n",
    "    plt.title(f'Mean Calcium Response for stim_id {stim_id}')\n",
    "    plt.legend()\n",
    "    plt.show()\n",
    "\n",
    "    return mean_response, sem_response\n",
    "\n",
    "for stimulation_id in stimulation_ids:\n",
    "    plot_mean_response(roi_data, stim_id=stimulation_id)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#plot the calcium signals for all sessions in the directory_df, do not need to re-run if all analysis has been done already \n",
    "#results = analysis.plot_all_sessions_calcium_signals()\n",
    "results = analysis.plot_all_sessions_calcium_signals(use_corrected_data=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from scipy.signal import fftconvolve\n",
    "\n",
    "# Parameters\n",
    "signal_length = 1000  # Length of the synthetic calcium signal\n",
    "template_length = 50  # Length of the template\n",
    "noise_level = 0.5  # Level of Gaussian noise to add to the signal\n",
    "\n",
    "# Create synthetic calcium signal with noise\n",
    "np.random.seed(0)\n",
    "calcium_signal = np.zeros(signal_length)\n",
    "calcium_signal[100:150] = 1  # Simulate a 1AP signal\n",
    "calcium_signal += noise_level * np.random.randn(signal_length)  # Add noise\n",
    "\n",
    "# Create template from a segment of the calcium signal\n",
    "template = calcium_signal[100:150]\n",
    "\n",
    "# Normalize the template\n",
    "template_norm = template / np.linalg.norm(template)\n",
    "\n",
    "# Apply matched filtering\n",
    "filtered_signal = fftconvolve(calcium_signal, template_norm[::-1], mode='same')\n",
    "\n",
    "# Detect peaks (threshold at 1.5 times the standard deviation of the filtered signal)\n",
    "threshold = 1.5 * np.std(filtered_signal)\n",
    "peaks = np.where(filtered_signal > threshold)[0]\n",
    "\n",
    "# Plotting\n",
    "plt.figure(figsize=(12, 6))\n",
    "plt.subplot(3, 1, 1)\n",
    "plt.plot(calcium_signal, label='Calcium Signal')\n",
    "plt.legend()\n",
    "\n",
    "plt.subplot(3, 1, 2)\n",
    "plt.plot(template, label='Template')\n",
    "plt.legend()\n",
    "\n",
    "plt.subplot(3, 1, 3)\n",
    "plt.plot(filtered_signal, label='Filtered Signal')\n",
    "plt.plot(peaks, filtered_signal[peaks], 'ro', label='Detected Peaks')\n",
    "plt.axhline(y=threshold, color='r', linestyle='--', label='Threshold')\n",
    "plt.legend()\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Generate a ground truth (for demonstration purposes, assume 1AP occurs at index 100)\n",
    "ground_truth_peaks = [100]\n",
    "\n",
    "# Calculate True Positives, False Positives, and False Negatives\n",
    "TP = len(set(ground_truth_peaks) & set(peaks))\n",
    "FP = len(set(peaks) - set(ground_truth_peaks))\n",
    "FN = len(set(ground_truth_peaks) - set(peaks))\n",
    "\n",
    "# Calculate True Negatives (assuming all other points are TN)\n",
    "# Total number of points - (TP + FP + FN)\n",
    "TN = len(calcium_signal) - (TP + FP + FN)\n",
    "\n",
    "# Calculate False Positive Rate (FPR) and True Positive Rate (TPR)\n",
    "FPR = FP / (FP + TN)\n",
    "TPR = TP / (TP + FN)\n",
    "\n",
    "print(f\"False Positive Rate (FPR): {FPR}\")\n",
    "print(f\"True Positive Rate (TPR): {TPR}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "analysis.plot_calcium_signals(session_id)  # Replace with your actual session ID"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "analysis.save_individual_roi_plots(session_id)  # Replace with your actual session ID"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#plot the individual roi signals for all sessions in the directory_df \n",
    "#analysis.save_individual_roi_plots_all_sessions()\n",
    "analysis.save_individual_roi_plots_all_sessions(use_corrected_data=False)\n",
    "#analysis.save_individual_roi_plots_all_sessions(use_corrected_data=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "analysis.plot_roi_with_zoomed_stimulations(session_id)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# plot the calcium signals for a specified session in the directory_df with the full and zoomed in traces around the stimulations\n",
    "analysis.plot_and_save_roi_stimulations(session_id)  # Replace with your actual session ID"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# plot the calcium signals for all sessions in the directory_df with the full and zoomed in traces around the stimulations\n",
    "analysis.plot_and_save_roi_stimulations_all_sessions()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "analysis.find_responsive_rois_first_stim_mean(session_id, pre_stim_duration=3, post_stim_duration=3, threshold=2)  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "analysis.plot_responsive_rois_around_stim(session_id, pre_stim_duration=3, post_stim_duration=3, threshold=2)  # Replace with your actual session ID"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "analysis.plot_mean_and_sem_of_responsive_rois(session_id, pre_stim_duration=3, post_stim_duration=3, threshold=2)  # Replace with your actual session ID"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "analysis.plot_normalized_mean_and_sem_of_responsive_rois(session_id, pre_stim_duration=3, post_stim_duration=3, threshold=2)  # Replace with your actual session ID"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "analysis.plot_normalized_mean_and_sem_of_all_stims(session_id, pre_stim_duration=3, post_stim_duration=3, threshold=2)  # Replace with your actual session ID"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "analysis.plot_mean_responses_from_file(session_id)  # Replace with your actual session ID"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "analysis.plot_overlaid_normalized_responses(session_id, pre_stim_duration=3, post_stim_duration=3, threshold=2)  # Replace with your actual session ID"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Since the folders are directly inside the project_folder, you don't need to append any subdirectory name\n",
    "data_files = analysis.list_files('') \n",
    "print(data_files) #print the list of files in the project folder \n",
    "\n",
    "directories = analysis.list_directories()\n",
    "print(directories) #print the list of directories in the project folder"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Assuming analysis is an instance of ImageAnalysis\n",
    "first_row = analysis.directory_df.iloc[3]\n",
    "directory_path = first_row['directory_path']\n",
    "\n",
    "# Automatically generate file paths based on the directory path\n",
    "dark_frames_path = os.path.join(directory_path, \"dark_frames.tiff\")\n",
    "raw_image_path = os.path.join(directory_path, \"raw_image.tiff\")\n",
    "\n",
    "print(\"dark_frames_path:\", dark_frames_path)\n",
    "print(\"raw_image_path:\", raw_image_path)\n",
    "\n",
    "tiff_path = '/Volumes/MannySSD/cablam_imaging/raw_data_for_analysis/c11_12232023_estim_10hz_1xfz/c11_12232023_estim_10hz_1xfz_biolumi_combined.tif'\n",
    "\n",
    "# Generate the dark image\n",
    "dark_image = analysis.generate_dark_image(tiff_path) #generates a dark image from the first 200 frames of the tiff file "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "# Display the dark image\n",
    "plt.imshow(dark_image, cmap='gray')\n",
    "plt.axis('off')\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Plot the calcium signals\n",
    "plt.figure(figsize=(10, 6))\n",
    "for roi in range(num_rois):\n",
    "    plt.plot(calcium_signals[roi], label=f'ROI {roi + 1}')\n",
    "\n",
    "plt.xlabel('Time (frames)')\n",
    "plt.ylabel('Mean Intensity')\n",
    "plt.title('Calcium Signals Over Time')\n",
    "plt.legend()\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# Assuming 'tiff_path' contains the path to your time series TIFF file\n",
    "# and 'labeled_image' is your ROI mask loaded as a numpy array\n",
    "time_series = io.imread(tiff_path)  # This should be a 3D numpy array (time, y, x)\n",
    "num_rois = np.max(labeled_image)\n",
    "num_frames = time_series.shape[0]\n",
    "\n",
    "# Initialize an array to hold the calcium signal data\n",
    "calcium_signals = np.zeros((num_rois, num_frames))\n",
    "\n",
    "# Process each frame to extract ROI signals\n",
    "for t in range(num_frames):\n",
    "    frame = time_series[t]\n",
    "    for roi in range(1, num_rois + 1):  # ROIs are labeled from 1 to num_rois\n",
    "        roi_mask = labeled_image == roi\n",
    "        roi_data = frame[roi_mask]\n",
    "        calcium_signals[roi - 1, t] = np.mean(roi_data) if roi_data.size > 0 else 0\n",
    "\n",
    "# Plotting the calcium signals\n",
    "offset = 10  # Change this value to adjust the vertical spacing between ROIs\n",
    "plt.figure(figsize=(15, 8))\n",
    "for roi in range(num_rois):\n",
    "    plt.plot(calcium_signals[roi] + offset * roi, label=f'ROI {roi + 1}')  # Offset each ROI signal\n",
    "\n",
    "plt.xlabel('Time')\n",
    "plt.ylabel('ROI')\n",
    "plt.title('Timeseries of ROIs')\n",
    "#plt.yticks(ticks=np.arange(num_rois) * offset, labels=np.arange(1, num_rois + 1))  # Set y-ticks to show ROI IDs\n",
    "plt.grid(True)\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load the time series TIFF file from the given path\n",
    "time_series = io.imread(tiff_path)  # 3D numpy array: (time, y, x)\n",
    "num_rois = np.max(labeled_image)    # Assuming labeled_image is already defined as shown before\n",
    "num_frames = time_series.shape[0]\n",
    "\n",
    "# Initialize an array to hold the calcium signal data for each ROI over time\n",
    "calcium_signals = np.zeros((num_rois, num_frames))\n",
    "\n",
    "# Process each frame to extract ROI signals\n",
    "for t in range(num_frames):\n",
    "    frame = time_series[t]\n",
    "    for roi in range(1, num_rois + 1):  # ROI labels start from 1\n",
    "        roi_mask = labeled_image == roi\n",
    "        roi_data = frame[roi_mask]\n",
    "        calcium_signals[roi - 1, t] = np.mean(roi_data) if np.any(roi_mask) else np.nan\n",
    "\n",
    "# Plotting the calcium signals\n",
    "plt.figure(figsize=(20, 10))  # Adjust the figure size as necessary\n",
    "\n",
    "# Define vertical offset between lines to ensure clear separation\n",
    "vertical_offset = 10  # Change as needed to match the plot scale and ROI separation\n",
    "\n",
    "# Iterate over the ROIs to plot each one with an offset\n",
    "for roi_idx in range(num_rois):\n",
    "    plt.plot(calcium_signals[roi_idx] + (vertical_offset * roi_idx), label=f'ROI {roi_idx + 1}')\n",
    "\n",
    "# Set the y-ticks to correspond to the ROIs\n",
    "# Here, we create a list of y-tick positions based on the number of ROIs and the vertical offset\n",
    "plt.yticks(ticks=np.arange(num_rois) * vertical_offset, labels=np.arange(1, num_rois + 1))\n",
    "\n",
    "plt.xlabel('Time (frames)')\n",
    "plt.ylabel('ROI')\n",
    "plt.title('Timeseries of ROIs')\n",
    "plt.grid(True)  # Include grid for better readability\n",
    "\n",
    "# Optional: Adjust the limits of the y-axis if needed to fit your data range\n",
    "plt.ylim(-5, (num_rois - 1) * vertical_offset + 15)\n",
    "\n",
    "# Optional: If you want to show a legend mapping colors to ROI IDs\n",
    "# plt.legend(loc='upper right')\n",
    "\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load and display the first few rows of the CSV file to understand its structure\n",
    "file_path = '/mnt/data/c11_12232023_estim_10hz_1xfz_biolumi_combined_calcium_signals.csv'\n",
    "calcium_data = pd.read_csv(file_path)\n",
    "\n",
    "calcium_data.head()\n",
    "\n",
    "\n",
    "# Load and display the first few rows of the second CSV file to understand its structure\n",
    "stimulation_file_path = '/mnt/data/c11_12232023_estim_10hz_1xfz_biolumi.csv'\n",
    "stimulation_data = pd.read_csv(stimulation_file_path)\n",
    "\n",
    "stimulation_data.head()\n",
    "\n",
    "# Re-load the data assuming there is no header and display it again to understand its structure\n",
    "stimulation_data_no_header = pd.read_csv(stimulation_file_path, header=None)\n",
    "stimulation_data_no_header.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import math\n",
    "\n",
    "# made modifications to the function to plot the calcium signals for each ROI with a white background and no grid lines and ensure \n",
    "\n",
    "def plot_roi_signals_no_grid(calcium_data, stimulation_frames, num_rois=46):\n",
    "    # Determine the number of rows needed for the subplots (n)\n",
    "    num_rows = math.ceil(num_rois / 5)\n",
    "\n",
    "    # Extract the frame numbers for stimulations\n",
    "    stimulation_points = stimulation_data_no_header.values.flatten()\n",
    "\n",
    "    # Create the subplot grid and plot data with a white background and no grid lines\n",
    "    fig, axs = plt.subplots(num_rows, 5, figsize=(25, 5 * num_rows), facecolor='white')\n",
    "    for i in range(num_rois):\n",
    "        row = i // 5\n",
    "        col = i % 5\n",
    "        # Generate a random color for each ROI\n",
    "        random_color = np.random.rand(3,)\n",
    "        axs[row, col].plot(calcium_data['Frame'], calcium_data[f'ROI_{i+1}'], label=f'ROI_{i+1}', color=random_color)\n",
    "        # Add stimulation markers\n",
    "        for stim_point in stimulation_points:\n",
    "            axs[row, col].axvline(x=stim_point, color='red', linestyle='dotted')\n",
    "        axs[row, col].set_title(f'ROI_{i+1}')\n",
    "        axs[row, col].set_xlabel('Frame')\n",
    "        axs[row, col].set_ylabel('Calcium Signal')\n",
    "        axs[row, col].set_facecolor('white')\n",
    "        axs[row, col].grid(False)  # Disable grid lines\n",
    "\n",
    "    # Adjust the layout and display the plot\n",
    "    plt.tight_layout()\n",
    "    plt.show()\n",
    "\n",
    "# Call the function to display the plot without grid lines\n",
    "plot_roi_signals_no_grid(calcium_data, stimulation_data_no_header)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def plot_all_rois_aligned(calcium_data, stimulation_frames, num_rois=46):\n",
    "    # Extract the frame numbers for stimulations\n",
    "    stimulation_points = stimulation_data_no_header.values.flatten()\n",
    "\n",
    "    # Initialize the figure\n",
    "    plt.figure(figsize=(20, 15))\n",
    "\n",
    "    # Define y-ticks and their labels based on the number of ROIs\n",
    "    y_ticks = []\n",
    "    y_tick_labels = []\n",
    "\n",
    "    # Calculate a reasonable fixed offset to visually separate the ROI lines\n",
    "    fixed_offset = 100  # Adjust if necessary\n",
    "\n",
    "    # Plot each ROI's calcium signal with a unique random color and apply fixed offset incrementally\n",
    "    for i in range(num_rois):\n",
    "        random_color = np.random.rand(3,)\n",
    "        # Calculate the offset for this ROI's line\n",
    "        offset = i * fixed_offset\n",
    "        plt.plot(calcium_data['Frame'], calcium_data[f'ROI_{i+1}'] + offset, color=random_color, label=f'ROI_{i+1}')\n",
    "        \n",
    "        # Add y-tick at the median of the offset signal for the label\n",
    "        y_ticks.append(np.median(calcium_data[f'ROI_{i+1}'] + offset))\n",
    "        y_tick_labels.append(f'ROI_{i+1}')\n",
    "\n",
    "    # Add stimulation markers\n",
    "    for stim_point in stimulation_points:\n",
    "        plt.axvline(x=stim_point, color='red', linestyle='dotted', linewidth=1)\n",
    "\n",
    "    plt.xlabel('Frame')\n",
    "    plt.ylabel('ROI')\n",
    "    plt.yticks(y_ticks, y_tick_labels)\n",
    "    plt.title('All ROIs Aligned with Corresponding Data')\n",
    "    plt.legend(loc='upper left', bbox_to_anchor=(1, 1))  # Move the legend outside of the plot\n",
    "    plt.tight_layout(rect=[0, 0, 0.85, 1])  # Adjust layout to make room for the legend\n",
    "    plt.show()\n",
    "\n",
    "# Call the function to display the plot with correctly aligned ROIs and their data\n",
    "plot_all_rois_aligned(calcium_data, stimulation_data_no_header)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def plot_roi_aligned_extended_frames(calcium_data, stimulation_frames, num_rois=46, frames_before_stim=1000):\n",
    "    # Extract the frame numbers for stimulations and find the first stimulation frame\n",
    "    stimulation_points = stimulation_frames.values.flatten()\n",
    "    first_stim_frame = np.min(stimulation_points)\n",
    "\n",
    "    # Set the range of frames to plot: from (first_stim_frame - frames_before_stim) to the end of the data\n",
    "    start_frame = max(0, first_stim_frame - frames_before_stim)\n",
    "    end_frame = calcium_data['Frame'].max()\n",
    "\n",
    "    # Filter the calcium_data to include only the relevant frames\n",
    "    limited_data = calcium_data[(calcium_data['Frame'] >= start_frame) & (calcium_data['Frame'] <= end_frame)]\n",
    "\n",
    "    # Initialize the figure\n",
    "    plt.figure(figsize=(20, 15))\n",
    "\n",
    "    # Define y-ticks and their labels based on the number of ROIs\n",
    "    y_ticks = []\n",
    "    y_tick_labels = []\n",
    "\n",
    "    fixed_offset = 100  # Adjust if necessary\n",
    "\n",
    "    for i in range(num_rois):\n",
    "        random_color = np.random.rand(3,)\n",
    "        offset = i * fixed_offset\n",
    "        plt.plot(limited_data['Frame'], limited_data[f'ROI_{i+1}'] + offset, color=random_color, label=f'ROI_{i+1}')\n",
    "        \n",
    "        y_ticks.append(np.median(limited_data[f'ROI_{i+1}'] + offset))\n",
    "        y_tick_labels.append(f'ROI_{i+1}')\n",
    "\n",
    "    # Add stimulation markers within the range\n",
    "    for stim_point in stimulation_points:\n",
    "        if start_frame <= stim_point <= end_frame:\n",
    "            plt.axvline(x=stim_point, color='red', linestyle='dotted', linewidth=1)\n",
    "\n",
    "    plt.xlabel('Frame')\n",
    "    plt.ylabel('ROI')\n",
    "    plt.yticks(y_ticks, y_tick_labels)\n",
    "    plt.xlim(start_frame, end_frame)\n",
    "    plt.title('Aligned ROIs with Extended Frame Range')\n",
    "    plt.legend(loc='upper left', bbox_to_anchor=(1, 1))  # Move the legend outside of the plot\n",
    "    plt.tight_layout(rect=[0, 0, 0.85, 1])  # Adjust layout to make room for the legend\n",
    "    plt.show()\n",
    "\n",
    "# Call the function with the extended frame range\n",
    "plot_roi_aligned_extended_frames(calcium_data, stimulation_data_no_header)\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "biolumi_calcium_imaging",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.18"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
